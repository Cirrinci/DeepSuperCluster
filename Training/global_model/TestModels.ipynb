{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5389e77-6c5a-4ef3-85ce-bfeb93c1093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f588d29-a284-4223-a10f-5a6a5a5c36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"model_ACAT21.py\"\n",
    "config_json = \"training_config_awk.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd89e66c-a06d-4559-ae56-df710b222218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version=2.1.0, CUDA=True, GPU=True\n",
      "Using 1 GPU\n",
      "Model output folder:  /work/dvalsecc/Clustering/models_archive/gcn_models/ACAT2021_v2//run_70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:34:32.874133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-09-22 12:34:37.216864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.217620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.222421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.223552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.224288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.225008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.225719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.226429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:37.227382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-22 12:34:37.230975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-22 12:34:37.234168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-22 12:34:37.235536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-22 12:34:37.238762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-22 12:34:37.240550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-22 12:34:37.246853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-22 12:34:37.257590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import awk_data\n",
    "import tensorflow as tf\n",
    "import loader\n",
    "import argparse \n",
    "from collections import defaultdict\n",
    "import os, json\n",
    "import importlib.util\n",
    "from time import time\n",
    "import numpy as np\n",
    "from plotting import * \n",
    "import plot_loss\n",
    "\n",
    "config = json.load(open(config_json))\n",
    "\n",
    "config['activation'] = tf.keras.activations.get(config['activation'])\n",
    "\n",
    "# Checking hardware\n",
    "print('version={}, CUDA={}, GPU={}'.format(\n",
    "    tf.__version__, tf.test.is_built_with_cuda(),\n",
    "    len(tf.config.list_physical_devices('GPU')) > 0))\n",
    "      \n",
    "gpus =  tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# if len(gpus) ==1 :\n",
    "#     print(\"Using 1 GPU\")\n",
    "#     tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "#     strategy = tf.distribute.OneDeviceStrategy(\"gpu:0\")\n",
    "# elif len(gpus):\n",
    "#     print(\"Using {} GPUs\".format(len(gpus)))\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu, enable=True)\n",
    "#     strategy = tf.distribute.MirroredStrategy()\n",
    "# else:\n",
    "#     strategy = tf.distribute.OneDeviceStrategy(\"cpu:0\")\n",
    "if len(gpus) >=1 :\n",
    "    print(\"Using 1 GPU\")\n",
    "    #tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"gpu:0\")\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"cpu:0\")\n",
    "\n",
    "\n",
    "##################\n",
    "# Prepare the output folder\n",
    "def get_unique_run():\n",
    "    previous_runs = os.listdir(config[\"models_path\"])\n",
    "    if len(previous_runs) == 0:\n",
    "        run_number = 1\n",
    "    else:\n",
    "        run_number = max([int(s.split('run_')[1]) for s in previous_runs]) + 1\n",
    "    return run_number\n",
    "\n",
    "if not os.path.isdir(config[\"models_path\"]):\n",
    "    os.makedirs(config[\"models_path\"])\n",
    "\n",
    "name =  'run_{:02}'.format(get_unique_run())\n",
    "\n",
    "outdir = config[\"models_path\"] + \"/\"+ name\n",
    "\n",
    "if os.path.isdir(outdir):\n",
    "    print(\"Output directory exists: {}\".format(outdir), file=sys.stderr)\n",
    "else:\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "print(\"Model output folder: \", outdir)\n",
    "\n",
    "############################3\n",
    "#Copying the config file and model file in the output dir:\n",
    "os.system(\"cp {} {}\".format(config_json, outdir))\n",
    "os.system(\"cp {} {}\".format(model_file, outdir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd48708-2ab3-4091-b4f4-8093b456e00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading datasets\n",
      "((tf.float32, tf.float32, tf.float32, tf.int64, tf.float32, tf.float32), (tf.int64, tf.float32, tf.float32, tf.float32, tf.float32), (tf.float32,))\n",
      "((tf.float32, tf.float32, tf.float32, tf.int64, tf.float32, tf.float32), (tf.int64, tf.float32, tf.float32, tf.float32, tf.float32), (tf.float32,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:34:37.372388: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-09-22 12:34:37.394421: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200115000 Hz\n",
      "2022-09-22 12:34:37.400446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595f6300450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-09-22 12:34:37.400494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-09-22 12:34:38.575156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5595f638a1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-09-22 12:34:38.575223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575239: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575276: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575300: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.575311: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-09-22 12:34:38.633397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.634248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: \n",
      "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.635069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 2 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.635892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 3 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.636713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 4 with properties: \n",
      "pciBusID: 0000:0c:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.637522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 5 with properties: \n",
      "pciBusID: 0000:0d:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.638332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 6 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.639162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 7 with properties: \n",
      "pciBusID: 0000:0f:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-09-22 12:34:38.639238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-22 12:34:38.639265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-22 12:34:38.639290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-09-22 12:34:38.639314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-09-22 12:34:38.639349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-09-22 12:34:38.639371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-09-22 12:34:38.639393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-22 12:34:38.651391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7\n",
      "2022-09-22 12:34:38.651444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-09-22 12:34:38.657976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-22 12:34:38.658001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 2 3 4 5 6 7 \n",
      "2022-09-22 12:34:38.658021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y Y Y Y Y Y Y \n",
      "2022-09-22 12:34:38.658030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N Y Y Y Y Y Y \n",
      "2022-09-22 12:34:38.658038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 2:   Y Y N Y Y Y Y Y \n",
      "2022-09-22 12:34:38.658045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 3:   Y Y Y N Y Y Y Y \n",
      "2022-09-22 12:34:38.658053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 4:   Y Y Y Y N Y Y Y \n",
      "2022-09-22 12:34:38.658061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 5:   Y Y Y Y Y N Y Y \n",
      "2022-09-22 12:34:38.658068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 6:   Y Y Y Y Y Y N Y \n",
      "2022-09-22 12:34:38.658076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 7:   Y Y Y Y Y Y Y N \n",
      "2022-09-22 12:34:38.665007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10487 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.666919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10487 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.669143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10487 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.671337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10487 MB memory) -> physical GPU (device: 3, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.672877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10487 MB memory) -> physical GPU (device: 4, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.674396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10487 MB memory) -> physical GPU (device: 5, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0d:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.675921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10487 MB memory) -> physical GPU (device: 6, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)\n",
      "2022-09-22 12:34:38.677951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10487 MB memory) -> physical GPU (device: 7, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0f:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "## Loading the datasets\n",
    "print(\">>> Loading datasets\")\n",
    "\n",
    "train_ds = awk_data.load_dataset(awk_data.LoaderConfig(**config[\"dataset_conf\"][\"training\"]))\n",
    "test_ds = awk_data.load_dataset(awk_data.LoaderConfig(**config[\"dataset_conf\"][\"validation\"]))\n",
    "# Create training and validation\n",
    "ds_train = train_ds.prefetch(200).repeat(config['nepochs'])\n",
    "ds_test  = test_ds.prefetch(200).repeat(config['nepochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4338201-15a1-4b5c-b7d4-cd7e0f8a1d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Creating the model\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:35:14.407778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-09-22 12:35:14.839418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-09-22 12:35:16.014217: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23605/1258610601.py\", line 25, in <module>\n",
      "    ypred = model(X, training=False)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 632, in call\n",
      "    cl_X, coord, adj, output_rechits,coord_att_ws = self.graphbuild(cl_X_initial, cl_hits, mask_rechits, mask_cls, training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 489, in call\n",
      "    output_rechits, (debug) = self.rechitsGCN(rechits_features, mask_rechits, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 422, in call\n",
      "    dense_output = self.dense_out(sa_output, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 818, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2098, in _maybe_build\n",
      "    self.input_spec, inputs, self.name)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 177, in assert_input_compatibility\n",
      "    str(x.shape.as_list()))\n",
      "ValueError: Input 0 of layer dense_rechits is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [256, 27, 32, 25]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23605/1258610601.py\", line 25, in <module>\n",
      "    ypred = model(X, training=False)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 632, in call\n",
      "    cl_X, coord, adj, output_rechits,coord_att_ws = self.graphbuild(cl_X_initial, cl_hits, mask_rechits, mask_cls, training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 489, in call\n",
      "    output_rechits, (debug) = self.rechitsGCN(rechits_features, mask_rechits, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 422, in call\n",
      "    dense_output = self.dense_out(sa_output, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 818, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2098, in _maybe_build\n",
      "    self.input_spec, inputs, self.name)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 177, in assert_input_compatibility\n",
      "    str(x.shape.as_list()))\n",
      "ValueError: Input 0 of layer dense_rechits is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [256, 27, 32, 25]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23605/1258610601.py\", line 25, in <module>\n",
      "    ypred = model(X, training=False)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 632, in call\n",
      "    cl_X, coord, adj, output_rechits,coord_att_ws = self.graphbuild(cl_X_initial, cl_hits, mask_rechits, mask_cls, training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 489, in call\n",
      "    output_rechits, (debug) = self.rechitsGCN(rechits_features, mask_rechits, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 822, in __call__\n",
      "    outputs = self.call(cast_inputs, *args, **kwargs)\n",
      "  File \"model_ACAT21.py\", line 422, in call\n",
      "    dense_output = self.dense_out(sa_output, training=training)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 818, in __call__\n",
      "    self._maybe_build(inputs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2098, in _maybe_build\n",
      "    self.input_spec, inputs, self.name)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\", line 177, in assert_input_compatibility\n",
      "    str(x.shape.as_list()))\n",
      "ValueError: Input 0 of layer dense_rechits is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [256, 27, 32, 25]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "############### \n",
    "# Loading the model file\n",
    " # Load model modules\n",
    "spec = importlib.util.spec_from_file_location(\"model\", model_file)\n",
    "model_lib = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(model_lib)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# Construction of the model in the strategy scope\n",
    "with strategy.scope():\n",
    "    print(\">>> Creating the model\")\n",
    "    # Build the model with all the configs\n",
    "    model = model_lib.DeepClusterGN(**config)\n",
    "\n",
    "    #optimizer\n",
    "    if config['opt'] == \"adam\":\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=config['lr'])\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer=opt)\n",
    "    model.set_metrics()\n",
    "\n",
    "    for X, y ,w  in ds_train:\n",
    "        # Load the model\n",
    "        ypred = model(X, training=False)\n",
    "        #l = custom_loss(y, ypred)\n",
    "        break\n",
    "\n",
    "    model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0bd0316-5a51-419b-80f4-0b1271c08d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:20:52.311865: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_44\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 15\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 6\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 4\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        unknown_rank: true\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 15\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 6\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 9\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        unknown_rank: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-09-22 11:20:52.414353: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.173596799\n",
      "0.192695349\n",
      "0.170938492\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:21:07.979263: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_89\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:3\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 15\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 6\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 4\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        unknown_rank: true\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 15\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 6\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: 9\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        unknown_rank: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 24s - loss: 21.6032 - loss_clusters: 0.1791 - loss_windows: 1.0218 - loss_softF1: 0.8626 - loss_en_resol: 0.3980 - loss_en_softF1: 0.4592 - loss_en_regr: 1131.6947 - val_loss: 17.7833 - val_loss_clusters: 0.1451 - val_loss_windows: 0.5793 - val_loss_softF1: 0.6132 - val_loss_en_resol: 0.3931 - val_loss_en_softF1: 0.4557 - val_loss_en_regr: 1047.1036 - 24s/epoch - 8s/step\n",
      "Epoch 2/3\n",
      "0.185970128\n",
      "0.178496212\n",
      "0.178051636\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "3/3 - 7s - loss: 19.8376 - loss_clusters: 0.1808 - loss_windows: 0.6298 - loss_softF1: 0.8425 - loss_en_resol: 0.3243 - loss_en_softF1: 0.3989 - loss_en_regr: 1020.3561 - val_loss: 16.6382 - val_loss_clusters: 0.1501 - val_loss_windows: 0.3145 - val_loss_softF1: 0.5889 - val_loss_en_resol: 0.2760 - val_loss_en_softF1: 0.3515 - val_loss_en_regr: 993.3220 - 7s/epoch - 2s/step\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/pool.py\", line 109, in worker\n",
      "    initializer(*initargs)\n",
      "  File \"/work/dvalsecc/Clustering/DeepSuperCluster/Training/global_model/awk_data.py\", line 265, in process\n",
      "    output_q.put(out)\n",
      "  File \"/work/dvalsecc/Clustering/DeepSuperCluster/Training/global_model/awk_data.py\", line 265, in process\n",
      "    output_q.put(out)\n",
      "  File \"/work/dvalsecc/Clustering/DeepSuperCluster/Training/global_model/awk_data.py\", line 265, in process\n",
      "    output_q.put(out)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/queues.py\", line 377, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/queues.py\", line 376, in put\n",
      "    with self._wlock:\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/queues.py\", line 376, in put\n",
      "    with self._wlock:\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/connection.py\", line 410, in _send_bytes\n",
      "    self._send(buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168071017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/work/dvalsecc/miniconda3/envs/clustering/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train,\n",
    "        validation_data=ds_test, \n",
    "        epochs=config['nepochs'],\n",
    "        steps_per_epoch=3, \n",
    "        validation_steps=3,\n",
    "        verbose=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4644bbb2-2371-4963-940a-0bc194cfbb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_en_resol, loss_en_softF1 = energy_loss(y, y_pred, w[0],1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b421c6-203f-4000-ad69-26ecceef6369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_en_resol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21934e71-c944-412f-bc85-b69a764fdc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Q_sa_SA_enregr:0', 'K_sa_SA_enregr:0', 'V_sa_SA_enregr:0', 'input_sa_SA_enregr:0', 'output_sa_SA_enregr_0/kernel:0', 'output_sa_SA_enregr_0/bias:0', 'output_sa_SA_enregr_1/kernel:0', 'output_sa_SA_enregr_1/bias:0', 'deep_cluster_gn/SA_enregr/SA_lnorm1_SA_enregr/gamma:0', 'deep_cluster_gn/SA_enregr/SA_lnorm1_SA_enregr/beta:0', 'deep_cluster_gn/SA_enregr/SA_lnorm2_SA_enregr/gamma:0', 'deep_cluster_gn/SA_enregr/SA_lnorm2_SA_enregr/beta:0', 'dense_enregr_0/kernel:0', 'dense_enregr_0/bias:0', 'dense_enregr_1/kernel:0', 'dense_enregr_1/bias:0', 'dense_enregr_2/kernel:0', 'dense_enregr_2/bias:0', 'dense_enregr_3/kernel:0', 'dense_enregr_3/bias:0', 'dense_enregr_4/kernel:0', 'dense_enregr_4/bias:0', 'deep_cluster_gn/SA_enregr_layernorm/gamma:0', 'deep_cluster_gn/SA_enregr_layernorm/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y_pred = model(X, training=True)  # Forward pass\n",
    "    # Compute our own loss\n",
    "    loss_clusters = clusters_classification_loss(y, y_pred, w[0])\n",
    "    loss_softF1 =  soft_f1_score(y,y_pred, w[0], 1.0)\n",
    "    loss_windows = window_classification_loss(y, y_pred, w[0])\n",
    "    #loss_en_resol, loss_en_softF1 = energy_loss(y, y_pred, w[0],1.0)\n",
    "    #loss_en_regr = energy_regression_loss(y, y_pred, w[0])\n",
    "    loss =  model.loss_weights[\"clusters\"] * loss_clusters +\\\n",
    "        model.loss_weights[\"window\"] * loss_windows + \\\n",
    "        model.loss_weights[\"softF1\"] * loss_softF1 + \\\n",
    "        sum(model.losses)\n",
    "    trainable_vars = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, trainable_vars)\n",
    "    # Update weights\n",
    "    model.optimizer.apply_gradients(zip(gradients, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84569398-3eab-4b01-8961-62fe7d2eab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dense_clclass, dense_windclass, en_regr_factor),  mask_cls, _  = y_pred\n",
    "y_clclass, y_windclass, cl_X, wind_X, y_metadata = y        \n",
    "class_loss = tf.keras.losses.binary_crossentropy(y_clclass[:,:,tf.newaxis], dense_clclass, from_logits=True) * mask_cls\n",
    "reduced_loss = tf.reduce_sum(tf.reduce_mean(class_loss, axis=-1) * w[0]) / tf.reduce_sum(w[0])\n",
    "# This should be replaced by the mean over the not masked elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fa6c41f-335f-4692-bb7c-f5ee2bf7c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dense_clclass, dense_windclass, en_regr_factor), mask_cls, _  = y_pred\n",
    "y_clclass, y_windclass, cl_X, wind_X, y_metadata = y\n",
    "y_target = tf.cast(y_clclass, tf.float32)[:,:,tf.newaxis]\n",
    "cl_en = Et = cl_X[:,:,0:1]\n",
    "En_sim_good = y_metadata[:,-1]\n",
    "pred_prob = tf.nn.sigmoid(dense_clclass)\n",
    "\n",
    "sel_en = tf.squeeze(tf.reduce_sum(cl_en * pred_prob , axis=1))\n",
    "en_resolution_loss =  tf.reduce_sum(tf.square( (sel_en/En_sim_good) - 1) * w[0] ) / tf.reduce_sum(w[0]) \n",
    "#soft f1 style loss\n",
    "tp = tf.reduce_sum(cl_en* pred_prob * y_target, axis=1)\n",
    "fn = tf.reduce_sum(cl_en* (1 - pred_prob) * y_target, axis=1)\n",
    "fp = tf.reduce_sum(cl_en* pred_prob * (1 - y_target), axis=1)\n",
    "beta = 0.5\n",
    "soft_f1_loss = 1 - ((1 + beta**2) * tp)/ ( (1+beta**2)*tp + beta* fn + fp + 1e-16)\n",
    "reduced_f1 = tf.reduce_sum(tf.squeeze(soft_f1_loss) * w[0])  / tf.reduce_sum(w[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a5c8fb-73b3-4f1c-bcc0-6d74374449a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "df = ak.from_parquet(config[\"dataset_conf\"][\"training\"][\"input_folders\"][0], lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1bde6-2253-46dd-a613-b54c84dc534b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561b084a-af97-4678-92c3-a2c8af1f7683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 52709., 113004., 120649., 121921., 121264., 121061., 119187.,\n",
       "        118122., 115305.,  74500.]),\n",
       " array([1.21495657e-03, 9.93404497e+00, 1.98668750e+01, 2.97997050e+01,\n",
       "        3.97325350e+01, 4.96653650e+01, 5.95981950e+01, 6.95310250e+01,\n",
       "        7.94638550e+01, 8.93966850e+01, 9.93295151e+01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.window_metadata.et_true_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11157a-2218-4e4e-b629-e756545f90fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
