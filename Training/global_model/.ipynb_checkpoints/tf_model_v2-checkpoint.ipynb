{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing setGPU\n",
      "Could not import setGPU, please make sure you configure CUDA_VISIBLE_DEVICES manually\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import glob\n",
    "try:\n",
    "    if not (\"CUDA_VISIBLE_DEVICES\" in os.environ):\n",
    "        os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "        print(\"importing setGPU\")\n",
    "        import setGPU\n",
    "except:\n",
    "    print(\"Could not import setGPU, please make sure you configure CUDA_VISIBLE_DEVICES manually\")\n",
    "    pass\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import io\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import tensorflow as tf\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "\n",
    "import scipy\n",
    "import scipy.special\n",
    "\n",
    "from mpnn import MessagePassing, ReadoutGraph, Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version=2.1.0, CUDA=True, GPU=True, TPU=False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "# Tested with TensorFlow 2.1.0\n",
    "print('version={}, CUDA={}, GPU={}, TPU={}'.format(\n",
    "    tf.__version__, tf.test.is_built_with_cuda(),\n",
    "    # GPU attached?\n",
    "    len(tf.config.list_physical_devices('GPU')) > 0,\n",
    "    # TPU accessible? (only works on Colab)\n",
    "    'COLAB_TPU_ADDR' in os.environ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(A,B):\n",
    "    na = tf.reduce_sum(tf.square(A), -1)\n",
    "    nb = tf.reduce_sum(tf.square(B), -1)\n",
    " \n",
    "    na = tf.reshape(na, [tf.shape(na)[0], -1, 1])\n",
    "    nb = tf.reshape(nb, [tf.shape(na)[0], 1, -1])\n",
    "    Dsq = tf.clip_by_value(na - 2*tf.linalg.matmul(A, B, transpose_a=False, transpose_b=True) + nb, 1e-12, 1e12)\n",
    "    D = tf.sqrt(Dsq)\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a list of [Nbatch, Nelem, Nfeat] input nodes, computes the dense [Nbatch, Nelem, Nelem] adjacency matrices\n",
    "class Distance(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, dist_shape, *args, **kwargs):\n",
    "        super(Distance, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs1, inputs2):\n",
    "        #compute the pairwise distance matrix between the vectors defined by the first two components of the input array\n",
    "        #inputs1, inputs2: [Nbatch, Nelem, distance_dim] embedded coordinates used for element-to-element distance calculation\n",
    "        D = dist(inputs1, inputs2)\n",
    "      \n",
    "        #adjacency between two elements should be high if the distance is small.\n",
    "        #this is equivalent to radial basis functions. \n",
    "        #self-loops adj_{i,i}=1 are included, as D_{i,i}=0 by construction\n",
    "        adj = tf.math.exp(-1.0*D)\n",
    "\n",
    "        #optionally set the adjacency matrix to 0 for low values in order to make the matrix sparse.\n",
    "        #need to test if this improves the result.\n",
    "        #adj = tf.keras.activations.relu(adj, threshold=0.01)\n",
    "\n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_input_classes):\n",
    "        super(InputEncoding, self).__init__()\n",
    "        self.num_input_classes = num_input_classes\n",
    "        \n",
    "    def call(self, X):\n",
    "        #X: [Nbatch, Nelem, Nfeat] array of all the input detector element feature data\n",
    "\n",
    "        #X[:, :, 0] - categorical index of the element type\n",
    "        Xid = tf.one_hot(tf.cast(X[:, :, 0], tf.int32), self.num_input_classes)\n",
    "\n",
    "        #X[:, :, 1:] - all the other non-categorical features\n",
    "        Xprop = X[:, :, 1:]\n",
    "        return tf.concat([Xid, Xprop], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph Highway network\n",
    "# https://arxiv.org/pdf/2004.04635.pdf\n",
    "#https://github.com/gcucurull/jax-ghnet/blob/master/models.py \n",
    "class GHConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, k, *args, **kwargs):\n",
    "        self.activation = kwargs.pop(\"activation\")\n",
    "        self.hidden_dim = args[0]\n",
    "        self.k = k\n",
    "\n",
    "        super(GHConv, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.W_t = self.add_weight(shape=(self.hidden_dim, self.hidden_dim), name=\"w_t\", initializer=\"random_normal\")\n",
    "        self.b_t = self.add_weight(shape=(self.hidden_dim, ), name=\"b_t\", initializer=\"zeros\")\n",
    "        self.W_h = self.add_weight(shape=(self.hidden_dim, self.hidden_dim), name=\"w_h\", initializer=\"random_normal\")\n",
    "        self.theta = self.add_weight(shape=(self.hidden_dim, self.hidden_dim), name=\"theta\", initializer=\"random_normal\")\n",
    " \n",
    "    def call(self, x, adj):\n",
    "        #compute the normalization of the adjacency matrix\n",
    "        in_degrees = tf.reduce_sum(adj, axis=-1)\n",
    "        #add epsilon to prevent numerical issues from 1/sqrt(x)\n",
    "        norm = tf.expand_dims(tf.pow(in_degrees + 1e-6, -0.5), -1)\n",
    "        norm_k = tf.pow(norm, self.k)\n",
    "        adj_k = tf.pow(adj, self.k)\n",
    "\n",
    "        f_hom = tf.linalg.matmul(x, self.theta)\n",
    "        f_hom = tf.linalg.matmul(adj_k, f_hom*norm_k)*norm_k\n",
    "\n",
    "        f_het = tf.linalg.matmul(x, self.W_h)\n",
    "        gate = tf.nn.sigmoid(tf.linalg.matmul(x, self.W_t) + self.b_t)\n",
    "        #tf.print(tf.reduce_mean(f_hom), tf.reduce_mean(f_het), tf.reduce_mean(gate))\n",
    "\n",
    "        out = gate*f_hom + (1-gate)*f_het\n",
    "        return out\n",
    "\n",
    "## Simple Graph Conv layer\n",
    "class SGConv(tf.keras.layers.Dense):\n",
    "    def __init__(self, k, *args, **kwargs):\n",
    "        super(SGConv, self).__init__(*args, **kwargs)\n",
    "        self.k = k\n",
    "    \n",
    "    def call(self, inputs, adj):\n",
    "        W = self.weights[0]\n",
    "        b = self.weights[1]\n",
    "\n",
    "        #compute the normalization of the adjacency matrix\n",
    "        in_degrees = tf.reduce_sum(adj, axis=-1)\n",
    "        #add epsilon to prevent numerical issues from 1/sqrt(x)\n",
    "        norm = tf.expand_dims(tf.pow(in_degrees + 1e-6, -0.5), -1)\n",
    "        norm_k = tf.pow(norm, self.k)\n",
    "\n",
    "        support = (tf.linalg.matmul(inputs, W))\n",
    "     \n",
    "        #k-th power of the normalized adjacency matrix is nearly equivalent to k consecutive GCN layers\n",
    "        adj_k = tf.pow(adj, self.k)\n",
    "        out = tf.linalg.matmul(adj_k, support*norm_k)*norm_k\n",
    "\n",
    "        return self.activation(out + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple message passing based on a matrix multiplication\n",
    "class DNNSuperCluster(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, activation=tf.nn.selu, nclass_labels=2, hidden_dim=256, distance_dim=256, num_conv=4, convlayer=\"ghconv\", dropout=0.1):\n",
    "        super(DNNSuperCluster, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.nclass_labels = nclass_labels\n",
    "\n",
    "        #self.enc = InputEncoding(3)\n",
    "\n",
    "        self.layer_distcoords1 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"distcoords1\")\n",
    "        self.layer_distcoords2 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"distcoords2\")\n",
    "        self.layer_distcoords3 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"distcoords3\")\n",
    "        self.layer_distcoords = tf.keras.layers.Dense(distance_dim, activation=\"linear\", name=\"distcoords\")\n",
    "\n",
    "        self.layer_input1 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"input1\")\n",
    "        self.layer_input1_do = tf.keras.layers.Dropout(dropout)\n",
    "        self.layer_input2 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"input2\")\n",
    "        self.layer_input2_do = tf.keras.layers.Dropout(dropout)\n",
    "        self.layer_input3 = tf.keras.layers.Dense(2*hidden_dim, activation=activation, name=\"input3\")\n",
    "        self.layer_input3_do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "            \n",
    "        self.layer_dist = Distance(distance_dim, name=\"distance\")\n",
    "\n",
    "        if convlayer == \"sgconv\":\n",
    "            self.layer_conv1 = SGConv(num_conv, 2*hidden_dim, activation=activation, name=\"conv1\")\n",
    "            #self.layer_conv2 = SGConv(num_conv, 2*hidden_dim+len(class_labels), activation=activation, name=\"conv2\")\n",
    "        elif convlayer == \"ghconv\":\n",
    "            self.layer_conv1 = GHConv(num_conv, 2*hidden_dim, activation=activation, name=\"conv1\")\n",
    "            #self.layer_conv2 = GHConv(num_conv, 2*hidden_dim+len(class_labels), activation=activation, name=\"conv2\")\n",
    "\n",
    "        self.layer_id1 = tf.keras.layers.Dense(2*hidden_dim, activation=activation, name=\"id1\")\n",
    "        self.layer_id2 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"id2\")\n",
    "        self.layer_id3 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"id3\")\n",
    "        self.layer_id = tf.keras.layers.Dense(nclass_labels, activation=\"linear\", name=\"out_id\")\n",
    "        #self.layer_charge = tf.keras.layers.Dense(1, activation=\"linear\", name=\"out_charge\")\n",
    "        \n",
    "        #self.layer_momentum1 = tf.keras.layers.Dense(2*hidden_dim, activation=activation, name=\"momentum1\")\n",
    "        #self.layer_momentum2 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"momentum2\")\n",
    "        #self.layer_momentum3 = tf.keras.layers.Dense(hidden_dim, activation=activation, name=\"momentum3\")\n",
    "        #self.layer_momentum = tf.keras.layers.Dense(3, activation=\"linear\", name=\"out_momentum\")\n",
    " \n",
    "    def predict_distancematrix(self, inputs, training=True):\n",
    "\n",
    "        act_inputs = self.activation(inputs)\n",
    "        x = self.layer_distcoords1(inputs)\n",
    "        x = self.layer_distcoords2(x)\n",
    "        x = self.layer_distcoords3(x)\n",
    "        distcoords = self.layer_distcoords(x)\n",
    "\n",
    "        dm = self.layer_dist(distcoords, distcoords)\n",
    "        \n",
    "        # masking if the first element is -1\n",
    "        msk_elem = tf.expand_dims(tf.cast(inputs[:, :, 0] != -1, dtype=tf.float32), -1)\n",
    "        dm = dm*msk_elem\n",
    "\n",
    "        return act_inputs, dm\n",
    "\n",
    "    #@tf.function(input_signature=[tf.TensorSpec(shape=[None, 15], dtype=tf.float32)])\n",
    "    def call(self, inputs, training=True):\n",
    "        X = inputs\n",
    "        msk_input = tf.expand_dims(tf.cast(X[:, :, 0] != -1, tf.float32), -1)\n",
    "\n",
    "        act_inputs, dm = self.predict_distancematrix(X, training=training)\n",
    "\n",
    "        x = self.layer_input1(act_inputs)\n",
    "        x = self.layer_input1_do(x, training)\n",
    "        x = self.layer_input2(x)\n",
    "        x = self.layer_input2_do(x, training)\n",
    "        x = self.layer_input3(x)\n",
    "        x = self.layer_input3_do(x, training)\n",
    "        x = self.layer_conv1(x, dm)\n",
    "        x = self.layer_id1(x)\n",
    "        x = self.layer_id2(x)\n",
    "        x = self.layer_id3(x)\n",
    "        out_id_logits = self.layer_id(x)\n",
    "\n",
    "\n",
    "        ret = out_id_logits*msk_input\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNSuperClusterOld(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, activation=tf.keras.activations.relu, hidden_dim_in=256,hidden_dim_out=256):\n",
    "        super(DNNSuperCluster, self).__init__()\n",
    "        self.layer_input1 = tf.keras.layers.Dense(hidden_dim_in, activation=activation, name=\"input1\")\n",
    "        self.layer_input2 = tf.keras.layers.Dense(hidden_dim_in, activation=activation, name=\"input2\")\n",
    "        self.layer_input3 = tf.keras.layers.Dense(hidden_dim_in, activation=activation, name=\"input3\")\n",
    "        \n",
    "        self.layer_dist = Distance(name=\"distance\")\n",
    "        self.layer_conv = GraphConv(hidden_dim_in, activation=activation, name=\"conv\")\n",
    "        \n",
    "        self.layer_id1 = tf.keras.layers.Dense(hidden_dim_out, activation=activation, name=\"id1\")\n",
    "        self.layer_id2 = tf.keras.layers.Dense(hidden_dim_out, activation=activation, name=\"id2\")\n",
    "        self.layer_id3 = tf.keras.layers.Dense(hidden_dim_out, activation=activation, name=\"id3\")\n",
    "        self.layer_id = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"out_id\")\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #print(inputs)\n",
    "        x_init = tf.concat([inputs[0],tf.broadcast_to(inputs[1],[inputs[0].shape[0], inputs[1].shape[1]] )],\n",
    "                  axis=1)\n",
    "        \n",
    "        x = self.layer_input1(x_init)\n",
    "        x = self.layer_input2(x)\n",
    "        x_before_gcn = self.layer_input3(x)\n",
    "        \n",
    "        dm = self.layer_dist(x_before_gcn)\n",
    "        #print(\"distance matrix:\", dm.shape)\n",
    "        x_gcn = self.layer_conv(x_before_gcn, dm)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x_join = tf.concat([x_init, x_gcn], axis=1)\n",
    "        \n",
    "        a = self.layer_id1(x_join)\n",
    "        a = self.layer_id2(a)\n",
    "        a = self.layer_id3(a)\n",
    "        out_id = self.layer_id(a)\n",
    "    \n",
    "        \n",
    "        return out_id, dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_unreduced(true, pred):\n",
    "    return tf.math.pow(true-pred,2)\n",
    "\n",
    "def msle_unreduced(true, pred):\n",
    "    return tf.math.pow(tf.math.log(tf.math.abs(true) + 1.0) - tf.math.log(tf.math.abs(pred) + 1.0), 2)\n",
    "\n",
    "def my_loss_cls(y_true, y_pred):\n",
    "    pred_id_onehot, pred_charge, pred_momentum = separate_prediction(y_pred)\n",
    "    pred_id = tf.cast(tf.argmax(pred_id_onehot, axis=-1), tf.int32)\n",
    "    true_id, true_charge, true_momentum = separate_truth(y_true)\n",
    "\n",
    "    true_id_onehot = tf.one_hot(tf.cast(true_id, tf.int32), depth=len(class_labels))\n",
    "    #predict the particle class labels\n",
    "    l1 = 1e4*tf.nn.softmax_cross_entropy_with_logits(true_id_onehot, pred_id_onehot)\n",
    "    #l1 = 1e4*tf.keras.losses.categorical_crossentropy(true_id_onehot[:, :, 0], pred_id_onehot, from_logits=True)\n",
    "    return 1e3*l1\n",
    "\n",
    "def my_loss_reg(y_true, y_pred):\n",
    "    pred_id_onehot, pred_charge, pred_momentum = separate_prediction(y_pred)\n",
    "    pred_id = tf.cast(tf.argmax(pred_id_onehot, axis=-1), tf.int32)\n",
    "    true_id, true_charge, true_momentum = separate_truth(y_true)\n",
    "\n",
    "    true_id_onehot = tf.one_hot(tf.cast(true_id, tf.int32), depth=len(class_labels))\n",
    "\n",
    "    l2_0 = mse_unreduced(true_momentum[:, :, 0], pred_momentum[:, :, 0])*10\n",
    "    l2_1 = mse_unreduced(tf.math.floormod(true_momentum[:, :, 1] - pred_momentum[:, :, 1] + np.pi, 2*np.pi) - np.pi, 0.0)*10\n",
    "    l2_2 = mse_unreduced(true_momentum[:, :, 2], pred_momentum[:, :, 2])/100.0\n",
    "\n",
    "    l2 = (l2_0 + l2_1 + l2_2)\n",
    "    \n",
    "    return 1e3*l2\n",
    "\n",
    "#@tf.function\n",
    "def my_loss_full(y_true, y_pred):\n",
    "    pred_id_onehot, pred_charge, pred_momentum = separate_prediction(y_pred)\n",
    "    pred_id = tf.cast(tf.argmax(pred_id_onehot, axis=-1), tf.int32)\n",
    "    true_id, true_charge, true_momentum = separate_truth(y_true)\n",
    "\n",
    "    true_id_onehot = tf.one_hot(tf.cast(true_id, tf.int32), depth=len(class_labels))\n",
    "    #tf.print(pred_id_onehot)\n",
    "    l1 = 1e3*tf.nn.softmax_cross_entropy_with_logits(true_id_onehot, pred_id_onehot)\n",
    "  \n",
    "    #msk_good = (true_id[:, 0] == pred_id)\n",
    "    #nsamp = tf.cast(tf.size(y_pred), tf.float32)\n",
    "\n",
    "    l2_0 = mse_unreduced(true_momentum[:, :, 0], pred_momentum[:, :, 0])\n",
    "    l2_1 = mse_unreduced(tf.math.floormod(true_momentum[:, :, 1] - pred_momentum[:, :, 1] + np.pi, 2*np.pi) - np.pi, 0.0)\n",
    "    l2_2 = mse_unreduced(true_momentum[:, :, 2], pred_momentum[:, :, 2])/100.0\n",
    "\n",
    "    l2 = (l2_0 + l2_1 + l2_2)\n",
    "    #l2 = tf.multiply(tf.cast(msk_good, tf.float32), l2)\n",
    "\n",
    "    l3 = mse_unreduced(true_charge, pred_charge)[:, :, 0]\n",
    "\n",
    "    #tf.debugging.check_numerics(l1, \"l1\")\n",
    "    #tf.debugging.check_numerics(l2_0, \"l2_0\")\n",
    "    #tf.debugging.check_numerics(l2_1, \"l2_1\")\n",
    "    #tf.debugging.check_numerics(l2_2, \"l2_2\")\n",
    "\n",
    "    #tf.print(\"l1\", tf.reduce_mean(l1))\n",
    "    #tf.print(\"l2_0\", tf.reduce_mean(l2_0))\n",
    "    #tf.print(\"l2_1\", tf.reduce_mean(l2_1))\n",
    "    #tf.print(\"l2_2\", tf.reduce_mean(l2_2))\n",
    "    #tf.print(\"l2\", tf.reduce_mean(l2))\n",
    "    #tf.print(\"l3\", tf.reduce_mean(l3))\n",
    "\n",
    "    #tf.print(\"\\n\")\n",
    "    l = l1 + l2 + l3\n",
    "    return 1e3*l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_gpus= 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    num_gpus = len(os.environ[\"CUDA_VISIBLE_DEVICES\"].split(\",\"))\n",
    "    print(\"num_gpus=\", num_gpus)\n",
    "    if num_gpus > 1:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "    else:\n",
    "        strategy = tf.distribute.OneDeviceStrategy(\"gpu:0\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"fallback to CPU\")\n",
    "    strategy = tf.distribute.OneDeviceStrategy(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 15\n",
    "n_seed_features = 6\n",
    "\n",
    "def _parse_tfr_element(element):\n",
    "    parse_dic = {\n",
    "        'X':      tf.io.FixedLenFeature([], tf.string),\n",
    "        'X_seed': tf.io.FixedLenFeature([], tf.string),\n",
    "        'y':      tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example_message = tf.io.parse_single_example(element, parse_dic)\n",
    "\n",
    "    X = example_message['X']\n",
    "    X_seed = example_message['X_seed']\n",
    "    y = example_message['y']\n",
    "    arr_X = tf.io.parse_tensor(X, out_type=tf.float32)\n",
    "    arr_X_seed = tf.io.parse_tensor(X_seed, out_type=tf.float32)\n",
    "    arr_y = tf.io.parse_tensor(y, out_type=tf.float32)\n",
    "    \n",
    "    #https://github.com/tensorflow/tensorflow/issues/24520#issuecomment-577325475\n",
    "    arr_X.set_shape(     tf.TensorShape((None, n_features)))\n",
    "    arr_X_seed.set_shape(tf.TensorShape((1, n_seed_features)))\n",
    "    arr_y.set_shape(     tf.TensorShape((None,)))\n",
    "    \n",
    "    arr_y = tf.one_hot(tf.cast(arr_y[:], tf.int32), 2)\n",
    "    \n",
    "    return arr_X, arr_X_seed, arr_y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/storage/ECAL/training_data/window_data/gammas/recordio_v2\"\n",
    "models_path = \"/storage/ECAL/deepcluster/models/gcn_models_v2\"\n",
    "\n",
    "#rain_steps_per_epoch = \n",
    "#eval_steps_per_epoch = 3e5 // batch_size\n",
    "from collections import namedtuple\n",
    "Args = namedtuple('args', [ 'models_path', 'nepochs','ntrain','nval','nfeatures',\n",
    "                            'n_seed_features','batch_size','lr_decay','lr',\n",
    "                            'nhidden','distance_dim','num_conv','dropout','convlayer',\n",
    "                           'nclass_labels', 'opt'])\n",
    "\n",
    "args = Args( \n",
    "        models_path = models_path,\n",
    "        nepochs = 10,\n",
    "        ntrain = 1000,\n",
    "        nval = 100,\n",
    "        batch_size = 52,\n",
    "        nfeatures = 15,\n",
    "        n_seed_features = 6,\n",
    "        lr_decay = False,\n",
    "        lr = 0.001,\n",
    "        nhidden = 100,\n",
    "        distance_dim = 100,\n",
    "        num_conv = 4,\n",
    "        dropout = 0.0,\n",
    "        convlayer = 'sgconv',\n",
    "        nclass_labels=2,\n",
    "        opt='adam'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding shape\n",
    "ps = ([None,args.nfeatures],[1, args.n_seed_features],[None,2])\n",
    "\n",
    "# Create datasets from TFRecord files.\n",
    "dataset = tf.data.TFRecordDataset(tf.io.gfile.glob('{}/training-*'.format(data_path))).map(_parse_tfr_element,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_train = dataset.take(ntrain).padded_batch(args.batch_size, padded_shapes=ps, drop_remainder=True,padding_values=(-1.,-1.,-1.))\n",
    "ds_test = dataset.skip(ntrain).take(nval).padded_batch(args.batch_size, padded_shapes=ps, drop_remainder=True,padding_values=(-1.,-1.,-1.))\n",
    "\n",
    "ds_train_r = ds_train.repeat(args.nepochs)\n",
    "ds_test_r = ds_test.repeat(args.nepochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = iter(ds_train)\n",
    "d = next(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_run():\n",
    "    previous_runs = os.listdir(args.models_path)\n",
    "    if len(previous_runs) == 0:\n",
    "        run_number = 1\n",
    "    else:\n",
    "        run_number = max([int(s.split('run_')[1]) for s in previous_runs]) + 1\n",
    "    return run_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.lr_decay > 0:\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            args.lr,\n",
    "            decay_steps=10*int(args.ntrain/batch_size),\n",
    "            decay_rate=args.lr_decay\n",
    "        )\n",
    "else:\n",
    "    lr_schedule = args.lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    model = DNNSuperCluster(hidden_dim=args.nhidden, nclass_labels=args.nclass_labels, distance_dim=args.distance_dim, \n",
    "                            num_conv=args.num_conv, convlayer=args.convlayer, dropout=args.dropout)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ECAL/deepcluster/models/gcn_models_v2run_01\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(args.models_path):\n",
    "    os.makedirs(args.models_path)\n",
    "\n",
    "name =  'run_{:02}'.format(get_unique_run())\n",
    "\n",
    "outdir = args.models_path + name\n",
    "\n",
    "if os.path.isdir(outdir):\n",
    "    print(\"Output directory exists: {}\".format(outdir), file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "print(outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "tb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=outdir, histogram_freq=10, write_graph=True, write_images=False,\n",
    "    update_freq='epoch',\n",
    "    #profile_batch=(10,90),\n",
    "    profile_batch=0,\n",
    ")\n",
    "tb.set_model(model)\n",
    "callbacks += [tb]\n",
    "\n",
    "terminate_cb = tf.keras.callbacks.TerminateOnNaN()\n",
    "callbacks += [terminate_cb]\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=outdir + \"/weights.{epoch:02d}-{val_loss:.6f}.hdf5\",\n",
    "    save_weights_only=True,\n",
    "    verbose=0\n",
    ")\n",
    "cp_callback.set_model(model)\n",
    "callbacks += [cp_callback]\n",
    "\n",
    "loss_fn = my_loss_full\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-a4a3d2b9f60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-588c54f32404>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mmsk_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_distancematrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_input1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-588c54f32404>\u001b[0m in \u001b[0;36mpredict_distancematrix\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmsk_elem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#@tf.function(input_signature=[tf.TensorSpec(shape=[None, 15], dtype=tf.float32)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enc' is not defined"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=args.opt, loss=loss_fn,\n",
    "        metrics=[],\n",
    "        sample_weight_mode=\"temporal\")\n",
    "\n",
    "    for X, y, w in ds_train:\n",
    "        ypred = model(X)\n",
    "        l = loss_fn(y, ypred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.load:\n",
    "        #ensure model input size is known\n",
    "        for X, y, w in ds_train:\n",
    "            model(X)\n",
    "            break\n",
    "\n",
    "        model.load_weights(args.load)\n",
    "    if args.nepochs > 0:\n",
    "        ret = model.fit(ds_train_r,\n",
    "            validation_data=ds_test_r, epochs=args.nepochs,\n",
    "            steps_per_epoch=args.ntrain/batch_size, validation_steps=args.ntest/batch_size,\n",
    "            verbose=True,\n",
    "            callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets):\n",
    "    out, _ = model(inputs)\n",
    "     # modified cross entropy to explicit mathematical formula of sigmoid cross entropy loss\n",
    "    cross_entropy = - tf.reduce_sum( (  (targets[:,0]*tf.math.log(out + 1e-9)) + ((1-targets[:,0]) * tf.math.log(1 - out + 1e-9)) )  , name='xentropy' ) \n",
    "    \n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=71.99879>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = next(idata)\n",
    "loss(model, d[:2],d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets, epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "        return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, loss_tot: nan\n",
      "i: 250, loss_tot: 208.95696445910843\n",
      "i: 500, loss_tot: 285.9967866801098\n",
      "i: 750, loss_tot: 215.49208974038717\n",
      "i: 1000, loss_tot: 235.45319188342896\n",
      "i: 1250, loss_tot: 250.05417004236486\n",
      "i: 1500, loss_tot: 270.592827648744\n",
      "i: 1750, loss_tot: 239.17497981898487\n",
      "i: 2000, loss_tot: 227.97677876235917\n",
      "i: 2250, loss_tot: 246.68653825044632\n",
      "i: 2500, loss_tot: 213.3957731453888\n",
      "i: 2750, loss_tot: 225.02449972154574\n",
      "i: 3000, loss_tot: 242.53036470352671\n",
      "i: 3250, loss_tot: 235.186609955905\n",
      "i: 3500, loss_tot: 240.67808114275337\n",
      "i: 3750, loss_tot: 219.18794876560568\n",
      "i: 4000, loss_tot: 186.38467956393959\n",
      "i: 4250, loss_tot: 198.93314678423107\n",
      "i: 4500, loss_tot: 224.8088186214678\n",
      "i: 4750, loss_tot: 216.3698060000874\n",
      "i: 5000, loss_tot: 212.80465302586555\n",
      "i: 5250, loss_tot: 223.1398355620727\n",
      "i: 5500, loss_tot: 237.8537559848884\n",
      "i: 5750, loss_tot: 226.61613926644438\n",
      "i: 6000, loss_tot: 265.59703569304196\n",
      "i: 6250, loss_tot: 224.47560287389905\n",
      "i: 6500, loss_tot: 297.88556430969385\n",
      "i: 6750, loss_tot: 186.99941098917276\n",
      "i: 7000, loss_tot: 204.76678121386095\n",
      "i: 7250, loss_tot: 246.71883002735674\n",
      "i: 7500, loss_tot: 233.4004320543818\n",
      "i: 7750, loss_tot: 203.10391250408023\n",
      "i: 8000, loss_tot: 170.15709351617727\n",
      "i: 8250, loss_tot: 224.84590063996149\n",
      "i: 8500, loss_tot: 250.47835696969182\n",
      "i: 8750, loss_tot: 217.2171918298304\n",
      "i: 9000, loss_tot: 229.82916888531298\n",
      "i: 9250, loss_tot: 230.05661200765056\n",
      "i: 9500, loss_tot: 244.53733078234364\n",
      "i: 9750, loss_tot: 242.32096510300414\n",
      "i: 10000, loss_tot: 330.8627153810859\n",
      "i: 10250, loss_tot: 254.08530973944812\n",
      "i: 10500, loss_tot: 251.44986084265634\n",
      "i: 10750, loss_tot: 235.15246453993024\n",
      "i: 11000, loss_tot: 207.93229394255206\n",
      "i: 11250, loss_tot: 233.55542871970684\n",
      "i: 11500, loss_tot: 237.35980522368104\n",
      "i: 11750, loss_tot: 264.6140964156389\n",
      "i: 12000, loss_tot: 258.118587681409\n",
      "i: 12250, loss_tot: 266.69620441174135\n",
      "i: 12500, loss_tot: 223.57887627720834\n",
      "i: 12750, loss_tot: 241.49155550726223\n",
      "i: 13000, loss_tot: 226.28697252940853\n",
      "i: 13250, loss_tot: 247.2037405377999\n",
      "i: 13500, loss_tot: 215.8666739743203\n",
      "i: 13750, loss_tot: 210.36133434167598\n",
      "i: 14000, loss_tot: 217.3601507273072\n",
      "i: 14250, loss_tot: 269.67580231912433\n",
      "i: 14500, loss_tot: 196.10660078856162\n",
      "i: 14750, loss_tot: 221.91707980103791\n",
      "i: 15000, loss_tot: 271.35856190728026\n",
      "i: 15250, loss_tot: 182.00257810184732\n",
      "i: 15500, loss_tot: 251.18974841156276\n",
      "i: 15750, loss_tot: 190.35864419050515\n",
      "i: 16000, loss_tot: 170.17544946428853\n",
      "i: 16250, loss_tot: 239.4285093191918\n",
      "i: 16500, loss_tot: 218.38998835027218\n",
      "i: 16750, loss_tot: 257.608986315988\n",
      "i: 17000, loss_tot: 257.4131903667422\n",
      "i: 17250, loss_tot: 228.76449960857164\n",
      "i: 17500, loss_tot: 234.98276784421876\n",
      "i: 17750, loss_tot: 217.29732146232388\n",
      "i: 18000, loss_tot: 245.22067631012294\n",
      "i: 18250, loss_tot: 204.0519412074401\n",
      "i: 18500, loss_tot: 241.16601505101892\n",
      "i: 18750, loss_tot: 247.67592098033987\n",
      "i: 19000, loss_tot: 256.8566047382355\n",
      "i: 19250, loss_tot: 216.40362419497222\n",
      "i: 19500, loss_tot: 228.02683677369495\n",
      "i: 19750, loss_tot: 224.8003610223951\n",
      "i: 20000, loss_tot: 190.10899912514725\n",
      "i: 20250, loss_tot: 266.17006560152396\n",
      "i: 20500, loss_tot: 229.00846689349973\n",
      "i: 20750, loss_tot: 221.5085078223096\n",
      "i: 21000, loss_tot: 240.10707653371617\n",
      "i: 21250, loss_tot: 217.10591009149329\n",
      "i: 21500, loss_tot: 220.7759878552705\n",
      "i: 21750, loss_tot: 234.6699906328926\n",
      "i: 22000, loss_tot: 205.02489537724293\n",
      "i: 22250, loss_tot: 241.98781102087815\n",
      "i: 22500, loss_tot: 252.0000972621236\n",
      "i: 22750, loss_tot: 217.6343707106635\n",
      "i: 23000, loss_tot: 216.09471770672127\n",
      "i: 23250, loss_tot: 261.27870649782943\n",
      "i: 23500, loss_tot: 209.56304685052484\n",
      "i: 23750, loss_tot: 264.0394220885262\n",
      "i: 24000, loss_tot: 260.9901409409568\n",
      "i: 24250, loss_tot: 241.45884370762855\n",
      "i: 24500, loss_tot: 262.61953593131153\n",
      "i: 24750, loss_tot: 251.52532491788267\n",
      "i: 25000, loss_tot: 275.3407194362581\n",
      "i: 25250, loss_tot: 233.00358003795148\n",
      "i: 25500, loss_tot: 237.89307227638784\n",
      "i: 25750, loss_tot: 197.26162103623153\n",
      "i: 26000, loss_tot: 228.44412799252197\n",
      "i: 26250, loss_tot: 200.28253452753648\n",
      "i: 26500, loss_tot: 217.4586594296433\n",
      "i: 26750, loss_tot: 249.32670215781778\n",
      "i: 27000, loss_tot: 220.14297238284723\n",
      "i: 27250, loss_tot: 223.1153957863711\n",
      "i: 27500, loss_tot: 217.58405953062697\n",
      "i: 27750, loss_tot: 235.19879159823992\n",
      "i: 28000, loss_tot: 230.47527885383926\n",
      "i: 28250, loss_tot: 225.92236824463123\n",
      "i: 28500, loss_tot: 191.61394779731287\n",
      "i: 28750, loss_tot: 306.5465461884532\n",
      "i: 29000, loss_tot: 250.00623066298664\n",
      "i: 29250, loss_tot: 221.33050852373242\n",
      "i: 29500, loss_tot: 194.882852584552\n",
      "i: 29750, loss_tot: 259.17375659219454\n",
      "i: 30000, loss_tot: 209.88356416762807\n",
      "i: 30250, loss_tot: 241.31820357028394\n",
      "i: 30500, loss_tot: 209.5107026148541\n",
      "i: 30750, loss_tot: 286.3695455757901\n",
      "i: 31000, loss_tot: 223.32428356133403\n",
      "i: 31250, loss_tot: 249.64555546207353\n",
      "i: 31500, loss_tot: 265.4148859592108\n",
      "i: 31750, loss_tot: 209.665234106821\n",
      "i: 32000, loss_tot: 246.35956627988256\n",
      "i: 32250, loss_tot: 231.00316651353612\n",
      "i: 32500, loss_tot: 270.1633623325452\n",
      "i: 32750, loss_tot: 209.21225154744462\n",
      "i: 33000, loss_tot: 212.17658394580707\n",
      "i: 33250, loss_tot: 215.94711938634515\n",
      "i: 33500, loss_tot: 236.52627423082944\n",
      "i: 33750, loss_tot: 220.04192159382626\n",
      "i: 34000, loss_tot: 238.55684833683074\n",
      "i: 34250, loss_tot: 220.9045957928989\n",
      "i: 34500, loss_tot: 220.9536317704711\n",
      "i: 34750, loss_tot: 195.90643401823937\n",
      "i: 35000, loss_tot: 179.7529651608295\n",
      "i: 35250, loss_tot: 295.04120375893314\n",
      "i: 35500, loss_tot: 203.17474926579743\n",
      "i: 35750, loss_tot: 251.34275055364705\n",
      "i: 36000, loss_tot: 180.5559129697457\n",
      "i: 36250, loss_tot: 232.33939988921395\n",
      "i: 36500, loss_tot: 242.57072888400407\n",
      "i: 36750, loss_tot: 218.18421070099808\n",
      "i: 37000, loss_tot: 231.4728157820506\n",
      "i: 37250, loss_tot: 230.30341335889884\n",
      "i: 37500, loss_tot: 223.97747691299767\n",
      "i: 37750, loss_tot: 189.872499552276\n",
      "i: 38000, loss_tot: 242.72498881221284\n",
      "i: 38250, loss_tot: 194.95076287714764\n",
      "i: 38500, loss_tot: 216.90043233218137\n",
      "i: 38750, loss_tot: 255.43171985156835\n",
      "i: 39000, loss_tot: 262.07942011864856\n",
      "i: 39250, loss_tot: 199.36815579038114\n",
      "i: 39500, loss_tot: 250.62155781350913\n",
      "i: 39750, loss_tot: 246.06688912119716\n",
      "i: 40000, loss_tot: 280.9572484994121\n",
      "i: 40250, loss_tot: 243.3002574686683\n",
      "i: 40500, loss_tot: 283.0734401305905\n",
      "i: 40750, loss_tot: 222.60774842744692\n",
      "i: 41000, loss_tot: 228.65495840288233\n",
      "i: 41250, loss_tot: 231.27434140435835\n",
      "i: 41500, loss_tot: 265.80075754904595\n",
      "i: 41750, loss_tot: 189.08947219384135\n",
      "i: 42000, loss_tot: 169.80027003892465\n",
      "i: 42250, loss_tot: 259.36933903468775\n",
      "i: 42500, loss_tot: 215.89465034133056\n",
      "i: 42750, loss_tot: 212.35743088188582\n",
      "i: 43000, loss_tot: 212.18709111690754\n",
      "i: 43250, loss_tot: 262.35404923793396\n",
      "i: 43500, loss_tot: 269.97290106477215\n",
      "i: 43750, loss_tot: 258.130139722731\n",
      "i: 44000, loss_tot: 220.9444861463993\n",
      "i: 44250, loss_tot: 204.55931636246854\n",
      "i: 44500, loss_tot: 221.64628434362822\n",
      "i: 44750, loss_tot: 215.88452436291612\n",
      "i: 45000, loss_tot: 293.37590633363\n",
      "i: 45250, loss_tot: 227.7475100954063\n",
      "i: 45500, loss_tot: 225.43253900738432\n",
      "i: 45750, loss_tot: 252.77623910821976\n",
      "i: 46000, loss_tot: 239.08089662625454\n",
      "i: 46250, loss_tot: 242.59389941876287\n",
      "i: 46500, loss_tot: 232.89227507947012\n",
      "i: 46750, loss_tot: 220.54922605635133\n",
      "i: 47000, loss_tot: 230.05719538303208\n",
      "i: 47250, loss_tot: 250.11644792651293\n",
      "i: 47500, loss_tot: 176.0327116855979\n",
      "i: 47750, loss_tot: 225.27334789801856\n",
      "i: 48000, loss_tot: 250.4494854375666\n",
      "i: 48250, loss_tot: 244.78037288517692\n",
      "i: 48500, loss_tot: 264.3363612220995\n",
      "i: 48750, loss_tot: 239.0441606093943\n",
      "i: 49000, loss_tot: 213.97743781452067\n",
      "i: 49250, loss_tot: 273.40703608407637\n",
      "i: 49500, loss_tot: 246.20373162109405\n",
      "i: 49750, loss_tot: 237.01121426478028\n",
      "i: 50000, loss_tot: 304.06789967799557\n",
      "i: 50250, loss_tot: 226.1899797041528\n",
      "i: 50500, loss_tot: 191.19078542952192\n",
      "i: 50750, loss_tot: 252.47908831872977\n",
      "i: 51000, loss_tot: 182.79771187119186\n",
      "i: 51250, loss_tot: 176.38829332007094\n",
      "i: 51500, loss_tot: 227.19410836128517\n",
      "i: 51750, loss_tot: 226.3811282806471\n",
      "i: 52000, loss_tot: 204.6093180753058\n",
      "i: 52250, loss_tot: 246.4690974027873\n",
      "i: 52500, loss_tot: 267.89192428819837\n",
      "i: 52750, loss_tot: 230.51792571021244\n",
      "i: 53000, loss_tot: 189.71427911748643\n",
      "i: 53250, loss_tot: 210.0812704742141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 53500, loss_tot: 196.63222378241247\n",
      "i: 53750, loss_tot: 243.57906349463389\n",
      "i: 54000, loss_tot: 194.37196313572232\n",
      "i: 54250, loss_tot: 187.90204194065183\n",
      "i: 54500, loss_tot: 205.80359384701586\n",
      "i: 54750, loss_tot: 183.49203126790235\n",
      "i: 55000, loss_tot: 218.31527184729464\n",
      "i: 55250, loss_tot: 207.90454569417983\n",
      "i: 55500, loss_tot: 223.5672454131278\n",
      "i: 55750, loss_tot: 206.1351486755861\n",
      "i: 56000, loss_tot: 223.97713837882503\n",
      "i: 56250, loss_tot: 197.50786902117542\n",
      "i: 56500, loss_tot: 239.7570540627511\n",
      "i: 56750, loss_tot: 244.33578633099793\n",
      "i: 57000, loss_tot: 277.9544284191914\n",
      "i: 57250, loss_tot: 230.16044629218058\n",
      "i: 57500, loss_tot: 264.22975816995836\n",
      "i: 57750, loss_tot: 277.35292240699755\n",
      "i: 58000, loss_tot: 239.65496104590594\n",
      "i: 58250, loss_tot: 181.84221364041093\n",
      "i: 58500, loss_tot: 244.8915189059172\n",
      "i: 58750, loss_tot: 219.90682541863293\n",
      "i: 59000, loss_tot: 193.96386425940784\n",
      "i: 59250, loss_tot: 265.65226422782985\n",
      "i: 59500, loss_tot: 196.30504738237244\n",
      "i: 59750, loss_tot: 229.37944929825565\n",
      "i: 60000, loss_tot: 208.13048482225742\n",
      "i: 60250, loss_tot: 297.5279914944386\n",
      "i: 60500, loss_tot: 234.4985612359643\n",
      "i: 60750, loss_tot: 220.87709319875574\n",
      "i: 61000, loss_tot: 170.934855857715\n",
      "i: 61250, loss_tot: 236.9501273452514\n",
      "i: 61500, loss_tot: 196.6687614760606\n",
      "i: 61750, loss_tot: 237.54747586756946\n",
      "i: 62000, loss_tot: 255.19493571224623\n",
      "i: 62250, loss_tot: 237.04557410242035\n",
      "i: 62500, loss_tot: 189.9598758696532\n",
      "i: 62750, loss_tot: 213.27117332065478\n",
      "i: 63000, loss_tot: 214.9524184045114\n",
      "i: 63250, loss_tot: 208.03472707002425\n",
      "i: 63500, loss_tot: 180.00246515611187\n",
      "i: 63750, loss_tot: 223.32177957005072\n",
      "i: 64000, loss_tot: 166.1389035115391\n",
      "i: 64250, loss_tot: 219.634291883228\n",
      "i: 64500, loss_tot: 229.92728775057475\n",
      "i: 64750, loss_tot: 195.478080203305\n",
      "i: 65000, loss_tot: 204.40586018256843\n",
      "i: 65250, loss_tot: 214.48186951785348\n",
      "i: 65500, loss_tot: 223.93594230208546\n",
      "i: 65750, loss_tot: 232.8483770296257\n",
      "i: 66000, loss_tot: 227.16513105626217\n",
      "i: 66250, loss_tot: 239.11304934724933\n",
      "i: 66500, loss_tot: 245.90635336458683\n",
      "i: 66750, loss_tot: 234.60260511610193\n",
      "i: 67000, loss_tot: 223.4926905078534\n",
      "i: 67250, loss_tot: 203.16744851190597\n",
      "i: 67500, loss_tot: 186.09673245059793\n",
      "i: 67750, loss_tot: 223.3457271405415\n",
      "i: 68000, loss_tot: 244.93139222364871\n",
      "i: 68250, loss_tot: 225.3679199431138\n",
      "i: 68500, loss_tot: 248.6378832607111\n",
      "i: 68750, loss_tot: 243.06365782407113\n",
      "i: 69000, loss_tot: 216.61342613973656\n",
      "i: 69250, loss_tot: 241.0960639483668\n",
      "i: 69500, loss_tot: 224.89675299192177\n",
      "i: 69750, loss_tot: 192.41738197729225\n",
      "i: 70000, loss_tot: 248.0932133386653\n",
      "i: 70250, loss_tot: 206.02147459639002\n",
      "i: 70500, loss_tot: 237.83052488973829\n",
      "i: 70750, loss_tot: 202.24127331554425\n",
      "i: 71000, loss_tot: 202.99761806947646\n",
      "i: 71250, loss_tot: 180.3429376723524\n",
      "i: 71500, loss_tot: 263.15499517459887\n",
      "i: 71750, loss_tot: 255.45654595040716\n",
      "i: 72000, loss_tot: 224.75985079159028\n",
      "i: 72250, loss_tot: 229.09403164808637\n",
      "i: 72500, loss_tot: 223.74429531148635\n",
      "i: 72750, loss_tot: 237.60178426022176\n",
      "i: 73000, loss_tot: 217.35808432683427\n",
      "i: 73250, loss_tot: 227.3305753027089\n",
      "i: 73500, loss_tot: 190.81327052353416\n",
      "i: 73750, loss_tot: 271.8286103597816\n",
      "i: 74000, loss_tot: 237.39111414489685\n",
      "i: 74250, loss_tot: 229.7016458747559\n",
      "i: 74500, loss_tot: 265.2055911072134\n",
      "i: 74750, loss_tot: 284.93189263989683\n",
      "i: 75000, loss_tot: 270.0036613851134\n",
      "i: 75250, loss_tot: 202.28186176608813\n",
      "i: 75500, loss_tot: 283.09590205566025\n",
      "i: 75750, loss_tot: 197.2976016090717\n",
      "i: 76000, loss_tot: 189.78463490978814\n",
      "i: 76250, loss_tot: 209.17239788526612\n",
      "i: 76500, loss_tot: 243.98274129213664\n",
      "i: 76750, loss_tot: 189.4776451864466\n",
      "i: 77000, loss_tot: 229.3143252299726\n",
      "i: 77250, loss_tot: 237.69367537645624\n",
      "i: 77500, loss_tot: 197.96239686012268\n",
      "i: 77750, loss_tot: 170.59842114281244\n",
      "i: 78000, loss_tot: 238.12525929894298\n",
      "i: 78250, loss_tot: 249.314720857325\n",
      "i: 78500, loss_tot: 208.77820376870687\n",
      "i: 78750, loss_tot: 172.73410696198786\n",
      "i: 79000, loss_tot: 249.4634092860983\n",
      "i: 79250, loss_tot: 214.0479071523715\n",
      "i: 79500, loss_tot: 203.42935660511256\n",
      "i: 79750, loss_tot: 192.58074235151756\n",
      "i: 80000, loss_tot: 192.11030631459317\n",
      "i: 80250, loss_tot: 241.54478565585114\n",
      "i: 80500, loss_tot: 226.74707322127688\n",
      "i: 80750, loss_tot: 193.178791303318\n",
      "i: 81000, loss_tot: 178.25565802522007\n",
      "i: 81250, loss_tot: 259.5495344965991\n",
      "i: 81500, loss_tot: 257.47820027683633\n",
      "i: 81750, loss_tot: 225.90389554804526\n",
      "i: 82000, loss_tot: 190.99714528862853\n",
      "i: 82250, loss_tot: 251.39609000099097\n",
      "i: 82500, loss_tot: 209.70861484551796\n",
      "i: 82750, loss_tot: 226.9031640693755\n",
      "i: 83000, loss_tot: 195.12906857239636\n",
      "i: 83250, loss_tot: 222.5215187538945\n",
      "i: 83500, loss_tot: 254.88312792464774\n",
      "i: 83750, loss_tot: 251.29443337646313\n",
      "i: 84000, loss_tot: 254.05156817104668\n",
      "i: 84250, loss_tot: 238.77287283178418\n",
      "i: 84500, loss_tot: 203.3044865136384\n",
      "i: 84750, loss_tot: 253.49556074563415\n",
      "i: 85000, loss_tot: 220.8519929384021\n",
      "i: 85250, loss_tot: 230.99765523884446\n",
      "i: 85500, loss_tot: 228.37416612280532\n",
      "i: 85750, loss_tot: 239.38312704813433\n",
      "i: 86000, loss_tot: 210.95915934560355\n",
      "i: 86250, loss_tot: 230.9580172683217\n",
      "i: 86500, loss_tot: 227.00964940897654\n",
      "i: 86750, loss_tot: 240.90491609670104\n",
      "i: 87000, loss_tot: 209.87732411567586\n",
      "i: 87250, loss_tot: 245.61280870952643\n",
      "i: 87500, loss_tot: 214.1532075026445\n",
      "i: 87750, loss_tot: 197.3056006911397\n",
      "i: 88000, loss_tot: 225.60195736153983\n",
      "i: 88250, loss_tot: 195.82497970013225\n",
      "i: 88500, loss_tot: 278.0051020965946\n",
      "i: 88750, loss_tot: 218.69054614132503\n",
      "i: 89000, loss_tot: 217.97223736752989\n",
      "i: 89250, loss_tot: 256.58763491379096\n",
      "i: 89500, loss_tot: 190.21449843824306\n",
      "i: 89750, loss_tot: 303.68730964872043\n",
      "i: 90000, loss_tot: 158.99600298043342\n",
      "i: 90250, loss_tot: 208.90918068798064\n",
      "i: 90500, loss_tot: 235.04267398414203\n",
      "i: 90750, loss_tot: 253.76397771753705\n",
      "i: 91000, loss_tot: 241.3941383224353\n",
      "i: 91250, loss_tot: 186.7307614137605\n",
      "i: 91500, loss_tot: 192.83764673461206\n",
      "i: 91750, loss_tot: 256.47497634928555\n",
      "i: 92000, loss_tot: 194.62871123700867\n",
      "i: 92250, loss_tot: 223.65729702463375\n",
      "i: 92500, loss_tot: 201.82928324351903\n",
      "i: 92750, loss_tot: 189.3806698843697\n",
      "i: 93000, loss_tot: 242.2806590733042\n",
      "i: 93250, loss_tot: 198.60115969346836\n",
      "i: 93500, loss_tot: 258.7711408738792\n",
      "i: 93750, loss_tot: 270.7253822441498\n",
      "i: 94000, loss_tot: 229.54937617740768\n",
      "i: 94250, loss_tot: 256.38699469891844\n",
      "i: 94500, loss_tot: 229.24776501776185\n",
      "i: 94750, loss_tot: 243.57349575021203\n",
      "i: 95000, loss_tot: 253.72520453622886\n",
      "i: 95250, loss_tot: 220.39638238058862\n",
      "i: 95500, loss_tot: 194.12949805251787\n",
      "i: 95750, loss_tot: 223.77365573131246\n",
      "i: 96000, loss_tot: 247.4360497152945\n",
      "i: 96250, loss_tot: 210.11902296018553\n",
      "i: 96500, loss_tot: 260.7837261185492\n",
      "i: 96750, loss_tot: 228.51254191508525\n",
      "i: 97000, loss_tot: 202.2610071682001\n",
      "i: 97250, loss_tot: 220.4774404875282\n",
      "i: 97500, loss_tot: 240.3147248460863\n",
      "i: 97750, loss_tot: 245.65066548175645\n",
      "i: 98000, loss_tot: 183.60498312201685\n",
      "i: 98250, loss_tot: 207.87602284980127\n",
      "i: 98500, loss_tot: 207.072399108152\n",
      "i: 98750, loss_tot: 282.54931986220197\n",
      "i: 99000, loss_tot: 191.72666710225192\n",
      "i: 99250, loss_tot: 249.78841773802094\n",
      "i: 99500, loss_tot: 233.99732124890798\n",
      "i: 99750, loss_tot: 292.73849682290717\n",
      "i: 100000, loss_tot: 229.73808926188386\n",
      "i: 100250, loss_tot: 245.98843543486436\n",
      "i: 100500, loss_tot: 259.6671019640134\n",
      "i: 100750, loss_tot: 219.87620032087202\n",
      "i: 101000, loss_tot: 202.46353336854662\n",
      "i: 101250, loss_tot: 209.60286398792522\n",
      "i: 101500, loss_tot: 184.7661358043668\n",
      "i: 101750, loss_tot: 198.90888875857812\n",
      "i: 102000, loss_tot: 227.60737246690965\n",
      "i: 102250, loss_tot: 202.52649359042837\n",
      "i: 102500, loss_tot: 210.8824160813447\n",
      "i: 102750, loss_tot: 199.63180152317625\n",
      "i: 103000, loss_tot: 226.82125076854186\n",
      "i: 103250, loss_tot: 221.71697797958822\n",
      "i: 103500, loss_tot: 208.57641974604456\n",
      "i: 103750, loss_tot: 223.7671939734556\n",
      "i: 104000, loss_tot: 234.4849843257203\n",
      "i: 104250, loss_tot: 249.92756036043866\n",
      "i: 104500, loss_tot: 210.7924134492146\n",
      "i: 104750, loss_tot: 231.15342492254192\n",
      "i: 105000, loss_tot: 239.4508895152441\n",
      "i: 105250, loss_tot: 267.90717571050163\n",
      "i: 105500, loss_tot: 227.88270557811848\n",
      "i: 105750, loss_tot: 257.8567006810375\n",
      "i: 106000, loss_tot: 196.21344805474365\n",
      "i: 106250, loss_tot: 211.15620000237192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 106500, loss_tot: 253.46463328302255\n",
      "i: 106750, loss_tot: 232.4778765048599\n",
      "i: 107000, loss_tot: 237.55550339414492\n",
      "i: 107250, loss_tot: 199.33844076780215\n",
      "i: 107500, loss_tot: 227.90935976129012\n",
      "i: 107750, loss_tot: 212.662644226775\n",
      "i: 108000, loss_tot: 200.689330088367\n",
      "i: 108250, loss_tot: 204.69631796650035\n",
      "i: 108500, loss_tot: 213.89729173250518\n",
      "i: 108750, loss_tot: 214.47074522374896\n",
      "i: 109000, loss_tot: 216.17597608039156\n",
      "i: 109250, loss_tot: 261.8982407411188\n",
      "i: 109500, loss_tot: 230.42022186422022\n",
      "i: 109750, loss_tot: 194.53987273549194\n",
      "i: 110000, loss_tot: 242.0785566044299\n",
      "i: 110250, loss_tot: 186.47825439905458\n",
      "i: 110500, loss_tot: 218.49419141830526\n",
      "i: 110750, loss_tot: 232.53813643434552\n",
      "i: 111000, loss_tot: 180.18275376212785\n",
      "i: 111250, loss_tot: 258.1342973970529\n",
      "i: 111500, loss_tot: 221.78341306778603\n",
      "i: 111750, loss_tot: 185.02807533215963\n",
      "i: 112000, loss_tot: 186.2398552709166\n",
      "i: 112250, loss_tot: 226.5505964107241\n",
      "i: 112500, loss_tot: 251.79410597045907\n",
      "i: 112750, loss_tot: 213.9100148857571\n",
      "i: 113000, loss_tot: 204.39007204702125\n",
      "i: 113250, loss_tot: 235.68801662814803\n",
      "i: 113500, loss_tot: 217.11233410734326\n",
      "i: 113750, loss_tot: 198.13931420197179\n",
      "i: 114000, loss_tot: 207.5126512716798\n",
      "i: 114250, loss_tot: 232.72766304932694\n",
      "i: 114500, loss_tot: 249.2578147313681\n",
      "i: 114750, loss_tot: 221.0828573130183\n",
      "i: 115000, loss_tot: 253.77190610396093\n",
      "i: 115250, loss_tot: 219.77561928350713\n",
      "i: 115500, loss_tot: 229.5601235224004\n",
      "i: 115750, loss_tot: 217.58099041874056\n",
      "i: 116000, loss_tot: 193.6184881928208\n",
      "i: 116250, loss_tot: 215.47346566936983\n",
      "i: 116500, loss_tot: 195.5572848928623\n",
      "i: 116750, loss_tot: 232.92977304027184\n",
      "i: 117000, loss_tot: 285.73285933319016\n",
      "i: 117250, loss_tot: 253.66489128184506\n",
      "i: 117500, loss_tot: 198.98156856399495\n",
      "i: 117750, loss_tot: 272.0203648358211\n",
      "i: 118000, loss_tot: 211.0239828325878\n",
      "i: 118250, loss_tot: 202.00881650096446\n",
      "i: 118500, loss_tot: 165.68131000235792\n",
      "i: 118750, loss_tot: 158.3304019219277\n",
      "i: 119000, loss_tot: 254.6381559070501\n",
      "i: 119250, loss_tot: 241.77406178371982\n",
      "i: 119500, loss_tot: 195.30605017342606\n",
      "i: 119750, loss_tot: 286.1182571133226\n",
      "i: 120000, loss_tot: 240.2197119939886\n",
      "i: 120250, loss_tot: 253.43062536315992\n",
      "i: 120500, loss_tot: 206.71298879887675\n",
      "i: 120750, loss_tot: 212.6737181827222\n",
      "i: 121000, loss_tot: 252.6557164726715\n",
      "i: 121250, loss_tot: 247.74801023817622\n",
      "i: 121500, loss_tot: 204.85680389515124\n",
      "i: 121750, loss_tot: 203.1023687699018\n",
      "i: 122000, loss_tot: 257.2015115248211\n",
      "i: 122250, loss_tot: 201.12193689060908\n",
      "i: 122500, loss_tot: 241.89564059229144\n",
      "i: 122750, loss_tot: 285.93431043837785\n",
      "i: 123000, loss_tot: 220.54195074980413\n",
      "i: 123250, loss_tot: 224.052126615981\n",
      "i: 123500, loss_tot: 220.84935641376185\n",
      "i: 123750, loss_tot: 267.713614825901\n",
      "i: 124000, loss_tot: 240.913796503509\n",
      "i: 124250, loss_tot: 259.48470715307195\n",
      "i: 124500, loss_tot: 201.0262962093635\n",
      "i: 124750, loss_tot: 192.6806469226051\n",
      "i: 125000, loss_tot: 203.08721158076295\n",
      "i: 125250, loss_tot: 187.2413273915089\n",
      "i: 125500, loss_tot: 162.84023569932674\n",
      "i: 125750, loss_tot: 229.38379665062843\n",
      "i: 126000, loss_tot: 212.0043646130315\n",
      "i: 126250, loss_tot: 224.11098028870896\n",
      "i: 126500, loss_tot: 243.9963339143964\n",
      "i: 126750, loss_tot: 221.51391295339843\n",
      "i: 127000, loss_tot: 205.13191016637037\n",
      "i: 127250, loss_tot: 199.40961584191768\n",
      "i: 127500, loss_tot: 245.23949558567256\n",
      "i: 127750, loss_tot: 219.14203180741518\n",
      "i: 128000, loss_tot: 229.78288601453417\n",
      "i: 128250, loss_tot: 210.56250459873422\n",
      "i: 128500, loss_tot: 208.04861208577174\n",
      "i: 128750, loss_tot: 210.0429502687324\n",
      "i: 129000, loss_tot: 185.13042645540088\n",
      "i: 129250, loss_tot: 255.47164334479137\n",
      "i: 129500, loss_tot: 215.5629661220048\n",
      "i: 129750, loss_tot: 200.50258010354136\n",
      "i: 130000, loss_tot: 219.7857261970092\n",
      "i: 130250, loss_tot: 192.38353715031758\n",
      "i: 130500, loss_tot: 237.29912641869603\n",
      "i: 130750, loss_tot: 248.96665529897626\n",
      "i: 131000, loss_tot: 283.649824451867\n",
      "i: 131250, loss_tot: 226.30432553970255\n",
      "i: 131500, loss_tot: 229.63297820011155\n",
      "i: 131750, loss_tot: 246.51177375691145\n",
      "i: 132000, loss_tot: 234.8404677038782\n",
      "i: 132250, loss_tot: 249.06701561885487\n",
      "i: 132500, loss_tot: 232.23610526855103\n",
      "i: 132750, loss_tot: 201.49786835911655\n",
      "i: 133000, loss_tot: 242.81059616662824\n",
      "i: 133250, loss_tot: 211.25723584625405\n",
      "i: 133500, loss_tot: 230.47217967338744\n",
      "i: 133750, loss_tot: 197.80091820754555\n",
      "i: 134000, loss_tot: 242.09035662130395\n",
      "i: 134250, loss_tot: 188.97697135437846\n",
      "i: 134500, loss_tot: 211.61896204541222\n",
      "i: 134750, loss_tot: 195.7941752281392\n",
      "i: 135000, loss_tot: 227.6489290006645\n",
      "i: 135250, loss_tot: 210.20106734832865\n",
      "i: 135500, loss_tot: 200.97734455434346\n",
      "i: 135750, loss_tot: 294.79271366009607\n",
      "i: 136000, loss_tot: 205.6161942499784\n",
      "i: 136250, loss_tot: 198.61267898894846\n",
      "i: 136500, loss_tot: 272.07979326212285\n",
      "i: 136750, loss_tot: 239.2231024892265\n",
      "i: 137000, loss_tot: 205.5482718707109\n",
      "i: 137250, loss_tot: 271.9494995818683\n",
      "i: 137500, loss_tot: 204.72226919132052\n",
      "i: 137750, loss_tot: 267.800305836373\n",
      "i: 138000, loss_tot: 201.01058370103593\n",
      "i: 138250, loss_tot: 218.43876876400142\n",
      "i: 138500, loss_tot: 221.43473167230783\n",
      "i: 138750, loss_tot: 229.82972130775562\n",
      "i: 139000, loss_tot: 237.53926643544344\n",
      "i: 139250, loss_tot: 190.84111956288055\n",
      "i: 139500, loss_tot: 177.16797119172406\n",
      "i: 139750, loss_tot: 197.05622149320553\n",
      "i: 140000, loss_tot: 217.23273596170344\n",
      "i: 140250, loss_tot: 232.18382050033674\n",
      "i: 140500, loss_tot: 227.21680656788288\n",
      "i: 140750, loss_tot: 193.6348400810817\n",
      "i: 141000, loss_tot: 158.35940715287347\n",
      "i: 141250, loss_tot: 232.05173937367275\n",
      "i: 141500, loss_tot: 189.3977901599231\n",
      "i: 141750, loss_tot: 266.26713645064274\n",
      "i: 142000, loss_tot: 232.3907962341851\n",
      "i: 142250, loss_tot: 205.38269023358473\n",
      "i: 142500, loss_tot: 179.96205432184928\n",
      "i: 142750, loss_tot: 226.20397458138135\n",
      "i: 143000, loss_tot: 204.59928622456297\n",
      "i: 143250, loss_tot: 230.3032135732306\n",
      "i: 143500, loss_tot: 266.8797111312355\n",
      "i: 143750, loss_tot: 221.1013671413358\n",
      "i: 144000, loss_tot: 185.25166743064528\n",
      "i: 144250, loss_tot: 245.77772401684896\n",
      "i: 144500, loss_tot: 285.6094029389406\n",
      "i: 144750, loss_tot: 165.62258359494638\n",
      "i: 145000, loss_tot: 289.91892664804817\n",
      "i: 145250, loss_tot: 222.9691439979166\n",
      "i: 145500, loss_tot: 208.05167942215041\n",
      "i: 145750, loss_tot: 199.08783260171708\n",
      "i: 146000, loss_tot: 222.39770084409363\n",
      "i: 146250, loss_tot: 213.93299018704565\n",
      "i: 146500, loss_tot: 196.18248072896466\n",
      "i: 146750, loss_tot: 223.03056217585225\n",
      "i: 147000, loss_tot: 197.77745464346998\n",
      "i: 147250, loss_tot: 209.52077436621445\n",
      "i: 147500, loss_tot: 275.61470198447785\n",
      "i: 147750, loss_tot: 271.8906280524284\n",
      "i: 148000, loss_tot: 200.9413778866688\n",
      "i: 148250, loss_tot: 217.62702235652134\n",
      "i: 148500, loss_tot: 185.81650133738702\n",
      "i: 148750, loss_tot: 211.5047506855738\n",
      "i: 149000, loss_tot: 241.05131901437744\n",
      "i: 149250, loss_tot: 181.03093786284836\n",
      "i: 149500, loss_tot: 192.86862344442866\n",
      "i: 149750, loss_tot: 228.76950845651677\n",
      "i: 150000, loss_tot: 201.5343831415029\n",
      "i: 150250, loss_tot: 199.07877135522043\n",
      "i: 150500, loss_tot: 255.76242644940328\n",
      "i: 150750, loss_tot: 187.25058617099828\n",
      "i: 151000, loss_tot: 239.55162576881992\n",
      "i: 151250, loss_tot: 214.07794887545765\n",
      "i: 151500, loss_tot: 182.94862942675246\n",
      "i: 151750, loss_tot: 279.73650200026583\n",
      "i: 152000, loss_tot: 200.45321993408726\n",
      "i: 152250, loss_tot: 217.73489797280112\n",
      "i: 152500, loss_tot: 233.15182360575892\n",
      "i: 152750, loss_tot: 245.6520612272294\n",
      "i: 153000, loss_tot: 206.041415424178\n",
      "i: 153250, loss_tot: 257.3979140477232\n",
      "i: 153500, loss_tot: 223.8862410548793\n",
      "i: 153750, loss_tot: 209.12944653942716\n",
      "i: 154000, loss_tot: 188.59380614696363\n",
      "i: 154250, loss_tot: 194.24996933004127\n",
      "i: 154500, loss_tot: 223.10420509932098\n",
      "i: 154750, loss_tot: 211.55291085279555\n",
      "i: 155000, loss_tot: 230.075918377568\n",
      "i: 155250, loss_tot: 162.62056704161682\n",
      "i: 155500, loss_tot: 254.80562928006862\n",
      "i: 155750, loss_tot: 181.2739388268744\n",
      "i: 156000, loss_tot: 199.06752779548822\n",
      "i: 156250, loss_tot: 171.23376744360314\n",
      "i: 156500, loss_tot: 189.22132167432198\n",
      "i: 156750, loss_tot: 214.21434866540338\n",
      "i: 157000, loss_tot: 221.70034796495383\n",
      "i: 157250, loss_tot: 249.71268516013407\n",
      "i: 157500, loss_tot: 227.59528259293663\n",
      "i: 157750, loss_tot: 184.4661198533412\n",
      "i: 158000, loss_tot: 192.31474502359066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 158250, loss_tot: 273.79737309615825\n",
      "i: 158500, loss_tot: 248.39857039453753\n",
      "i: 158750, loss_tot: 208.63610787773302\n",
      "i: 159000, loss_tot: 316.11544759259186\n",
      "i: 159250, loss_tot: 193.68333580251667\n",
      "i: 159500, loss_tot: 210.07463427734382\n",
      "i: 159750, loss_tot: 246.67457502349106\n",
      "i: 160000, loss_tot: 253.46721022756654\n",
      "i: 160250, loss_tot: 205.53194766984322\n",
      "i: 160500, loss_tot: 191.24232087644734\n",
      "i: 160750, loss_tot: 218.69996197019486\n",
      "i: 161000, loss_tot: 228.9686958142108\n",
      "i: 161250, loss_tot: 219.2850498936884\n",
      "i: 161500, loss_tot: 264.9396471658862\n",
      "i: 161750, loss_tot: 244.04483930122223\n",
      "i: 162000, loss_tot: 271.2400824238178\n",
      "i: 162250, loss_tot: 285.34641656265376\n",
      "i: 162500, loss_tot: 214.04839830499157\n",
      "i: 162750, loss_tot: 192.1898056708055\n",
      "i: 163000, loss_tot: 197.22354000536316\n",
      "i: 163250, loss_tot: 220.59410395575352\n",
      "i: 163500, loss_tot: 252.3521079925273\n",
      "i: 163750, loss_tot: 270.7512111997148\n",
      "i: 164000, loss_tot: 228.71704006306743\n",
      "i: 164250, loss_tot: 202.03034034657657\n",
      "i: 164500, loss_tot: 276.02622702153985\n",
      "i: 164750, loss_tot: 262.2996493486851\n",
      "i: 165000, loss_tot: 227.11938638121825\n",
      "i: 165250, loss_tot: 254.49128885797225\n",
      "i: 165500, loss_tot: 224.04162813853765\n",
      "i: 165750, loss_tot: 187.67824874711368\n",
      "i: 166000, loss_tot: 169.8552553584239\n",
      "i: 166250, loss_tot: 200.72721013808675\n",
      "i: 166500, loss_tot: 254.92835980535878\n",
      "i: 166750, loss_tot: 235.03317472914858\n",
      "i: 167000, loss_tot: 214.01820811335813\n",
      "i: 167250, loss_tot: 257.5666829972462\n",
      "i: 167500, loss_tot: 227.7357765571773\n",
      "i: 167750, loss_tot: 238.59643906676473\n",
      "i: 168000, loss_tot: 257.8399777918437\n",
      "i: 168250, loss_tot: 198.98795339621756\n",
      "i: 168500, loss_tot: 202.51052209757654\n",
      "i: 168750, loss_tot: 245.45527253868684\n",
      "i: 169000, loss_tot: 273.7819676553689\n",
      "i: 169250, loss_tot: 219.49545948801736\n",
      "i: 169500, loss_tot: 216.95706841720465\n",
      "i: 169750, loss_tot: 193.44925398940816\n",
      "i: 170000, loss_tot: 225.16547617459088\n",
      "i: 170250, loss_tot: 242.1804280941387\n",
      "i: 170500, loss_tot: 211.24313978152816\n",
      "i: 170750, loss_tot: 237.11880437689484\n",
      "i: 171000, loss_tot: 193.866277512652\n",
      "i: 171250, loss_tot: 202.48739162257888\n",
      "i: 171500, loss_tot: 251.3960598158245\n",
      "i: 171750, loss_tot: 217.10656564548088\n",
      "i: 172000, loss_tot: 225.71657970462576\n",
      "i: 172250, loss_tot: 224.0560868007899\n",
      "i: 172500, loss_tot: 176.82735823303665\n",
      "i: 172750, loss_tot: 207.62522302295554\n",
      "i: 173000, loss_tot: 254.2700831998745\n",
      "i: 173250, loss_tot: 231.17257766820023\n",
      "i: 173500, loss_tot: 191.12341223364908\n",
      "i: 173750, loss_tot: 246.93402256230965\n",
      "i: 174000, loss_tot: 242.85381905090514\n",
      "i: 174250, loss_tot: 223.51990891775583\n",
      "i: 174500, loss_tot: 208.87630643455313\n",
      "i: 174750, loss_tot: 242.8694219147609\n",
      "i: 175000, loss_tot: 190.77916569107813\n",
      "i: 175250, loss_tot: 215.43148527468088\n",
      "i: 175500, loss_tot: 234.87712475093315\n",
      "i: 175750, loss_tot: 230.75738056293463\n",
      "i: 176000, loss_tot: 244.48741891470272\n",
      "i: 176250, loss_tot: 181.48766703891204\n",
      "i: 176500, loss_tot: 274.9989744985292\n",
      "i: 176750, loss_tot: 206.34830743840567\n",
      "i: 177000, loss_tot: 241.69911591640383\n",
      "i: 177250, loss_tot: 198.8996703373897\n",
      "i: 177500, loss_tot: 276.93503621722806\n",
      "i: 177750, loss_tot: 203.49599028073573\n",
      "i: 178000, loss_tot: 174.04552164480455\n",
      "i: 178250, loss_tot: 208.4848123310432\n",
      "i: 178500, loss_tot: 215.76174939195104\n",
      "i: 178750, loss_tot: 216.2393946136157\n",
      "i: 179000, loss_tot: 196.58670371336066\n",
      "i: 179250, loss_tot: 219.566606219816\n",
      "i: 179500, loss_tot: 269.0867011639441\n",
      "i: 179750, loss_tot: 236.537666124056\n",
      "i: 180000, loss_tot: 236.09787514619973\n",
      "i: 180250, loss_tot: 238.64130775955738\n",
      "i: 180500, loss_tot: 216.0974457714\n",
      "i: 180750, loss_tot: 214.16589257035128\n",
      "i: 181000, loss_tot: 257.36828207752916\n",
      "i: 181250, loss_tot: 199.07270176387442\n",
      "i: 181500, loss_tot: 184.9689809383772\n",
      "i: 181750, loss_tot: 208.20370412449586\n",
      "i: 182000, loss_tot: 256.87954505140317\n",
      "i: 182250, loss_tot: 200.0427315352543\n",
      "i: 182500, loss_tot: 242.5334856510598\n",
      "i: 182750, loss_tot: 228.81473688604223\n",
      "i: 183000, loss_tot: 209.97659547742737\n",
      "i: 183250, loss_tot: 255.52565713781084\n",
      "i: 183500, loss_tot: 244.1036339547488\n",
      "i: 183750, loss_tot: 176.28502177352095\n",
      "i: 184000, loss_tot: 220.6335432165675\n",
      "i: 184250, loss_tot: 226.61012630384627\n",
      "i: 184500, loss_tot: 254.46545251566857\n",
      "i: 184750, loss_tot: 228.7312804935661\n",
      "i: 185000, loss_tot: 179.12798757015472\n",
      "i: 185250, loss_tot: 226.05692117824918\n",
      "i: 185500, loss_tot: 199.6655931668845\n",
      "i: 185750, loss_tot: 240.65015413082088\n",
      "i: 186000, loss_tot: 266.60669303210585\n",
      "i: 186250, loss_tot: 226.25281994514063\n",
      "i: 186500, loss_tot: 282.73575106698377\n",
      "i: 186750, loss_tot: 238.13878770807383\n",
      "i: 187000, loss_tot: 211.66215931079205\n",
      "i: 187250, loss_tot: 193.42740789971083\n",
      "i: 187500, loss_tot: 257.6471375393817\n",
      "i: 187750, loss_tot: 274.2999151209393\n",
      "i: 188000, loss_tot: 254.77303636644268\n",
      "i: 188250, loss_tot: 222.35029369395693\n",
      "i: 188500, loss_tot: 248.9899364876468\n",
      "i: 188750, loss_tot: 215.26260610386154\n",
      "i: 189000, loss_tot: 191.77384455947046\n",
      "i: 189250, loss_tot: 235.13486233838256\n",
      "i: 189500, loss_tot: 253.94268562017066\n",
      "i: 189750, loss_tot: 246.35893708562477\n",
      "i: 190000, loss_tot: 172.26075562306949\n",
      "i: 190250, loss_tot: 226.7137504455354\n",
      "i: 190500, loss_tot: 181.26355876639616\n",
      "i: 190750, loss_tot: 290.0434321799714\n",
      "i: 191000, loss_tot: 214.40950255685485\n",
      "i: 191250, loss_tot: 192.06212106845553\n",
      "i: 191500, loss_tot: 230.2382638242899\n",
      "i: 191750, loss_tot: 234.6693118220428\n",
      "i: 192000, loss_tot: 249.5473672218482\n",
      "i: 192250, loss_tot: 206.15106107427738\n",
      "i: 192500, loss_tot: 216.33274963885546\n",
      "i: 192750, loss_tot: 221.70792597627266\n",
      "i: 193000, loss_tot: 184.74346078496427\n",
      "i: 193250, loss_tot: 210.2269386363565\n",
      "i: 193500, loss_tot: 219.97889913767926\n",
      "i: 193750, loss_tot: 227.90223759241402\n",
      "i: 194000, loss_tot: 210.9037643434247\n",
      "i: 194250, loss_tot: 182.68523319289088\n",
      "i: 194500, loss_tot: 241.41137901067967\n",
      "i: 194750, loss_tot: 177.9513505772315\n",
      "i: 195000, loss_tot: 203.00488472548545\n",
      "i: 195250, loss_tot: 222.50868160924713\n",
      "i: 195500, loss_tot: 257.18167715479626\n",
      "i: 195750, loss_tot: 223.09205474065283\n",
      "i: 196000, loss_tot: 203.21281179653903\n",
      "i: 196250, loss_tot: 257.5548757776505\n",
      "i: 196500, loss_tot: 272.3592378592864\n",
      "i: 196750, loss_tot: 168.26924663390963\n",
      "i: 197000, loss_tot: 187.16422631343826\n",
      "i: 197250, loss_tot: 265.14934865506365\n",
      "i: 197500, loss_tot: 220.7769041504711\n",
      "i: 197750, loss_tot: 210.559058726097\n",
      "i: 198000, loss_tot: 228.38939633907742\n",
      "i: 198250, loss_tot: 225.11073299610948\n",
      "i: 198500, loss_tot: 234.42750855748935\n",
      "i: 198750, loss_tot: 236.738100115438\n",
      "i: 199000, loss_tot: 193.92297455801162\n",
      "i: 199250, loss_tot: 239.57873702920187\n",
      "i: 199500, loss_tot: 272.58309815319956\n",
      "i: 199750, loss_tot: 218.9146536508802\n",
      "i: 200000, loss_tot: 189.4497028316208\n",
      "i: 200250, loss_tot: 198.26239165007595\n",
      "i: 200500, loss_tot: 249.8175375473746\n",
      "i: 200750, loss_tot: 223.65000619751635\n",
      "i: 201000, loss_tot: 253.45488886420515\n",
      "i: 201250, loss_tot: 219.64401672536493\n",
      "i: 201500, loss_tot: 274.64980638732146\n",
      "i: 201750, loss_tot: 232.85942548766732\n",
      "i: 202000, loss_tot: 221.8451313163862\n",
      "i: 202250, loss_tot: 218.42155362997786\n",
      "i: 202500, loss_tot: 255.2473691680096\n",
      "i: 202750, loss_tot: 238.80000546751543\n",
      "i: 203000, loss_tot: 221.58483177222195\n",
      "i: 203250, loss_tot: 190.88459648097822\n",
      "i: 203500, loss_tot: 244.78436017161505\n",
      "i: 203750, loss_tot: 244.81966337590958\n",
      "i: 204000, loss_tot: 217.5423801649158\n",
      "i: 204250, loss_tot: 206.15602108386577\n",
      "i: 204500, loss_tot: 235.78246415975735\n",
      "i: 204750, loss_tot: 212.5612320469215\n",
      "i: 205000, loss_tot: 248.89895197291392\n",
      "i: 205250, loss_tot: 209.84067056116066\n",
      "i: 205500, loss_tot: 205.2251336551499\n",
      "i: 205750, loss_tot: 243.4626533455716\n",
      "i: 206000, loss_tot: 217.76722760393267\n",
      "i: 206250, loss_tot: 204.31736091874365\n",
      "i: 206500, loss_tot: 242.252619066732\n",
      "i: 206750, loss_tot: 223.06542636171972\n",
      "i: 207000, loss_tot: 242.5118110808032\n",
      "i: 207250, loss_tot: 256.07709224786873\n",
      "i: 207500, loss_tot: 258.72595852427713\n",
      "i: 207750, loss_tot: 200.0617828755946\n",
      "i: 208000, loss_tot: 267.75793893499764\n",
      "i: 208250, loss_tot: 192.8711835304374\n",
      "i: 208500, loss_tot: 182.62763958998897\n",
      "i: 208750, loss_tot: 210.47229385916634\n",
      "i: 209000, loss_tot: 205.7664616752544\n",
      "i: 209250, loss_tot: 269.03103376039684\n",
      "i: 209500, loss_tot: 224.61434284521133\n",
      "i: 209750, loss_tot: 200.20846262487868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 210000, loss_tot: 222.7471588911602\n",
      "i: 210250, loss_tot: 183.03838891014274\n",
      "i: 210500, loss_tot: 193.65115287433292\n",
      "i: 210750, loss_tot: 220.9447257387539\n",
      "i: 211000, loss_tot: 217.434254175684\n",
      "i: 211250, loss_tot: 242.28324966440073\n",
      "i: 211500, loss_tot: 241.8408116125554\n",
      "i: 211750, loss_tot: 213.20688717036035\n",
      "i: 212000, loss_tot: 227.59499197501617\n",
      "i: 212250, loss_tot: 266.4525665788702\n",
      "i: 212500, loss_tot: 185.8044412558712\n",
      "i: 212750, loss_tot: 221.8470372599177\n",
      "i: 213000, loss_tot: 258.8392713886686\n",
      "i: 213250, loss_tot: 215.03873767830083\n",
      "i: 213500, loss_tot: 259.9296202967211\n",
      "i: 213750, loss_tot: 211.95198286492334\n",
      "i: 214000, loss_tot: 228.7366633171242\n",
      "i: 214250, loss_tot: 229.68746061634738\n",
      "i: 214500, loss_tot: 198.28430455778727\n",
      "i: 214750, loss_tot: 252.816833384966\n",
      "i: 215000, loss_tot: 194.0183695360448\n",
      "i: 215250, loss_tot: 221.2670339269936\n",
      "i: 215500, loss_tot: 196.745967968732\n",
      "i: 215750, loss_tot: 202.27537264494342\n",
      "i: 216000, loss_tot: 220.33957548440435\n",
      "i: 216250, loss_tot: 231.57636329909786\n",
      "i: 216500, loss_tot: 211.14797942893753\n",
      "i: 216750, loss_tot: 194.31797138272393\n",
      "i: 217000, loss_tot: 261.5823199883217\n",
      "i: 217250, loss_tot: 178.91807684079743\n",
      "i: 217500, loss_tot: 183.448768077814\n",
      "i: 217750, loss_tot: 235.66078448257002\n",
      "i: 218000, loss_tot: 186.8496811692603\n",
      "i: 218250, loss_tot: 214.07669782886282\n",
      "i: 218500, loss_tot: 214.7397746982154\n",
      "i: 218750, loss_tot: 241.1657446859451\n",
      "i: 219000, loss_tot: 191.38874840820208\n",
      "i: 219250, loss_tot: 188.47979394852183\n",
      "i: 219500, loss_tot: 151.05888395591438\n",
      "i: 219750, loss_tot: 226.7042157589879\n",
      "i: 220000, loss_tot: 272.02123010581363\n",
      "i: 220250, loss_tot: 204.29209478858945\n",
      "i: 220500, loss_tot: 247.5250024611807\n",
      "i: 220750, loss_tot: 288.03607019739053\n",
      "i: 221000, loss_tot: 220.3106392637873\n",
      "i: 221250, loss_tot: 258.4778279711312\n",
      "i: 221500, loss_tot: 265.2304225342243\n",
      "i: 221750, loss_tot: 215.53933956547175\n",
      "i: 222000, loss_tot: 228.99462149463398\n",
      "i: 222250, loss_tot: 246.9161755186389\n",
      "i: 222500, loss_tot: 246.0943107691221\n",
      "i: 222750, loss_tot: 221.80346358682033\n",
      "i: 223000, loss_tot: 184.83748586297713\n",
      "i: 223250, loss_tot: 205.30448958915403\n",
      "i: 223500, loss_tot: 202.60389873018258\n",
      "i: 223750, loss_tot: 217.0145589676599\n",
      "i: 224000, loss_tot: 245.6139529980123\n",
      "i: 224250, loss_tot: 193.50440776259688\n",
      "i: 224500, loss_tot: 236.71877837249136\n",
      "i: 224750, loss_tot: 203.23245302694247\n",
      "i: 225000, loss_tot: 200.28952029866886\n",
      "i: 225250, loss_tot: 233.19463406872126\n",
      "i: 225500, loss_tot: 216.80931055645024\n",
      "i: 225750, loss_tot: 197.08939854213037\n",
      "i: 226000, loss_tot: 269.5366797038517\n",
      "i: 226250, loss_tot: 191.50385429738554\n",
      "i: 226500, loss_tot: 214.13624188860732\n",
      "i: 226750, loss_tot: 211.50821828499437\n",
      "i: 227000, loss_tot: 239.8845200384781\n",
      "i: 227250, loss_tot: 218.86613403926137\n",
      "i: 227500, loss_tot: 172.0290245451314\n",
      "i: 227750, loss_tot: 183.8971369023015\n",
      "i: 228000, loss_tot: 252.92686446565932\n",
      "i: 228250, loss_tot: 205.45688489657942\n",
      "i: 228500, loss_tot: 200.40115437326506\n",
      "i: 228750, loss_tot: 255.630940571643\n",
      "i: 229000, loss_tot: 222.32226054214408\n",
      "i: 229250, loss_tot: 238.5687257651845\n",
      "i: 229500, loss_tot: 277.83711846260866\n",
      "i: 229750, loss_tot: 188.99865282359707\n",
      "i: 230000, loss_tot: 185.27487052974146\n",
      "i: 230250, loss_tot: 184.96121173325548\n",
      "i: 230500, loss_tot: 174.85344586402724\n",
      "i: 230750, loss_tot: 259.05491421940155\n",
      "i: 231000, loss_tot: 213.50892322850595\n",
      "i: 231250, loss_tot: 245.994170304868\n",
      "i: 231500, loss_tot: 205.93733659705126\n",
      "i: 231750, loss_tot: 238.95959008380072\n",
      "i: 232000, loss_tot: 248.86006157795444\n",
      "i: 232250, loss_tot: 197.43949117193876\n",
      "i: 232500, loss_tot: 191.133333537604\n",
      "i: 232750, loss_tot: 185.4875309434219\n",
      "i: 233000, loss_tot: 187.90295109866275\n",
      "i: 233250, loss_tot: 225.55863490735942\n",
      "i: 233500, loss_tot: 191.2529166761786\n",
      "i: 233750, loss_tot: 225.6741946375434\n",
      "i: 234000, loss_tot: 252.8976246883464\n",
      "i: 234250, loss_tot: 264.68140516664556\n",
      "i: 234500, loss_tot: 240.4354936814872\n",
      "i: 234750, loss_tot: 228.29646575795357\n",
      "i: 235000, loss_tot: 206.88971511708252\n",
      "i: 235250, loss_tot: 247.04330702080392\n",
      "i: 235500, loss_tot: 271.01702506352063\n",
      "i: 235750, loss_tot: 201.2083803086408\n",
      "i: 236000, loss_tot: 225.44116284054004\n",
      "i: 236250, loss_tot: 232.75995836831294\n",
      "i: 236500, loss_tot: 190.62321607015562\n",
      "i: 236750, loss_tot: 222.2607492788951\n",
      "i: 237000, loss_tot: 243.88548046831042\n",
      "i: 237250, loss_tot: 179.50892904239242\n",
      "i: 237500, loss_tot: 222.35471461789223\n",
      "i: 237750, loss_tot: 220.12433065904446\n",
      "i: 238000, loss_tot: 188.78961216776668\n",
      "i: 238250, loss_tot: 253.8089997589495\n",
      "i: 238500, loss_tot: 253.7149935970735\n",
      "i: 238750, loss_tot: 224.38277047479815\n",
      "i: 239000, loss_tot: 242.1171288502264\n",
      "i: 239250, loss_tot: 237.8597994176077\n",
      "i: 239500, loss_tot: 209.70932763603517\n",
      "i: 239750, loss_tot: 221.25997793127326\n",
      "i: 240000, loss_tot: 240.02246165570824\n",
      "i: 240250, loss_tot: 232.2189547432736\n",
      "i: 240500, loss_tot: 229.47194395555184\n",
      "i: 240750, loss_tot: 204.46055339025696\n",
      "i: 241000, loss_tot: 258.08032986313714\n",
      "i: 241250, loss_tot: 245.46928179873154\n",
      "i: 241500, loss_tot: 188.83038083968134\n",
      "i: 241750, loss_tot: 246.70869216266863\n",
      "i: 242000, loss_tot: 193.75311376967932\n",
      "i: 242250, loss_tot: 224.80482619939198\n",
      "i: 242500, loss_tot: 221.83864897907696\n",
      "i: 242750, loss_tot: 192.49425070695165\n",
      "i: 243000, loss_tot: 181.01260353954115\n",
      "i: 243250, loss_tot: 228.0373385899514\n",
      "i: 243500, loss_tot: 269.5478025093721\n",
      "i: 243750, loss_tot: 209.99714402916823\n",
      "i: 244000, loss_tot: 222.25820265108032\n",
      "i: 244250, loss_tot: 187.1705491489405\n",
      "i: 244500, loss_tot: 264.8149235684122\n",
      "i: 244750, loss_tot: 210.43679429601173\n",
      "i: 245000, loss_tot: 272.54381070632485\n",
      "i: 245250, loss_tot: 196.74023780025541\n",
      "i: 245500, loss_tot: 229.51425560763127\n",
      "i: 245750, loss_tot: 235.1988851070359\n",
      "i: 246000, loss_tot: 259.4528633294179\n",
      "i: 246250, loss_tot: 241.749161562303\n",
      "i: 246500, loss_tot: 229.45990259232994\n",
      "i: 246750, loss_tot: 256.1580937208512\n",
      "i: 247000, loss_tot: 217.38147054118338\n",
      "i: 247250, loss_tot: 219.12948496531578\n",
      "i: 247500, loss_tot: 302.5963989416021\n",
      "i: 247750, loss_tot: 206.3524937593937\n",
      "i: 248000, loss_tot: 205.23314431638457\n",
      "i: 248250, loss_tot: 242.68005432476014\n",
      "i: 248500, loss_tot: 289.36525034069257\n",
      "i: 248750, loss_tot: 227.57032940054182\n",
      "i: 249000, loss_tot: 248.7670662524598\n",
      "i: 249250, loss_tot: 248.8955695478787\n",
      "i: 249500, loss_tot: 238.30148188655673\n",
      "i: 249750, loss_tot: 216.45330197530362\n",
      "i: 250000, loss_tot: 165.96297984716315\n",
      "i: 250250, loss_tot: 233.77581674514803\n",
      "i: 250500, loss_tot: 225.89265281387517\n",
      "i: 250750, loss_tot: 236.78692332414445\n",
      "i: 251000, loss_tot: 247.64401819440536\n",
      "i: 251250, loss_tot: 192.064569101035\n",
      "i: 251500, loss_tot: 214.09411404684187\n",
      "i: 251750, loss_tot: 210.3431164981681\n",
      "i: 252000, loss_tot: 242.9134137319636\n",
      "i: 252250, loss_tot: 225.87865922843105\n",
      "i: 252500, loss_tot: 186.60152850123706\n",
      "i: 252750, loss_tot: 232.66500732892425\n",
      "i: 253000, loss_tot: 255.0680205161682\n",
      "i: 253250, loss_tot: 213.0417498207926\n",
      "i: 253500, loss_tot: 268.3760861605057\n",
      "i: 253750, loss_tot: 228.31210923145474\n",
      "i: 254000, loss_tot: 202.81891519875973\n",
      "i: 254250, loss_tot: 238.59968562588372\n",
      "i: 254500, loss_tot: 230.57406688493037\n",
      "i: 254750, loss_tot: 206.81676063714085\n",
      "i: 255000, loss_tot: 210.75621382563259\n",
      "i: 255250, loss_tot: 251.73839660103593\n",
      "i: 255500, loss_tot: 208.81801235241542\n",
      "i: 255750, loss_tot: 232.95871599833887\n",
      "i: 260500, loss_tot: 237.20750639648816\n",
      "i: 260750, loss_tot: 226.4353830695944\n",
      "i: 261000, loss_tot: 230.51986679963767\n",
      "i: 261250, loss_tot: 257.60244510575114\n",
      "i: 261500, loss_tot: 215.86153721493667\n",
      "i: 261750, loss_tot: 200.19872214254923\n",
      "i: 262000, loss_tot: 225.84543717068766\n",
      "i: 262250, loss_tot: 212.166627084062\n",
      "i: 262500, loss_tot: 210.10949157049413\n",
      "i: 262750, loss_tot: 256.9649256656412\n",
      "i: 263000, loss_tot: 182.6053232463263\n",
      "i: 263250, loss_tot: 224.56191978326066\n",
      "i: 263500, loss_tot: 254.88389461159088\n",
      "i: 263750, loss_tot: 217.4389521004535\n",
      "i: 264000, loss_tot: 222.83798484199696\n",
      "i: 264250, loss_tot: 259.9470934200215\n",
      "i: 264500, loss_tot: 185.04431643014374\n",
      "i: 264750, loss_tot: 226.21843558201334\n",
      "i: 265000, loss_tot: 216.07327661772604\n",
      "i: 265250, loss_tot: 194.92029682832887\n",
      "i: 265500, loss_tot: 202.334015329947\n",
      "i: 265750, loss_tot: 217.7796605479173\n",
      "i: 266000, loss_tot: 183.73297480737557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 266250, loss_tot: 209.35218253486033\n",
      "i: 266500, loss_tot: 234.86459394401405\n",
      "i: 266750, loss_tot: 235.6737697120104\n",
      "i: 267000, loss_tot: 204.96482680415974\n",
      "i: 267250, loss_tot: 223.33002493123666\n",
      "i: 267500, loss_tot: 184.0261989990752\n",
      "i: 267750, loss_tot: 292.46440382585394\n",
      "i: 268000, loss_tot: 230.92876323651058\n",
      "i: 268250, loss_tot: 205.66398739330475\n",
      "i: 268500, loss_tot: 215.27962574399666\n",
      "i: 268750, loss_tot: 208.13157042921682\n",
      "i: 269000, loss_tot: 210.82508225417746\n",
      "i: 269250, loss_tot: 209.32847899821164\n",
      "i: 269500, loss_tot: 216.28452451244462\n",
      "i: 269750, loss_tot: 194.59091387503156\n",
      "i: 270000, loss_tot: 219.7087647319294\n",
      "i: 270250, loss_tot: 241.5018296864361\n",
      "i: 270500, loss_tot: 282.5670000299276\n",
      "i: 270750, loss_tot: 237.26457983915301\n",
      "i: 271000, loss_tot: 229.99471291558402\n",
      "i: 271250, loss_tot: 255.77943326419975\n",
      "i: 271500, loss_tot: 263.116213252666\n",
      "i: 271750, loss_tot: 227.15781768480315\n",
      "i: 272000, loss_tot: 221.3135668900609\n",
      "i: 272250, loss_tot: 216.53604675164502\n",
      "i: 272500, loss_tot: 227.9912849763874\n",
      "i: 272750, loss_tot: 196.23000603269557\n",
      "i: 273000, loss_tot: 251.9930693595209\n",
      "i: 273250, loss_tot: 229.6565105449773\n",
      "i: 273500, loss_tot: 197.78281318769325\n",
      "i: 273750, loss_tot: 176.37882261212653\n",
      "i: 274000, loss_tot: 178.59411358201322\n",
      "i: 274250, loss_tot: 228.43797923728118\n",
      "i: 274500, loss_tot: 161.4783623579054\n",
      "i: 274750, loss_tot: 194.52592108380048\n",
      "i: 275000, loss_tot: 251.21838175384102\n",
      "i: 275250, loss_tot: 219.21537163994742\n",
      "i: 275500, loss_tot: 222.0069834278524\n",
      "i: 275750, loss_tot: 292.1118945029352\n",
      "i: 276000, loss_tot: 222.5291407276952\n",
      "i: 276250, loss_tot: 259.21041473029646\n",
      "i: 276500, loss_tot: 242.2696165666863\n",
      "i: 276750, loss_tot: 255.99795488928993\n",
      "i: 277000, loss_tot: 246.8557979925233\n",
      "i: 277250, loss_tot: 230.516698247873\n",
      "i: 277500, loss_tot: 214.3049834482823\n",
      "i: 277750, loss_tot: 257.2411037493841\n",
      "i: 278000, loss_tot: 236.9746796352917\n",
      "i: 278250, loss_tot: 201.6239257910571\n",
      "i: 278500, loss_tot: 243.7098459125976\n",
      "i: 278750, loss_tot: 232.554714238281\n",
      "i: 279000, loss_tot: 238.15225119825044\n",
      "i: 279250, loss_tot: 212.25156143534107\n",
      "i: 279500, loss_tot: 243.611613493532\n",
      "i: 279750, loss_tot: 235.6799343334281\n",
      "i: 280000, loss_tot: 266.89569683683794\n",
      "i: 280250, loss_tot: 247.89590070463717\n",
      "i: 280500, loss_tot: 258.22260337231694\n",
      "i: 280750, loss_tot: 229.38184461598644\n",
      "i: 281000, loss_tot: 197.34060476575513\n",
      "i: 281250, loss_tot: 202.8720802110026\n",
      "i: 281500, loss_tot: 226.2968829270783\n",
      "i: 281750, loss_tot: 245.82530797648303\n",
      "i: 282000, loss_tot: 262.9931427882402\n",
      "i: 282250, loss_tot: 247.8774163695958\n",
      "i: 282500, loss_tot: 226.7408729473222\n",
      "i: 282750, loss_tot: 223.0022718786313\n",
      "i: 283000, loss_tot: 204.3265866829298\n",
      "i: 283250, loss_tot: 215.09694424049928\n",
      "i: 283500, loss_tot: 217.78142734721825\n",
      "i: 283750, loss_tot: 292.38380246887453\n",
      "i: 284000, loss_tot: 186.69235603061506\n",
      "i: 284250, loss_tot: 266.11789488770444\n",
      "i: 284500, loss_tot: 258.67212377807124\n",
      "i: 284750, loss_tot: 263.07839599344936\n",
      "i: 285000, loss_tot: 236.10222037549931\n",
      "i: 285250, loss_tot: 284.45523926818043\n",
      "i: 285500, loss_tot: 241.75808305853542\n",
      "i: 285750, loss_tot: 214.35753018816\n",
      "i: 286000, loss_tot: 270.34119021716964\n",
      "i: 286250, loss_tot: 265.0765215969913\n",
      "i: 286500, loss_tot: 237.21924264783695\n",
      "i: 286750, loss_tot: 221.1219112143712\n",
      "i: 287000, loss_tot: 274.05888613539764\n",
      "i: 287250, loss_tot: 237.82969098018484\n",
      "i: 287500, loss_tot: 217.74053824359325\n",
      "i: 287750, loss_tot: 226.2406623154879\n",
      "i: 288000, loss_tot: 207.95399460447632\n",
      "i: 288250, loss_tot: 238.0712408504449\n",
      "i: 288500, loss_tot: 216.22204580834602\n",
      "i: 288750, loss_tot: 221.63303920406452\n",
      "i: 289000, loss_tot: 270.9365607800428\n",
      "i: 289250, loss_tot: 155.86858451490951\n",
      "i: 289500, loss_tot: 216.72781455195917\n",
      "i: 289750, loss_tot: 209.68010763688926\n",
      "i: 290000, loss_tot: 227.17497816473772\n",
      "i: 290250, loss_tot: 223.23009996565176\n",
      "i: 290500, loss_tot: 208.1779181267819\n",
      "i: 290750, loss_tot: 251.99403364759112\n",
      "i: 291000, loss_tot: 176.5475756499982\n",
      "i: 291250, loss_tot: 255.7924205701147\n",
      "i: 291500, loss_tot: 211.59155227538665\n",
      "i: 291750, loss_tot: 218.40026051601745\n",
      "i: 292000, loss_tot: 245.24953360425658\n",
      "i: 292250, loss_tot: 216.16350063504066\n",
      "i: 292500, loss_tot: 206.84424610251386\n",
      "i: 292750, loss_tot: 190.1693837531645\n",
      "i: 293000, loss_tot: 228.6801274226824\n",
      "i: 293250, loss_tot: 222.64582369313862\n",
      "i: 293500, loss_tot: 217.66725332764383\n",
      "i: 293750, loss_tot: 204.12625456352833\n",
      "i: 294000, loss_tot: 223.23911854016217\n",
      "i: 294250, loss_tot: 200.00024140234106\n",
      "i: 294500, loss_tot: 228.56536398730117\n",
      "i: 294750, loss_tot: 206.80730575465518\n",
      "i: 295000, loss_tot: 235.94601223371922\n",
      "i: 295250, loss_tot: 247.66908550730906\n",
      "i: 295500, loss_tot: 216.59150459471624\n",
      "i: 295750, loss_tot: 221.4050817315017\n",
      "i: 296000, loss_tot: 201.23796391674037\n",
      "i: 296250, loss_tot: 216.2152659457305\n",
      "i: 296500, loss_tot: 192.03796554951194\n",
      "i: 296750, loss_tot: 277.0483405526797\n",
      "i: 297000, loss_tot: 225.5270846077986\n",
      "i: 297250, loss_tot: 231.79596185172355\n",
      "i: 297500, loss_tot: 203.572379001719\n",
      "i: 297750, loss_tot: 266.34821360788317\n",
      "i: 298000, loss_tot: 181.70281473673379\n",
      "i: 298250, loss_tot: 222.28149265262064\n",
      "i: 298500, loss_tot: 162.2078640851518\n",
      "i: 298750, loss_tot: 185.86671215739275\n",
      "i: 299000, loss_tot: 199.15567797824275\n",
      "i: 299250, loss_tot: 178.146187023673\n",
      "i: 299500, loss_tot: 294.8235373491736\n",
      "i: 299750, loss_tot: 238.38831754956453\n",
      "i: 300000, loss_tot: 211.52806342102835\n",
      "i: 300250, loss_tot: 199.94917238610594\n",
      "i: 300500, loss_tot: 200.36489915514267\n",
      "i: 300750, loss_tot: 229.72972109872194\n",
      "i: 301000, loss_tot: 226.11179812659043\n",
      "i: 301250, loss_tot: 250.7929351430644\n",
      "i: 301500, loss_tot: 281.90979395635424\n",
      "i: 301750, loss_tot: 240.59447119895833\n",
      "i: 302000, loss_tot: 209.98361306401048\n",
      "i: 302250, loss_tot: 212.73339297049841\n",
      "i: 302500, loss_tot: 198.13560225551248\n",
      "i: 302750, loss_tot: 245.24850731359152\n",
      "i: 303000, loss_tot: 243.80398557184037\n",
      "i: 303250, loss_tot: 210.18229666657746\n",
      "i: 303500, loss_tot: 201.53688132436773\n",
      "i: 303750, loss_tot: 212.48755108736572\n",
      "i: 304000, loss_tot: 191.74222226084692\n",
      "i: 304250, loss_tot: 251.6643406650475\n",
      "i: 304500, loss_tot: 245.04954990162324\n",
      "i: 304750, loss_tot: 225.68523240824993\n",
      "i: 305000, loss_tot: 241.59221585257217\n",
      "i: 305250, loss_tot: 202.81281983563676\n",
      "i: 305500, loss_tot: 223.99301516776904\n",
      "i: 305750, loss_tot: 197.4919111219416\n",
      "i: 306000, loss_tot: 201.86953640383902\n",
      "i: 306250, loss_tot: 222.1985085356422\n",
      "i: 306500, loss_tot: 146.74731067567132\n",
      "i: 306750, loss_tot: 261.4278559052176\n",
      "i: 307000, loss_tot: 183.8139263417553\n",
      "i: 307250, loss_tot: 184.2291123670782\n",
      "i: 307500, loss_tot: 197.36552976613476\n",
      "i: 307750, loss_tot: 225.3600329310252\n",
      "i: 308000, loss_tot: 189.20803123052934\n",
      "i: 308250, loss_tot: 246.90011944372915\n",
      "i: 308500, loss_tot: 261.92261120919176\n",
      "i: 308750, loss_tot: 240.37359822083744\n",
      "i: 309000, loss_tot: 234.98528265665985\n",
      "i: 309250, loss_tot: 234.07906186695865\n",
      "i: 309500, loss_tot: 215.11597986238564\n",
      "i: 309750, loss_tot: 196.1796789770751\n",
      "i: 310000, loss_tot: 211.751601504437\n",
      "i: 310250, loss_tot: 162.16134582689395\n",
      "i: 310500, loss_tot: 230.30487413096125\n",
      "i: 310750, loss_tot: 206.8126516446464\n",
      "i: 311000, loss_tot: 207.6599776881648\n",
      "i: 311250, loss_tot: 175.00061208120843\n",
      "i: 311500, loss_tot: 208.17512592531858\n",
      "i: 311750, loss_tot: 203.14973905702638\n",
      "i: 312000, loss_tot: 243.20687249495043\n",
      "i: 312250, loss_tot: 210.52134031724185\n",
      "i: 312500, loss_tot: 233.6541470336076\n",
      "i: 312750, loss_tot: 253.74862824442164\n",
      "i: 313000, loss_tot: 209.37735825743295\n",
      "i: 313250, loss_tot: 210.5812638872303\n",
      "i: 313500, loss_tot: 238.30771529924124\n",
      "i: 313750, loss_tot: 242.2204169815732\n",
      "i: 314000, loss_tot: 199.20571232369474\n",
      "i: 314250, loss_tot: 184.64542713091708\n",
      "i: 314500, loss_tot: 237.69881360126422\n",
      "i: 314750, loss_tot: 267.8071698463598\n",
      "i: 315000, loss_tot: 194.64113931503655\n",
      "i: 315250, loss_tot: 197.4984234431214\n",
      "i: 315500, loss_tot: 208.13550713283942\n",
      "i: 315750, loss_tot: 185.07538428311494\n",
      "i: 316000, loss_tot: 212.029578538324\n",
      "i: 316250, loss_tot: 230.9368532007259\n",
      "i: 316500, loss_tot: 206.25047432281775\n",
      "i: 316750, loss_tot: 227.73326483801705\n",
      "i: 317000, loss_tot: 254.67188182184546\n",
      "i: 317250, loss_tot: 226.6910120676516\n",
      "i: 317500, loss_tot: 275.84655161905863\n",
      "i: 317750, loss_tot: 272.06965636969545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 318000, loss_tot: 269.99567874162545\n",
      "i: 318250, loss_tot: 241.89107630460876\n",
      "i: 318500, loss_tot: 220.33105245762505\n",
      "i: 318750, loss_tot: 192.34491530579984\n",
      "i: 319000, loss_tot: 245.5514203167407\n",
      "i: 319250, loss_tot: 287.9513078546431\n",
      "i: 319500, loss_tot: 246.99633468367648\n",
      "i: 319750, loss_tot: 228.20283182969084\n",
      "i: 320000, loss_tot: 217.74233141831553\n",
      "i: 320250, loss_tot: 264.5350873042088\n",
      "i: 320500, loss_tot: 270.1095783567056\n",
      "i: 320750, loss_tot: 226.19536688216874\n",
      "i: 321000, loss_tot: 217.97877684553387\n",
      "i: 321250, loss_tot: 266.6009068709984\n",
      "i: 321500, loss_tot: 266.7936446601525\n",
      "i: 321750, loss_tot: 226.38896571927705\n",
      "i: 322000, loss_tot: 242.1235203309142\n",
      "i: 322250, loss_tot: 239.81798603355884\n",
      "i: 322500, loss_tot: 207.75538106399122\n",
      "i: 322750, loss_tot: 196.68540845136624\n",
      "i: 323000, loss_tot: 213.19955634166033\n",
      "i: 323250, loss_tot: 200.49027486378793\n",
      "i: 323500, loss_tot: 195.1898364117249\n",
      "i: 323750, loss_tot: 269.57051966620025\n",
      "i: 324000, loss_tot: 225.17033428942545\n",
      "i: 324250, loss_tot: 233.7260317534861\n",
      "i: 324500, loss_tot: 195.75646587871714\n",
      "i: 324750, loss_tot: 244.463097492354\n",
      "i: 325000, loss_tot: 214.55286106862243\n",
      "i: 325250, loss_tot: 259.74926790457937\n",
      "i: 325500, loss_tot: 214.14817889682948\n",
      "i: 325750, loss_tot: 200.02543362292462\n",
      "i: 326000, loss_tot: 188.55604462129006\n",
      "i: 326250, loss_tot: 230.8911452696519\n",
      "i: 326500, loss_tot: 234.3480228726199\n",
      "i: 326750, loss_tot: 218.72003575038164\n",
      "i: 327000, loss_tot: 250.93108450216013\n",
      "i: 327250, loss_tot: 213.0131751724084\n",
      "i: 327500, loss_tot: 230.9025927077806\n",
      "i: 327750, loss_tot: 219.9515231634232\n",
      "i: 328000, loss_tot: 197.7096292038575\n",
      "i: 328250, loss_tot: 249.394320061896\n",
      "i: 328500, loss_tot: 227.7470641981438\n",
      "i: 328750, loss_tot: 245.0492119144788\n",
      "i: 329000, loss_tot: 241.5909262680916\n",
      "i: 329250, loss_tot: 244.61563208727904\n",
      "i: 329500, loss_tot: 210.73756330947697\n",
      "i: 329750, loss_tot: 254.38388764404925\n",
      "i: 330000, loss_tot: 214.27483409886256\n",
      "i: 330250, loss_tot: 202.13153874160022\n",
      "i: 330500, loss_tot: 224.63883340346743\n",
      "i: 330750, loss_tot: 255.458658582933\n",
      "i: 331000, loss_tot: 222.08317715403643\n",
      "i: 331250, loss_tot: 200.90623699391043\n",
      "i: 331500, loss_tot: 244.01773129851034\n",
      "i: 331750, loss_tot: 271.7846090263489\n",
      "i: 332000, loss_tot: 229.04457718167808\n",
      "i: 332250, loss_tot: 231.28713785997599\n",
      "i: 332500, loss_tot: 243.90814706346254\n",
      "i: 332750, loss_tot: 290.64091812013123\n",
      "i: 333000, loss_tot: 248.92958975526756\n",
      "i: 333250, loss_tot: 246.8284037939619\n",
      "i: 333500, loss_tot: 207.65141074036598\n",
      "i: 333750, loss_tot: 218.2717783878291\n",
      "i: 334000, loss_tot: 248.51075636456488\n",
      "i: 334250, loss_tot: 241.33744165156037\n",
      "i: 334500, loss_tot: 202.12142912233162\n",
      "i: 334750, loss_tot: 231.8558558487825\n",
      "i: 335000, loss_tot: 207.61138216308493\n",
      "i: 335250, loss_tot: 199.47966365369268\n",
      "i: 335500, loss_tot: 225.23535177601502\n",
      "i: 335750, loss_tot: 185.59138408847153\n",
      "i: 336000, loss_tot: 208.91904354410252\n",
      "i: 336250, loss_tot: 278.93777909472584\n",
      "i: 336500, loss_tot: 226.4059416097947\n",
      "i: 336750, loss_tot: 223.05288259799622\n",
      "i: 337000, loss_tot: 200.17202076158952\n",
      "i: 337250, loss_tot: 218.01019892743557\n",
      "i: 337500, loss_tot: 193.45291155123152\n",
      "i: 337750, loss_tot: 192.80901631097615\n",
      "i: 338000, loss_tot: 264.3528425609885\n",
      "i: 338250, loss_tot: 189.69828233565204\n",
      "i: 338500, loss_tot: 250.33761449102792\n",
      "i: 338750, loss_tot: 199.8954287496372\n",
      "i: 339000, loss_tot: 247.1138028456777\n",
      "i: 339250, loss_tot: 274.43136517795676\n",
      "i: 339500, loss_tot: 194.3428120445623\n",
      "i: 339750, loss_tot: 237.37598423387885\n",
      "i: 340000, loss_tot: 273.27377593129927\n",
      "i: 340250, loss_tot: 258.17109075414015\n",
      "i: 340500, loss_tot: 214.28239296976943\n",
      "i: 340750, loss_tot: 239.7717992225784\n",
      "i: 341000, loss_tot: 201.36103073343168\n",
      "i: 341250, loss_tot: 257.9330195958622\n",
      "i: 341500, loss_tot: 247.62388226435985\n",
      "i: 341750, loss_tot: 228.0079509780748\n",
      "i: 342000, loss_tot: 221.967097190161\n",
      "i: 342250, loss_tot: 258.61963300587854\n",
      "i: 342500, loss_tot: 189.72381967097172\n",
      "i: 342750, loss_tot: 249.4331326203444\n",
      "i: 343000, loss_tot: 154.73107024687334\n",
      "i: 343250, loss_tot: 226.94244369827678\n",
      "i: 343500, loss_tot: 219.49148222421215\n",
      "i: 343750, loss_tot: 208.14437025861815\n",
      "i: 344000, loss_tot: 217.6685078456998\n",
      "i: 344250, loss_tot: 233.50120771193986\n",
      "i: 344500, loss_tot: 215.9675246286392\n",
      "i: 344750, loss_tot: 194.46756811637442\n",
      "i: 345000, loss_tot: 295.1507151021808\n",
      "i: 345250, loss_tot: 210.1426028632649\n",
      "i: 345500, loss_tot: 200.73571994790814\n",
      "i: 345750, loss_tot: 207.5022200879581\n",
      "i: 346000, loss_tot: 210.6254140393731\n",
      "i: 346250, loss_tot: 263.5635492864508\n",
      "i: 346500, loss_tot: 185.13413845151825\n",
      "i: 346750, loss_tot: 265.57619193602363\n",
      "i: 347000, loss_tot: 243.12305297370068\n",
      "i: 347250, loss_tot: 243.53940510197077\n",
      "i: 347500, loss_tot: 183.65693855845007\n",
      "i: 347750, loss_tot: 213.7864818965993\n",
      "i: 348000, loss_tot: 238.59157266079563\n",
      "i: 348250, loss_tot: 236.04445985467646\n",
      "i: 348500, loss_tot: 203.92932690090964\n",
      "i: 348750, loss_tot: 290.68770328782966\n",
      "i: 349000, loss_tot: 238.40620644519046\n",
      "i: 349250, loss_tot: 230.77880655841594\n",
      "i: 349500, loss_tot: 199.39147195276144\n",
      "i: 349750, loss_tot: 224.00040576981846\n",
      "i: 350000, loss_tot: 223.8046802453581\n",
      "i: 350250, loss_tot: 210.06762205964188\n",
      "i: 350500, loss_tot: 198.8043932613452\n",
      "i: 350750, loss_tot: 199.35263500701637\n",
      "i: 351000, loss_tot: 236.80583809895458\n",
      "i: 351250, loss_tot: 229.61582066457748\n",
      "i: 351500, loss_tot: 215.45044971447686\n",
      "i: 351750, loss_tot: 260.54164933327587\n",
      "i: 352000, loss_tot: 241.66560943862424\n",
      "i: 352250, loss_tot: 210.24844001858028\n",
      "i: 352500, loss_tot: 250.522910439936\n",
      "i: 352750, loss_tot: 209.20435511541015\n",
      "i: 353000, loss_tot: 242.87851237449897\n",
      "i: 353250, loss_tot: 255.4026875511976\n",
      "i: 353500, loss_tot: 219.92192092471296\n",
      "i: 353750, loss_tot: 226.89225576196156\n",
      "i: 354000, loss_tot: 182.53685298052994\n",
      "i: 354250, loss_tot: 209.53349703577544\n",
      "i: 354500, loss_tot: 213.5162298475951\n",
      "i: 354750, loss_tot: 243.4405493482924\n",
      "i: 355000, loss_tot: 242.5482889985877\n",
      "i: 355250, loss_tot: 265.1225477527065\n",
      "i: 355500, loss_tot: 258.7519915671507\n",
      "i: 355750, loss_tot: 240.2818393707022\n",
      "i: 356000, loss_tot: 288.367070187286\n",
      "i: 356250, loss_tot: 207.5122856973391\n",
      "i: 356500, loss_tot: 223.86213002436796\n",
      "i: 356750, loss_tot: 250.7291651023645\n",
      "i: 357000, loss_tot: 294.9684405243546\n",
      "i: 357250, loss_tot: 213.70386402329757\n",
      "i: 357500, loss_tot: 192.1004239699617\n",
      "i: 357750, loss_tot: 206.0970983200195\n",
      "i: 358000, loss_tot: 209.20803524002548\n",
      "i: 358250, loss_tot: 212.24459267798892\n",
      "i: 358500, loss_tot: 214.77814322135063\n",
      "i: 358750, loss_tot: 162.97893344083278\n",
      "i: 359000, loss_tot: 219.86622195087477\n",
      "i: 359250, loss_tot: 189.91951984065585\n",
      "i: 359500, loss_tot: 199.81221077313646\n",
      "i: 359750, loss_tot: 206.97078649232165\n",
      "i: 360000, loss_tot: 187.5644477387797\n",
      "i: 360250, loss_tot: 213.82119297319093\n",
      "i: 360500, loss_tot: 227.37069161167892\n",
      "i: 360750, loss_tot: 234.315513204488\n",
      "i: 361000, loss_tot: 191.8395113188494\n",
      "i: 361250, loss_tot: 185.6893661485007\n",
      "i: 361500, loss_tot: 214.55773893514652\n",
      "i: 361750, loss_tot: 204.18360764028915\n",
      "i: 362000, loss_tot: 202.61580034867163\n",
      "i: 362250, loss_tot: 243.51904563835288\n",
      "i: 362500, loss_tot: 221.23004976875848\n",
      "i: 362750, loss_tot: 235.15123577572405\n",
      "i: 363000, loss_tot: 194.76277327163842\n",
      "i: 363250, loss_tot: 193.7536526167579\n",
      "i: 363500, loss_tot: 155.44240708376282\n",
      "i: 363750, loss_tot: 186.46678243931382\n",
      "i: 364000, loss_tot: 204.45360966762354\n",
      "i: 364250, loss_tot: 179.83030292269598\n",
      "i: 364500, loss_tot: 212.86541196129204\n",
      "i: 364750, loss_tot: 200.3546414448235\n",
      "i: 365000, loss_tot: 211.3545691290674\n",
      "i: 365250, loss_tot: 233.42469922500896\n",
      "i: 365500, loss_tot: 192.32291528816563\n",
      "i: 365750, loss_tot: 289.6072362725134\n",
      "i: 366000, loss_tot: 238.19882849793532\n",
      "i: 366250, loss_tot: 170.21719785399912\n",
      "i: 366500, loss_tot: 235.25477354888164\n",
      "i: 366750, loss_tot: 205.74952870320777\n",
      "i: 367000, loss_tot: 214.8752808223106\n",
      "i: 367250, loss_tot: 241.38405677145113\n",
      "i: 367500, loss_tot: 232.18790925633178\n",
      "i: 367750, loss_tot: 199.2674823520938\n",
      "i: 368000, loss_tot: 228.96142902199747\n",
      "i: 368250, loss_tot: 239.45642305432818\n",
      "i: 368500, loss_tot: 220.84568975251696\n",
      "i: 368750, loss_tot: 225.6815463532426\n",
      "i: 369000, loss_tot: 253.99573042745237\n",
      "i: 369250, loss_tot: 208.1432139686076\n",
      "i: 369500, loss_tot: 241.87571292428115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 369750, loss_tot: 194.24152920999563\n",
      "i: 370000, loss_tot: 182.58172116332338\n",
      "i: 370250, loss_tot: 231.23096923257725\n",
      "i: 370500, loss_tot: 283.2724883945932\n",
      "i: 370750, loss_tot: 206.64300570157357\n",
      "i: 371000, loss_tot: 262.7844821895333\n",
      "i: 371250, loss_tot: 222.65236459279956\n",
      "i: 371500, loss_tot: 298.79554905761967\n",
      "i: 371750, loss_tot: 237.23705197622039\n",
      "i: 372000, loss_tot: 247.72032625796274\n",
      "i: 372250, loss_tot: 233.64993213991775\n",
      "i: 372500, loss_tot: 221.3519018962351\n",
      "i: 372750, loss_tot: 263.10924500637555\n",
      "i: 373000, loss_tot: 208.96542186162435\n",
      "i: 373250, loss_tot: 302.8299050919805\n",
      "i: 373500, loss_tot: 205.52417205245473\n",
      "i: 373750, loss_tot: 239.72813794603746\n",
      "i: 374000, loss_tot: 231.44082982542005\n",
      "i: 374250, loss_tot: 251.5471491848817\n",
      "i: 374500, loss_tot: 239.97566145770486\n",
      "i: 374750, loss_tot: 211.43668203861336\n",
      "i: 375000, loss_tot: 219.7385301554494\n",
      "i: 375250, loss_tot: 255.89885393107193\n",
      "i: 375500, loss_tot: 228.5114612720249\n",
      "i: 375750, loss_tot: 227.48795843144063\n",
      "i: 376000, loss_tot: 199.11188340493518\n",
      "i: 376250, loss_tot: 203.35824907856644\n",
      "i: 376500, loss_tot: 246.2061988996784\n",
      "i: 376750, loss_tot: 198.67158901026198\n",
      "i: 377000, loss_tot: 222.61874321015588\n",
      "i: 377250, loss_tot: 224.3073482597994\n",
      "i: 377500, loss_tot: 228.77527700859824\n",
      "i: 377750, loss_tot: 216.15976357308625\n",
      "i: 378000, loss_tot: 269.47523103517136\n",
      "i: 378250, loss_tot: 206.23919822748758\n",
      "i: 378500, loss_tot: 205.0223604943906\n",
      "i: 378750, loss_tot: 242.7101005778196\n",
      "i: 379000, loss_tot: 232.2818307134755\n",
      "i: 379250, loss_tot: 176.60381217115136\n",
      "i: 379500, loss_tot: 247.34067880667487\n",
      "i: 379750, loss_tot: 200.52069624483528\n",
      "i: 380000, loss_tot: 198.091325129536\n",
      "i: 380250, loss_tot: 221.84059889607363\n",
      "i: 380500, loss_tot: 256.2710775669478\n",
      "i: 380750, loss_tot: 190.05900365589434\n",
      "i: 381000, loss_tot: 208.71814987606368\n",
      "i: 381250, loss_tot: 198.08908064380333\n",
      "i: 381500, loss_tot: 205.54986328456084\n",
      "i: 381750, loss_tot: 188.5106687259606\n",
      "i: 382000, loss_tot: 237.21169708053583\n",
      "i: 382250, loss_tot: 267.0369310722011\n",
      "i: 382500, loss_tot: 188.80394855899232\n",
      "i: 382750, loss_tot: 238.76373704763012\n",
      "i: 383000, loss_tot: 211.10230211504154\n",
      "i: 383250, loss_tot: 210.09681973935906\n",
      "i: 383500, loss_tot: 231.25403646170744\n",
      "i: 383750, loss_tot: 208.99468527005985\n",
      "i: 384000, loss_tot: 181.85489203649857\n",
      "i: 384250, loss_tot: 206.45394972953014\n",
      "i: 384500, loss_tot: 209.93847668388392\n",
      "i: 384750, loss_tot: 174.56467862825914\n",
      "i: 385000, loss_tot: 221.33021156849338\n",
      "i: 385250, loss_tot: 268.1145038788998\n",
      "i: 385500, loss_tot: 209.1614336513728\n",
      "i: 385750, loss_tot: 240.8767800385179\n",
      "i: 386000, loss_tot: 198.87310145472236\n",
      "i: 386250, loss_tot: 276.2982949527912\n",
      "i: 386500, loss_tot: 222.6952499905741\n",
      "i: 386750, loss_tot: 168.28084921849893\n",
      "i: 387000, loss_tot: 300.41674806512424\n",
      "i: 387250, loss_tot: 235.00653592611314\n",
      "i: 387500, loss_tot: 196.41887026051808\n",
      "i: 387750, loss_tot: 229.63405960616663\n",
      "i: 388000, loss_tot: 226.94760487714782\n",
      "i: 388250, loss_tot: 253.89068530011923\n",
      "i: 388500, loss_tot: 217.4018663984426\n",
      "i: 388750, loss_tot: 225.1823710499925\n",
      "i: 389000, loss_tot: 214.34894003360532\n",
      "i: 389250, loss_tot: 221.94940575286282\n",
      "i: 389500, loss_tot: 233.51156672791578\n",
      "i: 389750, loss_tot: 222.42427578462753\n",
      "i: 390000, loss_tot: 187.75767832502916\n",
      "i: 390250, loss_tot: 206.7620075841539\n",
      "i: 390500, loss_tot: 256.0282639412694\n",
      "i: 390750, loss_tot: 216.48210312097234\n",
      "i: 391000, loss_tot: 241.75088128360636\n",
      "i: 391250, loss_tot: 251.82796716515907\n",
      "i: 391500, loss_tot: 235.39126268023512\n",
      "i: 391750, loss_tot: 201.47746131989362\n",
      "i: 392000, loss_tot: 224.60875662203398\n",
      "i: 392250, loss_tot: 165.78081236230915\n",
      "i: 392500, loss_tot: 246.37413239949382\n",
      "i: 392750, loss_tot: 224.26432564270664\n",
      "i: 393000, loss_tot: 221.49697144428296\n",
      "i: 393250, loss_tot: 230.0713204010017\n",
      "i: 393500, loss_tot: 230.4822427710565\n",
      "i: 393750, loss_tot: 211.18969230778896\n",
      "i: 394000, loss_tot: 223.8404501840623\n",
      "i: 394250, loss_tot: 250.52510358587904\n",
      "i: 394500, loss_tot: 195.45779641570786\n",
      "i: 394750, loss_tot: 244.4817804376222\n",
      "i: 395000, loss_tot: 204.69275914765893\n",
      "i: 395250, loss_tot: 255.92564546908062\n",
      "i: 395500, loss_tot: 222.30606773516823\n",
      "i: 395750, loss_tot: 229.40057847747374\n",
      "i: 396000, loss_tot: 266.0890309628332\n",
      "i: 396250, loss_tot: 186.6580787209107\n",
      "i: 396500, loss_tot: 239.44912544302872\n",
      "i: 396750, loss_tot: 254.26897090113548\n",
      "i: 397000, loss_tot: 223.2061452290148\n",
      "i: 397250, loss_tot: 207.27969446061644\n",
      "i: 397500, loss_tot: 245.6560438219162\n",
      "i: 397750, loss_tot: 225.71791038025404\n",
      "i: 398000, loss_tot: 208.72480728035794\n",
      "i: 398250, loss_tot: 227.94738186614356\n",
      "i: 398500, loss_tot: 200.1495379196992\n",
      "i: 398750, loss_tot: 226.42113392946354\n",
      "i: 399000, loss_tot: 243.3828697303473\n",
      "i: 399250, loss_tot: 209.56531504873652\n",
      "i: 399500, loss_tot: 220.40499146446936\n",
      "i: 399750, loss_tot: 241.96684179237985\n",
      "i: 400000, loss_tot: 188.0357912104251\n",
      "i: 400250, loss_tot: 177.07546841753182\n",
      "i: 400500, loss_tot: 235.15862315857376\n",
      "i: 400750, loss_tot: 183.441557765326\n",
      "i: 401000, loss_tot: 272.9623900560969\n",
      "i: 401250, loss_tot: 207.7806328641996\n",
      "i: 401500, loss_tot: 239.67828623805195\n",
      "i: 401750, loss_tot: 254.3673373575908\n",
      "i: 402000, loss_tot: 208.96143056157976\n",
      "i: 402250, loss_tot: 188.71386800843368\n",
      "i: 402500, loss_tot: 218.6401333668356\n",
      "i: 402750, loss_tot: 213.82307146864943\n",
      "i: 403000, loss_tot: 183.0805970687735\n",
      "i: 403250, loss_tot: 243.29961084451526\n",
      "i: 403500, loss_tot: 194.88519984731917\n",
      "i: 403750, loss_tot: 214.86294478435767\n",
      "i: 404000, loss_tot: 217.7474178345126\n",
      "i: 404250, loss_tot: 250.63596987281926\n",
      "i: 404500, loss_tot: 208.22865359302276\n",
      "i: 404750, loss_tot: 250.47943504305383\n",
      "i: 405000, loss_tot: 212.951053132588\n",
      "i: 405250, loss_tot: 216.5118708886268\n",
      "i: 405500, loss_tot: 245.56303734083428\n",
      "i: 405750, loss_tot: 228.62917675348473\n",
      "i: 406000, loss_tot: 210.16630524550527\n",
      "i: 406250, loss_tot: 217.0783587143256\n",
      "i: 406500, loss_tot: 188.1847449834051\n",
      "i: 406750, loss_tot: 210.77959054829054\n",
      "i: 407000, loss_tot: 196.96346917718012\n",
      "i: 407250, loss_tot: 221.47734466244583\n",
      "i: 407500, loss_tot: 210.97840258242752\n",
      "i: 407750, loss_tot: 206.0810708971807\n",
      "i: 408000, loss_tot: 239.72554128537652\n",
      "i: 408250, loss_tot: 225.34792682226515\n",
      "i: 408500, loss_tot: 318.985074239634\n",
      "i: 408750, loss_tot: 259.8471599967138\n",
      "i: 409000, loss_tot: 243.82904379685584\n",
      "i: 409250, loss_tot: 200.2183246598993\n",
      "i: 409500, loss_tot: 269.45617840515956\n",
      "i: 409750, loss_tot: 214.10021542035975\n",
      "i: 410000, loss_tot: 247.51337621501835\n",
      "i: 410250, loss_tot: 210.3047051945253\n",
      "i: 410500, loss_tot: 220.88082209226675\n",
      "i: 410750, loss_tot: 259.6315981518809\n",
      "i: 411000, loss_tot: 265.2267745453678\n",
      "i: 411250, loss_tot: 187.0738609808893\n",
      "i: 411500, loss_tot: 263.37346845152325\n",
      "i: 411750, loss_tot: 205.8178622718621\n",
      "i: 412000, loss_tot: 190.66924234675943\n",
      "i: 412250, loss_tot: 217.93943498961278\n",
      "i: 412500, loss_tot: 203.22992619111668\n",
      "i: 412750, loss_tot: 190.4934060074165\n",
      "i: 413000, loss_tot: 244.7989409784577\n",
      "i: 413250, loss_tot: 256.3920660322415\n",
      "i: 413500, loss_tot: 251.3997009906033\n",
      "i: 413750, loss_tot: 232.92565400127322\n",
      "i: 414000, loss_tot: 192.01834812453134\n",
      "i: 414250, loss_tot: 199.80222725139146\n",
      "i: 414500, loss_tot: 205.63398005648517\n",
      "i: 414750, loss_tot: 213.11161940840935\n",
      "i: 415000, loss_tot: 222.05558420687578\n",
      "i: 415250, loss_tot: 261.99679064516147\n",
      "i: 415500, loss_tot: 196.08814655114665\n",
      "i: 415750, loss_tot: 193.69615133202635\n",
      "i: 416000, loss_tot: 200.0249440434773\n",
      "i: 416250, loss_tot: 219.74563814348588\n",
      "i: 416500, loss_tot: 231.7884941890955\n",
      "i: 416750, loss_tot: 222.616125175326\n",
      "i: 417000, loss_tot: 198.86143866939472\n",
      "i: 417250, loss_tot: 259.18996958317234\n",
      "i: 417500, loss_tot: 236.3061434108112\n",
      "i: 417750, loss_tot: 205.5289566752236\n",
      "i: 418000, loss_tot: 227.29107099334942\n",
      "i: 418250, loss_tot: 224.98981831317303\n",
      "i: 418500, loss_tot: 222.30734307872598\n",
      "i: 418750, loss_tot: 220.7087900899444\n",
      "i: 419000, loss_tot: 211.98315806321335\n",
      "i: 419250, loss_tot: 230.54744957557878\n",
      "i: 419500, loss_tot: 211.80338105260861\n",
      "i: 419750, loss_tot: 209.8349606976239\n",
      "i: 420000, loss_tot: 247.51182554430852\n",
      "i: 420250, loss_tot: 238.24183208621952\n",
      "i: 420500, loss_tot: 243.27526937731452\n",
      "i: 420750, loss_tot: 252.32564444009213\n",
      "i: 421000, loss_tot: 226.16418383686454\n",
      "i: 421250, loss_tot: 221.14789463545895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 421500, loss_tot: 192.91261483535826\n",
      "i: 421750, loss_tot: 198.10933042709163\n",
      "i: 422000, loss_tot: 199.17323544760526\n",
      "i: 422250, loss_tot: 262.10665336568604\n",
      "i: 422500, loss_tot: 224.64865237947393\n",
      "i: 422750, loss_tot: 215.84224806705498\n",
      "i: 423000, loss_tot: 201.20374926334028\n",
      "i: 423250, loss_tot: 192.12329652740854\n",
      "i: 423500, loss_tot: 203.78832149479538\n",
      "i: 423750, loss_tot: 237.79375486987877\n",
      "i: 424000, loss_tot: 195.5482828497386\n",
      "i: 424250, loss_tot: 216.2961102392059\n",
      "i: 424500, loss_tot: 268.76809307730406\n",
      "i: 424750, loss_tot: 256.4623376817955\n",
      "i: 425000, loss_tot: 200.96182286016642\n",
      "i: 425250, loss_tot: 204.5081690647977\n",
      "i: 425500, loss_tot: 219.10530454760794\n",
      "i: 425750, loss_tot: 235.08093105787236\n",
      "i: 426000, loss_tot: 189.16731302413623\n",
      "i: 426250, loss_tot: 203.1894930001264\n",
      "i: 426500, loss_tot: 252.85371015694938\n",
      "i: 426750, loss_tot: 225.7047546628173\n",
      "i: 427000, loss_tot: 248.34073927908204\n",
      "i: 427250, loss_tot: 201.93739238508715\n",
      "i: 427500, loss_tot: 249.60772844757537\n",
      "i: 427750, loss_tot: 240.19433221335987\n",
      "i: 428000, loss_tot: 213.0456389409746\n",
      "i: 428250, loss_tot: 200.4951642214853\n",
      "i: 428500, loss_tot: 208.01959334946238\n",
      "i: 428750, loss_tot: 209.5395054946374\n",
      "i: 429000, loss_tot: 238.13984807305968\n",
      "i: 429250, loss_tot: 171.87724217901473\n",
      "i: 429500, loss_tot: 239.34826913157016\n",
      "i: 429750, loss_tot: 215.62243062687384\n",
      "i: 430000, loss_tot: 199.57250906009227\n",
      "i: 430250, loss_tot: 212.07145450843032\n",
      "i: 430500, loss_tot: 239.73331342735725\n",
      "i: 430750, loss_tot: 250.14680147236288\n",
      "i: 431000, loss_tot: 235.965487551053\n",
      "i: 431250, loss_tot: 240.41280582694336\n",
      "i: 431500, loss_tot: 201.62661766052247\n",
      "i: 431750, loss_tot: 219.9465113017452\n",
      "i: 432000, loss_tot: 214.05960102203417\n",
      "i: 432250, loss_tot: 267.65718420000775\n",
      "i: 432500, loss_tot: 260.4483520820929\n",
      "i: 432750, loss_tot: 256.3696155850591\n",
      "i: 433000, loss_tot: 222.09925489966497\n",
      "i: 433250, loss_tot: 266.8687302727345\n",
      "i: 433500, loss_tot: 231.33574679169405\n",
      "i: 433750, loss_tot: 184.57830490684574\n",
      "i: 434000, loss_tot: 188.66848861460983\n",
      "i: 434250, loss_tot: 285.7601221087866\n",
      "i: 434500, loss_tot: 246.8329455941415\n",
      "i: 434750, loss_tot: 241.1589017872687\n",
      "i: 435000, loss_tot: 214.07501601384138\n",
      "i: 435250, loss_tot: 252.5009559104246\n",
      "i: 435500, loss_tot: 239.9234259613447\n",
      "i: 435750, loss_tot: 246.59952375267548\n",
      "i: 436000, loss_tot: 173.96874009169608\n",
      "i: 436250, loss_tot: 227.20395478498264\n",
      "i: 436500, loss_tot: 217.94575827031397\n",
      "i: 436750, loss_tot: 155.92835749992025\n",
      "i: 437000, loss_tot: 193.417468716959\n",
      "i: 437250, loss_tot: 174.9179242772248\n",
      "i: 437500, loss_tot: 205.64984037698494\n",
      "i: 437750, loss_tot: 214.48029416099888\n",
      "i: 438000, loss_tot: 206.97554603578936\n",
      "i: 438250, loss_tot: 217.71709643837298\n",
      "i: 438500, loss_tot: 238.5832958451938\n",
      "i: 438750, loss_tot: 219.01674499093323\n",
      "i: 439000, loss_tot: 233.42202241298293\n",
      "i: 439250, loss_tot: 236.06267240195228\n",
      "i: 439500, loss_tot: 190.26356038636294\n",
      "i: 439750, loss_tot: 246.75073606164108\n",
      "i: 440000, loss_tot: 240.4208596761385\n",
      "i: 440250, loss_tot: 259.39620205846074\n",
      "i: 440500, loss_tot: 215.01681235350668\n",
      "i: 440750, loss_tot: 188.99119474568826\n",
      "i: 441000, loss_tot: 237.22488579293284\n",
      "i: 441250, loss_tot: 233.0818913198961\n",
      "i: 441500, loss_tot: 236.43878068268066\n",
      "i: 441750, loss_tot: 203.69342926701995\n",
      "i: 442000, loss_tot: 234.2852804436395\n",
      "i: 442250, loss_tot: 211.46661145336168\n",
      "i: 442500, loss_tot: 240.4327654953953\n",
      "i: 442750, loss_tot: 295.8951635240951\n",
      "i: 443000, loss_tot: 237.12743648807285\n",
      "i: 443250, loss_tot: 224.07256070449483\n",
      "i: 443500, loss_tot: 250.2003426934143\n",
      "i: 443750, loss_tot: 198.00771440675481\n",
      "i: 444000, loss_tot: 178.60119879909317\n",
      "i: 444250, loss_tot: 141.76374859466517\n",
      "i: 444500, loss_tot: 238.1938902568635\n",
      "i: 444750, loss_tot: 212.74274014968077\n",
      "i: 445000, loss_tot: 245.50779596706136\n",
      "i: 445250, loss_tot: 236.93954954454767\n",
      "i: 445500, loss_tot: 204.8564219280239\n",
      "i: 445750, loss_tot: 262.5557436635491\n",
      "i: 446000, loss_tot: 192.04371487211668\n",
      "i: 446250, loss_tot: 195.55164440821855\n",
      "i: 446500, loss_tot: 226.73508776495314\n",
      "i: 446750, loss_tot: 225.57531865855213\n",
      "i: 447000, loss_tot: 240.18841014005247\n",
      "i: 447250, loss_tot: 189.65260403084102\n",
      "i: 447500, loss_tot: 241.75161065574218\n",
      "i: 447750, loss_tot: 293.27045176582413\n",
      "i: 448000, loss_tot: 226.1338941272703\n",
      "i: 448250, loss_tot: 170.71105696129817\n",
      "i: 448500, loss_tot: 234.70838281059056\n",
      "i: 448750, loss_tot: 215.17007821383916\n",
      "i: 449000, loss_tot: 200.93408209161834\n",
      "i: 449250, loss_tot: 198.39492776137024\n",
      "i: 449500, loss_tot: 238.20938833857014\n",
      "i: 449750, loss_tot: 188.64658004414733\n",
      "i: 450000, loss_tot: 165.22267342170818\n",
      "i: 450250, loss_tot: 181.477485368122\n",
      "i: 450500, loss_tot: 225.06815756920165\n",
      "i: 450750, loss_tot: 204.9535743839317\n",
      "i: 451000, loss_tot: 226.9409548952477\n",
      "i: 451250, loss_tot: 250.87279453630268\n",
      "i: 451500, loss_tot: 194.56389827481004\n",
      "i: 451750, loss_tot: 220.2371759778203\n",
      "i: 452000, loss_tot: 248.62584407227146\n",
      "i: 452250, loss_tot: 264.06022053337364\n",
      "i: 452500, loss_tot: 230.08081251345575\n",
      "i: 452750, loss_tot: 265.2687108075828\n",
      "i: 453000, loss_tot: 230.15127859569787\n",
      "i: 453250, loss_tot: 176.88942085266345\n",
      "i: 453500, loss_tot: 231.23878935504138\n",
      "i: 453750, loss_tot: 243.25635191228764\n",
      "i: 454000, loss_tot: 228.05934633624724\n",
      "i: 454250, loss_tot: 236.04612609643664\n",
      "i: 454500, loss_tot: 275.7655187029237\n",
      "i: 454750, loss_tot: 235.71868536941713\n",
      "i: 455000, loss_tot: 233.76438436757772\n",
      "i: 455250, loss_tot: 257.2345247326315\n",
      "i: 455500, loss_tot: 246.47799582561436\n",
      "i: 455750, loss_tot: 219.01487814783118\n",
      "i: 456000, loss_tot: 235.4630644557999\n",
      "i: 456250, loss_tot: 215.1556821562026\n",
      "i: 456500, loss_tot: 234.62169108672538\n",
      "i: 456750, loss_tot: 236.9867801961326\n",
      "i: 457000, loss_tot: 222.7804510112398\n",
      "i: 457250, loss_tot: 233.01828638563748\n",
      "i: 457500, loss_tot: 177.33947357494384\n",
      "i: 457750, loss_tot: 191.1478471051136\n",
      "i: 458000, loss_tot: 237.73433413841994\n",
      "i: 458250, loss_tot: 211.7729870807717\n",
      "i: 458500, loss_tot: 186.4820454174573\n",
      "i: 458750, loss_tot: 277.9870536670787\n",
      "i: 459000, loss_tot: 230.04702425725233\n",
      "i: 459250, loss_tot: 188.89080408653626\n",
      "i: 459500, loss_tot: 219.54960215907084\n",
      "i: 459750, loss_tot: 216.81041651336477\n",
      "i: 460000, loss_tot: 242.95332848512916\n",
      "i: 460250, loss_tot: 226.3610129816155\n",
      "i: 460500, loss_tot: 274.27284290755057\n",
      "i: 460750, loss_tot: 185.55510808984516\n",
      "i: 461000, loss_tot: 193.49504816845757\n",
      "i: 461250, loss_tot: 252.18936244613798\n",
      "i: 461500, loss_tot: 260.4750173644013\n",
      "i: 461750, loss_tot: 210.97905052098852\n",
      "i: 462000, loss_tot: 215.00296152835872\n",
      "i: 462250, loss_tot: 240.47443520748055\n",
      "i: 462500, loss_tot: 219.60529644720256\n",
      "i: 462750, loss_tot: 206.3864830888249\n",
      "i: 463000, loss_tot: 237.98671872832347\n",
      "i: 463250, loss_tot: 266.0490240402367\n",
      "i: 463500, loss_tot: 263.74309037673214\n",
      "i: 463750, loss_tot: 222.9793474707877\n",
      "i: 464000, loss_tot: 253.57749004842256\n",
      "i: 464250, loss_tot: 182.19213459522467\n",
      "i: 464500, loss_tot: 227.1754481278854\n",
      "i: 464750, loss_tot: 232.32038630272262\n",
      "i: 465000, loss_tot: 228.239067347041\n",
      "i: 465250, loss_tot: 215.7903107009409\n",
      "i: 465500, loss_tot: 237.4163528667914\n",
      "i: 465750, loss_tot: 236.53729480428737\n",
      "i: 466000, loss_tot: 190.5694246859208\n",
      "i: 466250, loss_tot: 195.83845984270346\n",
      "i: 466500, loss_tot: 237.41355997827372\n",
      "i: 466750, loss_tot: 222.92239421952362\n",
      "i: 467000, loss_tot: 182.5207638456335\n",
      "i: 467250, loss_tot: 200.93954709060696\n",
      "i: 467500, loss_tot: 186.21220773594985\n",
      "i: 467750, loss_tot: 249.98457767434303\n",
      "i: 468000, loss_tot: 198.7240553074633\n",
      "i: 468250, loss_tot: 225.68809158420598\n",
      "i: 468500, loss_tot: 215.4454052694165\n",
      "i: 468750, loss_tot: 240.5916731489892\n",
      "i: 469000, loss_tot: 229.943472460708\n",
      "i: 469250, loss_tot: 191.82485051131837\n",
      "i: 469500, loss_tot: 198.63895471675553\n",
      "i: 469750, loss_tot: 258.1647040676622\n",
      "i: 470000, loss_tot: 206.4683849744033\n",
      "i: 470250, loss_tot: 246.6097135162435\n",
      "i: 470500, loss_tot: 235.5045369534274\n",
      "i: 470750, loss_tot: 231.39747978253044\n",
      "i: 471000, loss_tot: 199.6947619188321\n",
      "i: 471250, loss_tot: 221.83722370521514\n",
      "i: 471500, loss_tot: 194.8577387628093\n",
      "i: 471750, loss_tot: 231.85149132424033\n",
      "i: 472000, loss_tot: 211.58942714913098\n",
      "i: 472250, loss_tot: 267.6510588454281\n",
      "i: 472500, loss_tot: 259.5462963908678\n",
      "i: 472750, loss_tot: 296.39425603873354\n",
      "i: 473000, loss_tot: 186.3735816079381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 473250, loss_tot: 234.6087592701876\n",
      "i: 473500, loss_tot: 197.51954417627292\n",
      "i: 473750, loss_tot: 193.08571952223602\n",
      "i: 474000, loss_tot: 226.3472908866241\n",
      "i: 474250, loss_tot: 228.9739955358388\n",
      "i: 474500, loss_tot: 244.37644655471087\n",
      "i: 474750, loss_tot: 249.35751154112745\n",
      "i: 475000, loss_tot: 203.6333217321722\n",
      "i: 475250, loss_tot: 190.15045345163205\n",
      "i: 475500, loss_tot: 198.21782716457733\n",
      "i: 475750, loss_tot: 184.72904053182108\n",
      "i: 476000, loss_tot: 197.43575902521647\n",
      "i: 476250, loss_tot: 189.6902693167718\n",
      "i: 476500, loss_tot: 224.86319404133815\n",
      "i: 476750, loss_tot: 268.68124966877514\n",
      "i: 477000, loss_tot: 243.3114087085225\n",
      "i: 477250, loss_tot: 234.23193274776452\n",
      "i: 477500, loss_tot: 237.5082333750045\n",
      "i: 477750, loss_tot: 259.30738658715285\n",
      "i: 478000, loss_tot: 257.81568934388457\n",
      "i: 478250, loss_tot: 221.9681905891378\n",
      "i: 478500, loss_tot: 249.1407658706262\n",
      "i: 478750, loss_tot: 295.4352917330675\n",
      "i: 479000, loss_tot: 232.0988411292249\n",
      "i: 479250, loss_tot: 242.4104537615714\n",
      "i: 479500, loss_tot: 209.49363553519595\n",
      "i: 479750, loss_tot: 181.44005781740424\n",
      "i: 480000, loss_tot: 201.34443774817746\n",
      "i: 480250, loss_tot: 244.7095718220923\n",
      "i: 480500, loss_tot: 201.50389556769048\n",
      "i: 480750, loss_tot: 247.19563501064897\n",
      "i: 481000, loss_tot: 222.24282273844167\n",
      "i: 481250, loss_tot: 226.26063341313954\n",
      "i: 481500, loss_tot: 222.1871844551619\n",
      "i: 481750, loss_tot: 231.48375830838674\n",
      "i: 482000, loss_tot: 207.4816048598646\n",
      "i: 482250, loss_tot: 233.10912881278816\n",
      "i: 482500, loss_tot: 273.9359537420619\n",
      "i: 482750, loss_tot: 185.2144011883624\n",
      "i: 483000, loss_tot: 220.72960210168966\n",
      "i: 483250, loss_tot: 260.2929305419163\n",
      "i: 483500, loss_tot: 166.24266065295552\n",
      "i: 483750, loss_tot: 232.02296081786503\n",
      "i: 484000, loss_tot: 268.6825524004828\n",
      "i: 484250, loss_tot: 164.66896385255237\n",
      "i: 484500, loss_tot: 191.11171686718706\n",
      "i: 484750, loss_tot: 221.58556792729337\n",
      "i: 485000, loss_tot: 239.4096995827905\n",
      "i: 485250, loss_tot: 216.31321211016504\n",
      "i: 485500, loss_tot: 253.38400792936534\n",
      "i: 485750, loss_tot: 206.53612496341805\n",
      "i: 486000, loss_tot: 209.53243839545584\n",
      "i: 486250, loss_tot: 200.07320808022268\n",
      "i: 486500, loss_tot: 215.86554094612876\n",
      "i: 486750, loss_tot: 262.85274794872765\n",
      "i: 487000, loss_tot: 266.02919910442046\n",
      "i: 487250, loss_tot: 247.8156698966821\n",
      "i: 487500, loss_tot: 244.43456825224203\n",
      "i: 487750, loss_tot: 216.9075666189826\n",
      "i: 488000, loss_tot: 235.71550745248794\n",
      "i: 488250, loss_tot: 209.99702336702444\n",
      "i: 488500, loss_tot: 259.4600093955451\n",
      "i: 488750, loss_tot: 201.13473810246506\n",
      "i: 489000, loss_tot: 215.82132276047253\n",
      "i: 489250, loss_tot: 203.9840761452203\n",
      "i: 489500, loss_tot: 193.04814565880224\n",
      "i: 489750, loss_tot: 279.5856442736559\n",
      "i: 490000, loss_tot: 187.39013767494427\n",
      "i: 490250, loss_tot: 231.56913782377612\n",
      "i: 490500, loss_tot: 213.778808887938\n",
      "i: 490750, loss_tot: 182.9680362700997\n",
      "i: 491000, loss_tot: 214.468864283961\n",
      "i: 491250, loss_tot: 231.6073633639235\n",
      "i: 491500, loss_tot: 188.29878929159662\n",
      "i: 491750, loss_tot: 207.31943111691507\n",
      "i: 492000, loss_tot: 208.1338586080799\n",
      "i: 492250, loss_tot: 252.2491547487017\n",
      "i: 492500, loss_tot: 252.00324000709224\n",
      "i: 492750, loss_tot: 198.8808811683094\n",
      "i: 493000, loss_tot: 289.26868341196445\n",
      "i: 493250, loss_tot: 221.8766486775686\n",
      "i: 493500, loss_tot: 216.5918116218364\n",
      "i: 493750, loss_tot: 242.8813230419194\n",
      "i: 494000, loss_tot: 255.11477475361434\n",
      "i: 494250, loss_tot: 209.75534753900953\n",
      "i: 494500, loss_tot: 213.83768213031607\n",
      "i: 494750, loss_tot: 240.2689206604226\n",
      "i: 495000, loss_tot: 229.3530999096416\n",
      "i: 495250, loss_tot: 244.24439914511095\n",
      "i: 495500, loss_tot: 230.35353807736772\n",
      "i: 495750, loss_tot: 217.6828899166033\n",
      "i: 496000, loss_tot: 185.6389950938543\n",
      "i: 496250, loss_tot: 236.45497503907885\n",
      "i: 496500, loss_tot: 235.22385196545474\n",
      "i: 496750, loss_tot: 230.844575863129\n",
      "i: 497000, loss_tot: 211.35394792599894\n",
      "i: 497250, loss_tot: 218.701190274574\n",
      "i: 497500, loss_tot: 238.18083415182306\n",
      "i: 497750, loss_tot: 209.07404064549976\n",
      "i: 498000, loss_tot: 217.35320359369274\n",
      "i: 498250, loss_tot: 179.54700246180175\n",
      "i: 498500, loss_tot: 219.74289197328034\n",
      "i: 498750, loss_tot: 187.94239096793527\n",
      "i: 499000, loss_tot: 231.21101137987134\n",
      "i: 499250, loss_tot: 274.9980497610582\n",
      "i: 499500, loss_tot: 191.870766318206\n",
      "i: 499750, loss_tot: 203.75266535789422\n",
      "i: 500000, loss_tot: 251.0780637146371\n",
      "i: 500250, loss_tot: 243.23852714320645\n",
      "i: 500500, loss_tot: 208.11379558137182\n",
      "i: 500750, loss_tot: 274.89276402762624\n",
      "i: 501000, loss_tot: 223.87038351010182\n",
      "i: 501250, loss_tot: 228.5737312676289\n",
      "i: 501500, loss_tot: 229.50769136178772\n",
      "i: 501750, loss_tot: 219.93823602967547\n",
      "i: 502000, loss_tot: 196.01195853599114\n",
      "i: 502250, loss_tot: 236.64670296761665\n",
      "i: 502500, loss_tot: 232.39846038144088\n",
      "i: 502750, loss_tot: 193.5194944735952\n",
      "i: 503000, loss_tot: 266.09900042529915\n",
      "i: 503250, loss_tot: 242.65221259461362\n",
      "i: 503500, loss_tot: 233.08108181866382\n",
      "i: 503750, loss_tot: 301.6320977283618\n",
      "i: 504000, loss_tot: 270.78587447273077\n",
      "i: 504250, loss_tot: 250.36937439367352\n",
      "i: 504500, loss_tot: 304.8713601781058\n",
      "i: 504750, loss_tot: 177.23780044980586\n",
      "i: 505000, loss_tot: 206.0631672795082\n",
      "i: 505250, loss_tot: 255.73656735265627\n",
      "i: 505500, loss_tot: 232.33158541458891\n",
      "i: 505750, loss_tot: 210.11480613811872\n",
      "i: 506000, loss_tot: 172.15094345776015\n",
      "i: 506250, loss_tot: 213.0546056819323\n",
      "i: 506500, loss_tot: 210.4934421081736\n",
      "i: 506750, loss_tot: 217.97386033747955\n",
      "i: 507000, loss_tot: 198.1245449961438\n",
      "i: 507250, loss_tot: 191.92167911149096\n",
      "i: 507500, loss_tot: 230.82383766822517\n",
      "i: 507750, loss_tot: 209.67660722909494\n",
      "i: 508000, loss_tot: 176.1973001809651\n",
      "i: 508250, loss_tot: 223.38477684827555\n",
      "i: 508500, loss_tot: 219.10673245527548\n",
      "i: 508750, loss_tot: 217.4706524788821\n",
      "i: 509000, loss_tot: 236.93447103570682\n",
      "i: 509250, loss_tot: 230.4402949317397\n",
      "i: 509500, loss_tot: 165.29750293607358\n",
      "i: 509750, loss_tot: 187.35199703280117\n",
      "i: 510000, loss_tot: 233.69543347943363\n",
      "i: 510250, loss_tot: 211.50751577889466\n",
      "i: 510500, loss_tot: 197.29668667186982\n",
      "i: 510750, loss_tot: 221.14138470322607\n",
      "i: 511000, loss_tot: 233.02938142568928\n",
      "i: 511250, loss_tot: 226.96313860060442\n",
      "i: 511500, loss_tot: 227.8259416579879\n",
      "i: 511750, loss_tot: 243.7674733223184\n",
      "i: 512000, loss_tot: 244.8593224248478\n",
      "i: 512250, loss_tot: 201.34361392721533\n",
      "i: 512500, loss_tot: 261.7770319799101\n",
      "i: 512750, loss_tot: 231.30878907838837\n",
      "i: 513000, loss_tot: 157.49101879598572\n",
      "i: 513250, loss_tot: 231.76906917228362\n",
      "i: 513500, loss_tot: 271.6778775393183\n",
      "i: 513750, loss_tot: 185.1180997574702\n",
      "i: 514000, loss_tot: 216.96858532590792\n",
      "i: 514250, loss_tot: 191.58111939238384\n",
      "i: 514500, loss_tot: 200.1415024881997\n",
      "i: 514750, loss_tot: 221.9001321137672\n",
      "i: 515000, loss_tot: 233.12928939279703\n",
      "i: 515250, loss_tot: 220.74312024378685\n",
      "i: 515500, loss_tot: 193.8467532760289\n",
      "i: 515750, loss_tot: 210.36616753871095\n",
      "i: 516000, loss_tot: 253.69246145604643\n",
      "i: 516250, loss_tot: 154.79799089794977\n",
      "i: 516500, loss_tot: 218.00766074130806\n",
      "i: 516750, loss_tot: 240.89197408577195\n",
      "i: 517000, loss_tot: 232.86780997599737\n",
      "i: 517250, loss_tot: 242.2430787249474\n",
      "i: 517500, loss_tot: 223.62536545010283\n",
      "i: 517750, loss_tot: 200.37506450805245\n",
      "i: 518000, loss_tot: 224.5587715215422\n",
      "i: 518250, loss_tot: 207.84757771697892\n",
      "i: 518500, loss_tot: 305.4968859416573\n",
      "i: 518750, loss_tot: 236.27281054976382\n",
      "i: 519000, loss_tot: 220.2209308861471\n",
      "i: 519250, loss_tot: 236.95093168372057\n",
      "i: 519500, loss_tot: 218.49703373013529\n",
      "i: 519750, loss_tot: 236.82246210383693\n",
      "i: 520000, loss_tot: 232.21630705833442\n",
      "i: 520250, loss_tot: 220.7506104165165\n",
      "i: 520500, loss_tot: 200.86774531730532\n",
      "i: 520750, loss_tot: 246.77265825434995\n",
      "i: 521000, loss_tot: 177.4073095058653\n",
      "i: 521250, loss_tot: 243.85313356704017\n",
      "i: 521500, loss_tot: 218.92548633192914\n",
      "i: 521750, loss_tot: 261.08171433034437\n",
      "i: 522000, loss_tot: 179.17384761494645\n",
      "i: 522250, loss_tot: 182.4239645521622\n",
      "i: 522500, loss_tot: 293.92527530821445\n",
      "i: 522750, loss_tot: 245.6780106809357\n",
      "i: 523000, loss_tot: 253.96383313574137\n",
      "i: 523250, loss_tot: 239.054093619255\n",
      "i: 523500, loss_tot: 228.97616608316778\n",
      "i: 523750, loss_tot: 191.3181374642346\n",
      "i: 524000, loss_tot: 193.6213576300218\n",
      "i: 524250, loss_tot: 231.70118023183196\n",
      "i: 524500, loss_tot: 217.17936839042284\n",
      "i: 524750, loss_tot: 182.96962364155684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 525000, loss_tot: 215.64893132783575\n",
      "i: 525250, loss_tot: 218.4641618114186\n",
      "i: 525500, loss_tot: 222.0314932494838\n",
      "i: 525750, loss_tot: 223.77845084885456\n",
      "i: 526000, loss_tot: 180.52128949994454\n",
      "i: 526250, loss_tot: 222.80871001239052\n",
      "i: 526500, loss_tot: 207.36412023667668\n",
      "i: 526750, loss_tot: 248.59857952344962\n",
      "i: 527000, loss_tot: 232.36229851009332\n",
      "i: 527250, loss_tot: 267.6980154099376\n",
      "i: 527500, loss_tot: 268.18861017156394\n",
      "i: 527750, loss_tot: 251.8099386283281\n",
      "i: 528000, loss_tot: 225.8331625523651\n",
      "i: 528250, loss_tot: 247.97563554794408\n",
      "i: 528500, loss_tot: 211.58799455771222\n",
      "i: 528750, loss_tot: 209.16452857160476\n",
      "i: 529000, loss_tot: 253.62148275386397\n",
      "i: 529250, loss_tot: 244.97738266725514\n",
      "i: 529500, loss_tot: 205.6396378662905\n",
      "i: 529750, loss_tot: 202.65135761235956\n",
      "i: 530000, loss_tot: 243.2207071040501\n",
      "i: 530250, loss_tot: 203.9787352422066\n",
      "i: 530500, loss_tot: 205.23582799309864\n",
      "i: 530750, loss_tot: 261.36598081196195\n",
      "i: 531000, loss_tot: 230.96871236183102\n",
      "i: 531250, loss_tot: 221.67427122704686\n",
      "i: 531500, loss_tot: 191.37892578964122\n",
      "i: 531750, loss_tot: 203.90324124177744\n",
      "i: 532000, loss_tot: 212.84055898063815\n",
      "i: 532250, loss_tot: 224.2324102746835\n",
      "i: 532500, loss_tot: 246.24963122496032\n",
      "i: 532750, loss_tot: 256.7116644250311\n",
      "i: 533000, loss_tot: 205.16433856848397\n",
      "i: 533250, loss_tot: 220.6365694824752\n",
      "i: 533500, loss_tot: 169.01636481433175\n",
      "i: 533750, loss_tot: 243.3915302030492\n",
      "i: 534000, loss_tot: 220.2290246196743\n",
      "i: 534250, loss_tot: 195.12572344972287\n",
      "i: 534500, loss_tot: 260.44541052372625\n",
      "i: 534750, loss_tot: 166.67884308802277\n",
      "i: 535000, loss_tot: 200.57511682723415\n",
      "i: 535250, loss_tot: 211.46725602115504\n",
      "i: 535500, loss_tot: 205.03762542433805\n",
      "i: 535750, loss_tot: 225.73215521086706\n",
      "i: 536000, loss_tot: 273.6817179532873\n",
      "i: 536250, loss_tot: 298.3348193904292\n",
      "i: 536500, loss_tot: 259.0425336049001\n",
      "i: 536750, loss_tot: 232.6529641453934\n",
      "i: 537000, loss_tot: 210.5241514778207\n",
      "i: 537250, loss_tot: 236.98072492528837\n",
      "i: 537500, loss_tot: 204.5880672789429\n",
      "i: 537750, loss_tot: 229.77573655054613\n",
      "i: 538000, loss_tot: 213.24326554896572\n",
      "i: 538250, loss_tot: 241.87682492220154\n",
      "i: 538500, loss_tot: 205.0301359436626\n",
      "i: 538750, loss_tot: 211.63656499091098\n",
      "i: 539000, loss_tot: 224.97713318760506\n",
      "i: 539250, loss_tot: 213.61015993399334\n",
      "i: 539500, loss_tot: 188.06572107477848\n",
      "i: 539750, loss_tot: 188.9558180840325\n",
      "i: 540000, loss_tot: 227.21118508345447\n",
      "i: 540250, loss_tot: 231.645340074252\n",
      "i: 540500, loss_tot: 215.59413499489813\n",
      "i: 540750, loss_tot: 239.6734335092595\n",
      "i: 541000, loss_tot: 276.3380603399017\n",
      "i: 541250, loss_tot: 235.93282239838504\n",
      "i: 541500, loss_tot: 277.47200588914563\n",
      "i: 541750, loss_tot: 189.63574894972146\n",
      "i: 542000, loss_tot: 262.18936453518495\n",
      "i: 542250, loss_tot: 219.93096097730566\n",
      "i: 542500, loss_tot: 203.82571467107692\n",
      "i: 542750, loss_tot: 251.63600260667081\n",
      "i: 543000, loss_tot: 247.2521602217108\n",
      "i: 543250, loss_tot: 218.9297080910206\n",
      "i: 543500, loss_tot: 219.20492843328648\n",
      "i: 543750, loss_tot: 197.57654634233563\n",
      "i: 544000, loss_tot: 258.846118582171\n",
      "i: 544250, loss_tot: 228.06506552103448\n",
      "i: 544500, loss_tot: 209.53387132540112\n",
      "i: 544750, loss_tot: 228.3540553235737\n",
      "i: 545000, loss_tot: 211.72832443120924\n",
      "i: 545250, loss_tot: 269.32011554700034\n",
      "i: 545500, loss_tot: 175.42364661868666\n",
      "i: 545750, loss_tot: 179.64235524645468\n",
      "i: 546000, loss_tot: 247.65172560544218\n",
      "i: 546250, loss_tot: 225.18223572463737\n",
      "i: 546500, loss_tot: 170.84117814749945\n",
      "i: 546750, loss_tot: 220.8574562216553\n",
      "i: 547000, loss_tot: 236.08965651703417\n",
      "i: 547250, loss_tot: 244.20890415833452\n",
      "i: 547500, loss_tot: 262.95244031571985\n",
      "i: 547750, loss_tot: 209.3107395574026\n",
      "i: 548000, loss_tot: 196.05298138865484\n",
      "i: 548250, loss_tot: 204.35855908372264\n",
      "i: 548500, loss_tot: 227.4785346808021\n",
      "i: 548750, loss_tot: 252.07256123490632\n",
      "i: 549000, loss_tot: 241.58361055921563\n",
      "i: 549250, loss_tot: 251.26067886205158\n",
      "i: 549500, loss_tot: 221.6961316573713\n",
      "i: 549750, loss_tot: 207.6434592147229\n",
      "i: 550000, loss_tot: 271.48230689330956\n",
      "i: 550250, loss_tot: 190.19071346543612\n",
      "i: 550500, loss_tot: 215.5197073840235\n",
      "i: 550750, loss_tot: 227.52127120384947\n",
      "i: 551000, loss_tot: 250.88551156973028\n",
      "i: 551250, loss_tot: 170.40039154691505\n",
      "i: 551500, loss_tot: 212.0384472725918\n",
      "i: 551750, loss_tot: 235.62939671880216\n",
      "i: 552000, loss_tot: 219.37157806762727\n",
      "i: 552250, loss_tot: 233.13359816895797\n",
      "i: 552500, loss_tot: 215.2378508700826\n",
      "i: 552750, loss_tot: 290.371815785979\n",
      "i: 553000, loss_tot: 230.39352677250804\n",
      "i: 553250, loss_tot: 219.8653141934122\n",
      "i: 553500, loss_tot: 197.36721979276277\n",
      "i: 553750, loss_tot: 196.335165414699\n",
      "i: 554000, loss_tot: 176.18151927240177\n",
      "i: 554250, loss_tot: 224.57967675776968\n",
      "i: 554500, loss_tot: 254.86260632750768\n",
      "i: 554750, loss_tot: 212.19397707269994\n",
      "i: 555000, loss_tot: 233.2914914245996\n",
      "i: 555250, loss_tot: 230.21992869998067\n",
      "i: 555500, loss_tot: 195.77830405958812\n",
      "i: 555750, loss_tot: 202.51061199446474\n",
      "i: 556000, loss_tot: 216.07386634409895\n",
      "i: 556250, loss_tot: 185.16759142651415\n",
      "i: 556500, loss_tot: 227.13794670578096\n",
      "i: 556750, loss_tot: 254.8514420570305\n",
      "i: 557000, loss_tot: 222.44626287139124\n",
      "i: 557250, loss_tot: 264.95758745906875\n",
      "i: 557500, loss_tot: 231.05415144180412\n",
      "i: 557750, loss_tot: 223.17640541057514\n",
      "i: 558000, loss_tot: 206.26441476449617\n",
      "i: 558250, loss_tot: 193.56280516996515\n",
      "i: 558500, loss_tot: 227.71559912431314\n",
      "i: 558750, loss_tot: 202.62394985263074\n",
      "i: 559000, loss_tot: 222.1317274845764\n",
      "i: 559250, loss_tot: 203.01460451282009\n",
      "i: 559500, loss_tot: 215.07614099633093\n",
      "i: 559750, loss_tot: 197.86241671846074\n",
      "i: 560000, loss_tot: 245.94178548453033\n",
      "i: 560250, loss_tot: 237.9746438270688\n",
      "i: 560500, loss_tot: 178.5558154656436\n",
      "i: 560750, loss_tot: 231.22297747772188\n",
      "i: 561000, loss_tot: 220.43965380820038\n",
      "i: 561250, loss_tot: 241.29138784815092\n",
      "i: 561500, loss_tot: 173.58177155156628\n",
      "i: 561750, loss_tot: 196.67399095624162\n",
      "i: 562000, loss_tot: 260.09124290293636\n",
      "i: 562250, loss_tot: 247.80244412244298\n",
      "i: 562500, loss_tot: 203.10508322932768\n",
      "i: 562750, loss_tot: 219.18953350060852\n",
      "i: 563000, loss_tot: 206.33625126314217\n",
      "i: 563250, loss_tot: 245.241078548067\n",
      "i: 563500, loss_tot: 266.09373855751005\n",
      "i: 563750, loss_tot: 219.0711893689132\n",
      "i: 564000, loss_tot: 237.42219795599922\n",
      "i: 564250, loss_tot: 262.77814927936066\n",
      "i: 564500, loss_tot: 202.16222468716907\n",
      "i: 564750, loss_tot: 245.2206668853195\n",
      "i: 565000, loss_tot: 249.24820569865523\n",
      "i: 565250, loss_tot: 213.04631788123658\n",
      "i: 565500, loss_tot: 205.8458081373343\n",
      "i: 565750, loss_tot: 245.24880447658427\n",
      "i: 566000, loss_tot: 207.58289470507071\n",
      "i: 566250, loss_tot: 196.89136866550894\n",
      "i: 566500, loss_tot: 230.9358620911254\n",
      "i: 566750, loss_tot: 208.6335977896071\n",
      "i: 567000, loss_tot: 191.83690079576104\n",
      "i: 567250, loss_tot: 219.67501877552016\n",
      "i: 567500, loss_tot: 186.6478576186215\n",
      "i: 567750, loss_tot: 236.58963764013012\n",
      "i: 568000, loss_tot: 255.05602508193465\n",
      "i: 568250, loss_tot: 230.63132787444908\n",
      "i: 568500, loss_tot: 208.0490398982837\n",
      "i: 568750, loss_tot: 204.92557841177575\n",
      "i: 569000, loss_tot: 208.6167460056534\n",
      "i: 569250, loss_tot: 212.48448568795575\n",
      "i: 569500, loss_tot: 184.2515138767485\n",
      "i: 569750, loss_tot: 240.68047688254228\n",
      "i: 570000, loss_tot: 225.74927936441324\n",
      "i: 570250, loss_tot: 234.06090027723286\n",
      "i: 570500, loss_tot: 210.1668987204028\n",
      "i: 570750, loss_tot: 202.57512916809975\n",
      "i: 571000, loss_tot: 229.20635711081442\n",
      "i: 571250, loss_tot: 202.1452828467136\n",
      "i: 571500, loss_tot: 242.19225240389497\n",
      "i: 571750, loss_tot: 256.3743677463363\n",
      "i: 572000, loss_tot: 192.54053413347341\n",
      "i: 572250, loss_tot: 246.089682168467\n",
      "i: 572500, loss_tot: 201.48277834818234\n",
      "i: 572750, loss_tot: 202.53635640185792\n",
      "i: 573000, loss_tot: 231.50570488770734\n",
      "i: 573250, loss_tot: 173.20619325219502\n",
      "i: 573500, loss_tot: 264.09600611583517\n",
      "i: 573750, loss_tot: 174.50135891852202\n",
      "i: 574000, loss_tot: 239.82105756378266\n",
      "i: 574250, loss_tot: 195.22462369278074\n",
      "i: 574500, loss_tot: 219.529196763559\n",
      "i: 574750, loss_tot: 247.91074181593606\n",
      "i: 575000, loss_tot: 233.9882693731971\n",
      "i: 575250, loss_tot: 226.85655098287512\n",
      "i: 575500, loss_tot: 216.90498288537427\n",
      "i: 575750, loss_tot: 188.0574895657692\n",
      "i: 576000, loss_tot: 157.6145626740862\n",
      "i: 576250, loss_tot: 186.99260389739678\n",
      "i: 576500, loss_tot: 242.48097955014032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 576750, loss_tot: 262.9644492306281\n",
      "i: 577000, loss_tot: 268.5376177310664\n",
      "i: 577250, loss_tot: 189.55169617084786\n",
      "i: 577500, loss_tot: 199.54723428823053\n",
      "i: 577750, loss_tot: 242.69521252424457\n",
      "i: 578000, loss_tot: 270.31080128835515\n",
      "i: 578250, loss_tot: 197.70752793615802\n",
      "i: 578500, loss_tot: 231.74930546165444\n",
      "i: 578750, loss_tot: 241.2502410798148\n",
      "i: 579000, loss_tot: 261.1486596222785\n",
      "i: 579250, loss_tot: 210.3658348857169\n",
      "i: 579500, loss_tot: 206.8673452442825\n",
      "i: 579750, loss_tot: 187.77929957350017\n",
      "i: 580000, loss_tot: 209.40448521762076\n",
      "i: 580250, loss_tot: 197.9746032600222\n",
      "i: 580500, loss_tot: 171.59750246102863\n",
      "i: 580750, loss_tot: 208.41313536195085\n",
      "i: 581000, loss_tot: 293.07122738131324\n",
      "i: 581250, loss_tot: 192.96526285238332\n",
      "i: 581500, loss_tot: 248.50760428451002\n",
      "i: 581750, loss_tot: 197.31304269610075\n",
      "i: 582000, loss_tot: 210.24056498820428\n",
      "i: 582250, loss_tot: 242.51875421423466\n",
      "i: 582500, loss_tot: 212.28686331769453\n",
      "i: 582750, loss_tot: 237.9307080650609\n",
      "i: 583000, loss_tot: 214.71237821792295\n",
      "i: 583250, loss_tot: 202.4242115643248\n",
      "i: 583500, loss_tot: 229.66304633159191\n",
      "i: 583750, loss_tot: 232.9128917521052\n",
      "i: 584000, loss_tot: 202.69075050272983\n",
      "i: 584250, loss_tot: 226.27800028586455\n",
      "i: 584500, loss_tot: 254.0309837576421\n",
      "i: 584750, loss_tot: 221.0262821908234\n",
      "i: 585000, loss_tot: 214.30862882278626\n",
      "i: 585250, loss_tot: 237.00099439526676\n",
      "i: 585500, loss_tot: 170.55068574858987\n",
      "i: 585750, loss_tot: 257.752458305493\n",
      "i: 586000, loss_tot: 256.99638351101135\n",
      "i: 586250, loss_tot: 208.68605558764423\n",
      "i: 586500, loss_tot: 231.32097785820253\n",
      "i: 586750, loss_tot: 203.92723890639\n",
      "i: 587000, loss_tot: 196.2084597683698\n",
      "i: 587250, loss_tot: 205.13625620872713\n",
      "i: 587500, loss_tot: 262.709613448494\n",
      "i: 587750, loss_tot: 189.47514545157784\n",
      "i: 588000, loss_tot: 234.35433043876662\n",
      "i: 588250, loss_tot: 194.5665742148785\n",
      "i: 588500, loss_tot: 186.52767261358895\n",
      "i: 588750, loss_tot: 216.0751086442708\n",
      "i: 589000, loss_tot: 218.76864021361573\n",
      "i: 589250, loss_tot: 200.28940623312724\n",
      "i: 589500, loss_tot: 248.95642086993902\n",
      "i: 589750, loss_tot: 226.60212114659623\n",
      "i: 590000, loss_tot: 194.27612090472132\n",
      "i: 590250, loss_tot: 182.19306821123698\n",
      "i: 590500, loss_tot: 199.28580933710583\n",
      "i: 590750, loss_tot: 229.85649016194512\n",
      "i: 591000, loss_tot: 221.1922534260332\n",
      "i: 591250, loss_tot: 258.16678845520136\n",
      "i: 591500, loss_tot: 260.64330510469154\n",
      "i: 591750, loss_tot: 192.08969150925844\n",
      "i: 592000, loss_tot: 204.92344804879352\n",
      "i: 592250, loss_tot: 245.92949445010746\n",
      "i: 592500, loss_tot: 260.5455421211757\n",
      "i: 592750, loss_tot: 173.56287282095013\n",
      "i: 593000, loss_tot: 225.25179055404152\n",
      "i: 593250, loss_tot: 193.13814191225828\n",
      "i: 593500, loss_tot: 232.19210697626306\n",
      "i: 593750, loss_tot: 238.40864071181045\n",
      "i: 594000, loss_tot: 217.01825975079169\n",
      "i: 594250, loss_tot: 225.06707067147624\n",
      "i: 594500, loss_tot: 262.09794713891114\n",
      "i: 594750, loss_tot: 171.04106524739416\n",
      "i: 595000, loss_tot: 240.24708179237786\n",
      "i: 595250, loss_tot: 167.9262649161648\n",
      "i: 595500, loss_tot: 223.88952701157424\n",
      "i: 595750, loss_tot: 236.3122114874702\n",
      "i: 596000, loss_tot: 225.10943588553928\n",
      "i: 596250, loss_tot: 237.72559414575812\n",
      "i: 596500, loss_tot: 229.34922118200456\n",
      "i: 596750, loss_tot: 256.1201184996925\n",
      "i: 597000, loss_tot: 243.81284978671465\n",
      "i: 597250, loss_tot: 214.1058005032137\n",
      "i: 597500, loss_tot: 241.28582025591285\n",
      "i: 597750, loss_tot: 218.40020935120992\n",
      "i: 598000, loss_tot: 280.1940349257535\n",
      "i: 598250, loss_tot: 204.1795549175609\n",
      "i: 598500, loss_tot: 242.5391478590481\n",
      "i: 598750, loss_tot: 248.59440474733717\n",
      "i: 599000, loss_tot: 227.20435159449\n",
      "i: 599250, loss_tot: 246.17437655958355\n",
      "i: 599500, loss_tot: 198.17124446025147\n",
      "i: 599750, loss_tot: 207.2829132046085\n",
      "i: 600000, loss_tot: 227.86598510356154\n",
      "i: 600250, loss_tot: 181.54935016610193\n",
      "i: 600500, loss_tot: 198.17931485111956\n",
      "i: 600750, loss_tot: 219.55092235116666\n",
      "i: 601000, loss_tot: 239.69208194479464\n",
      "i: 601250, loss_tot: 216.6121139220103\n",
      "i: 601500, loss_tot: 215.76313419992977\n",
      "i: 601750, loss_tot: 192.60065996800668\n",
      "i: 602000, loss_tot: 220.40903582809725\n",
      "i: 602250, loss_tot: 232.23645907149074\n",
      "i: 602500, loss_tot: 225.59459777529838\n",
      "i: 602750, loss_tot: 205.85772749300813\n",
      "i: 603000, loss_tot: 279.16101598881517\n",
      "i: 603250, loss_tot: 208.2832160401607\n",
      "i: 603500, loss_tot: 234.14536077814853\n",
      "i: 603750, loss_tot: 199.9412222207189\n",
      "i: 604000, loss_tot: 240.60013480281458\n",
      "i: 604250, loss_tot: 246.7083004364511\n",
      "i: 604500, loss_tot: 262.8217208910112\n",
      "i: 604750, loss_tot: 244.1089258358628\n",
      "i: 605000, loss_tot: 221.5547248772718\n",
      "i: 605250, loss_tot: 241.49322520784145\n",
      "i: 605500, loss_tot: 248.49046610515586\n",
      "i: 605750, loss_tot: 249.32938651405274\n",
      "i: 606000, loss_tot: 161.1535225029662\n",
      "i: 606250, loss_tot: 224.33791086182114\n",
      "i: 606500, loss_tot: 203.06033266649726\n",
      "i: 606750, loss_tot: 190.05397608536816\n",
      "i: 607000, loss_tot: 185.4009033522047\n",
      "i: 607250, loss_tot: 288.6691418293596\n",
      "i: 607500, loss_tot: 224.0581768959879\n",
      "i: 607750, loss_tot: 233.88682085469424\n",
      "i: 608000, loss_tot: 186.36855654771335\n",
      "i: 608250, loss_tot: 232.84871745754702\n",
      "i: 608500, loss_tot: 243.25298397218052\n",
      "i: 608750, loss_tot: 222.57645232655574\n",
      "i: 609000, loss_tot: 226.54706272267737\n",
      "i: 609250, loss_tot: 212.16825997218024\n",
      "i: 609500, loss_tot: 216.1647650111094\n",
      "i: 609750, loss_tot: 201.24863075668\n",
      "i: 610000, loss_tot: 209.4741036489399\n",
      "i: 610250, loss_tot: 221.20090930532197\n",
      "i: 610500, loss_tot: 248.35479381738057\n",
      "i: 610750, loss_tot: 279.2305289581338\n",
      "i: 611000, loss_tot: 188.03654942025432\n",
      "i: 611250, loss_tot: 248.0139611174735\n",
      "i: 611500, loss_tot: 263.61697578126314\n",
      "i: 611750, loss_tot: 201.19978512791073\n",
      "i: 612000, loss_tot: 179.60330384777882\n",
      "i: 612250, loss_tot: 221.82430575906335\n",
      "i: 612500, loss_tot: 231.60896268770048\n",
      "i: 612750, loss_tot: 230.08940719307168\n",
      "i: 613000, loss_tot: 232.8846429477644\n",
      "i: 613250, loss_tot: 230.8960537266487\n",
      "i: 613500, loss_tot: 228.1645666206528\n",
      "i: 613750, loss_tot: 219.22128881501732\n",
      "i: 614000, loss_tot: 180.92869156979964\n",
      "i: 614250, loss_tot: 250.32033533872877\n",
      "i: 614500, loss_tot: 216.96651467038046\n",
      "i: 614750, loss_tot: 263.915587220639\n",
      "i: 615000, loss_tot: 192.08968483593796\n",
      "i: 615250, loss_tot: 231.11114679221478\n",
      "i: 615500, loss_tot: 241.67801331028576\n",
      "i: 615750, loss_tot: 270.15153961427046\n",
      "i: 616000, loss_tot: 193.39175972276135\n",
      "i: 616250, loss_tot: 217.4741330437502\n",
      "i: 616500, loss_tot: 204.9913180404692\n",
      "i: 616750, loss_tot: 246.47927578787414\n",
      "i: 617000, loss_tot: 229.6496283189094\n",
      "i: 617250, loss_tot: 177.57969449610218\n",
      "i: 617500, loss_tot: 216.5149096258942\n",
      "i: 617750, loss_tot: 215.07591400052422\n",
      "i: 618000, loss_tot: 271.89593070195826\n",
      "i: 618250, loss_tot: 203.37819821369544\n",
      "i: 618500, loss_tot: 236.10364935525692\n",
      "i: 618750, loss_tot: 243.85869875485542\n",
      "i: 619000, loss_tot: 249.1014488676627\n",
      "i: 619250, loss_tot: 170.4108478731296\n",
      "i: 619500, loss_tot: 237.65385913055573\n",
      "i: 619750, loss_tot: 211.2446447829716\n",
      "i: 620000, loss_tot: 182.26403360146506\n",
      "i: 620250, loss_tot: 246.2260470811557\n",
      "i: 620500, loss_tot: 163.46750533252202\n",
      "i: 620750, loss_tot: 193.87970530314604\n",
      "i: 621000, loss_tot: 218.56191982402953\n",
      "i: 621250, loss_tot: 215.29213190287527\n",
      "i: 621500, loss_tot: 208.21489889239388\n",
      "i: 621750, loss_tot: 216.8001826900273\n",
      "i: 622000, loss_tot: 250.9345936975722\n",
      "i: 622250, loss_tot: 201.03616557008587\n",
      "i: 622500, loss_tot: 222.1348112872312\n",
      "i: 622750, loss_tot: 221.4388638479603\n",
      "i: 623000, loss_tot: 249.3523145943571\n",
      "i: 623250, loss_tot: 219.48909409845714\n",
      "i: 623500, loss_tot: 172.59519418746333\n",
      "i: 623750, loss_tot: 219.82270222295773\n",
      "i: 624000, loss_tot: 219.45930729242977\n",
      "i: 624250, loss_tot: 179.3362298045447\n",
      "i: 624500, loss_tot: 197.43119885773748\n",
      "i: 624750, loss_tot: 203.54134423567447\n",
      "i: 625000, loss_tot: 234.47614392824937\n",
      "i: 625250, loss_tot: 229.3481447561027\n",
      "i: 625500, loss_tot: 262.97925032813333\n",
      "i: 625750, loss_tot: 169.52678575329952\n",
      "i: 626000, loss_tot: 204.6200223422679\n",
      "i: 626250, loss_tot: 210.0640628857552\n",
      "i: 626500, loss_tot: 257.98757470672484\n",
      "i: 626750, loss_tot: 243.0416721056495\n",
      "i: 627000, loss_tot: 224.68118045013398\n",
      "i: 627250, loss_tot: 254.90806578622085\n",
      "i: 627500, loss_tot: 204.15647523681776\n",
      "i: 627750, loss_tot: 205.07803631324023\n",
      "i: 628000, loss_tot: 204.96799701436422\n",
      "i: 628250, loss_tot: 193.4114131032722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 628500, loss_tot: 257.70720541239297\n",
      "i: 628750, loss_tot: 198.93611151242908\n",
      "i: 629000, loss_tot: 221.76173611864854\n",
      "i: 629250, loss_tot: 171.97616132064277\n",
      "i: 629500, loss_tot: 191.99172647357946\n",
      "i: 629750, loss_tot: 303.6225040785955\n",
      "i: 630000, loss_tot: 215.92240322075784\n",
      "i: 630250, loss_tot: 263.3211314351205\n",
      "i: 630500, loss_tot: 213.256870596895\n",
      "i: 630750, loss_tot: 204.074246023288\n",
      "i: 631000, loss_tot: 223.0984052023245\n",
      "i: 631250, loss_tot: 216.0044294408965\n",
      "i: 631500, loss_tot: 216.1279933447392\n",
      "i: 631750, loss_tot: 242.80647651409294\n",
      "i: 632000, loss_tot: 222.20492712593753\n",
      "i: 632250, loss_tot: 294.89105797845536\n",
      "i: 632500, loss_tot: 249.31122063362972\n",
      "i: 632750, loss_tot: 254.70223384037257\n",
      "i: 633000, loss_tot: 245.1876728801978\n",
      "i: 633250, loss_tot: 207.58274408710383\n",
      "i: 633500, loss_tot: 228.4439568282677\n",
      "i: 633750, loss_tot: 278.3643546783371\n",
      "i: 634000, loss_tot: 223.5838115686305\n",
      "i: 634250, loss_tot: 224.8450546283461\n",
      "i: 634500, loss_tot: 227.79137141697575\n",
      "i: 634750, loss_tot: 237.2671906418925\n",
      "i: 635000, loss_tot: 199.3455159369072\n",
      "i: 635250, loss_tot: 200.16426812365447\n",
      "i: 635500, loss_tot: 185.75767777718488\n",
      "i: 635750, loss_tot: 218.58497234007015\n",
      "i: 636000, loss_tot: 245.20310434765517\n",
      "i: 636250, loss_tot: 206.2104476371978\n",
      "i: 636500, loss_tot: 185.99536187848818\n",
      "i: 636750, loss_tot: 229.47301900829902\n",
      "i: 637000, loss_tot: 270.50617927757094\n",
      "i: 637250, loss_tot: 272.4974879496886\n",
      "i: 637500, loss_tot: 198.0172849386325\n",
      "i: 637750, loss_tot: 219.30455476117902\n",
      "i: 638000, loss_tot: 189.6922614755808\n",
      "i: 638250, loss_tot: 188.7288227828243\n",
      "i: 638500, loss_tot: 210.83772584414487\n",
      "i: 638750, loss_tot: 215.09467517128599\n",
      "i: 639000, loss_tot: 189.27582470145543\n",
      "i: 639250, loss_tot: 189.50975356552368\n",
      "i: 639500, loss_tot: 232.89729805505922\n",
      "i: 639750, loss_tot: 291.2095561555569\n",
      "i: 640000, loss_tot: 221.41571078813635\n",
      "i: 640250, loss_tot: 214.6282970591588\n",
      "i: 640500, loss_tot: 202.96720568656303\n",
      "i: 640750, loss_tot: 187.23014147370384\n",
      "i: 641000, loss_tot: 218.93430918797588\n",
      "i: 641250, loss_tot: 262.0857208388817\n",
      "i: 641500, loss_tot: 228.5338608637173\n",
      "i: 641750, loss_tot: 207.92143269038857\n",
      "i: 642000, loss_tot: 292.49355217996987\n",
      "i: 642250, loss_tot: 200.05572957370984\n",
      "i: 642500, loss_tot: 226.22314413904851\n",
      "i: 642750, loss_tot: 222.7051085996309\n",
      "i: 643000, loss_tot: 264.38462874537043\n",
      "i: 643250, loss_tot: 180.4914326994698\n",
      "i: 643500, loss_tot: 246.52587747795042\n",
      "i: 643750, loss_tot: 204.26760935938918\n",
      "i: 644000, loss_tot: 209.92850001452214\n",
      "i: 644250, loss_tot: 213.82883371189905\n",
      "i: 644500, loss_tot: 204.37318241601054\n",
      "i: 644750, loss_tot: 210.90740830998868\n",
      "i: 645000, loss_tot: 241.85441288889066\n",
      "i: 645250, loss_tot: 191.7441213181685\n",
      "i: 645500, loss_tot: 212.28895720965892\n",
      "i: 645750, loss_tot: 198.79851069952855\n",
      "i: 646000, loss_tot: 192.0407875038218\n",
      "i: 646250, loss_tot: 200.0369871342834\n",
      "i: 646500, loss_tot: 192.1807286907846\n",
      "i: 646750, loss_tot: 233.29853863072873\n",
      "i: 647000, loss_tot: 193.9060497754882\n",
      "i: 647250, loss_tot: 222.59638231680282\n",
      "i: 647500, loss_tot: 267.02607532360724\n",
      "i: 647750, loss_tot: 157.52684378726752\n",
      "i: 648000, loss_tot: 223.57800664205723\n",
      "i: 648250, loss_tot: 247.23778901046376\n",
      "i: 648500, loss_tot: 195.6747772852931\n",
      "i: 648750, loss_tot: 243.48806649908306\n",
      "i: 649000, loss_tot: 193.31816325878026\n",
      "i: 649250, loss_tot: 201.26262691114565\n",
      "i: 649500, loss_tot: 234.01845332820434\n",
      "i: 649750, loss_tot: 181.77093858486973\n",
      "i: 650000, loss_tot: 256.6679406035045\n",
      "i: 650250, loss_tot: 232.0364592865534\n",
      "i: 650500, loss_tot: 210.11655330377397\n",
      "i: 650750, loss_tot: 231.6885525437517\n",
      "i: 651000, loss_tot: 210.02541297696655\n",
      "i: 651250, loss_tot: 243.37865764319432\n",
      "i: 651500, loss_tot: 242.9183190613799\n",
      "i: 651750, loss_tot: 263.67167406735246\n",
      "i: 652000, loss_tot: 237.54173029437675\n",
      "i: 652250, loss_tot: 237.05670103678716\n",
      "i: 652500, loss_tot: 239.95640514328844\n",
      "i: 652750, loss_tot: 215.81162904996927\n",
      "i: 653000, loss_tot: 215.82844374942957\n",
      "i: 653250, loss_tot: 187.01693564104045\n",
      "i: 653500, loss_tot: 240.9672409660622\n",
      "i: 653750, loss_tot: 203.55425119797698\n",
      "i: 654000, loss_tot: 219.69055760881216\n",
      "i: 654250, loss_tot: 175.1860306083475\n",
      "i: 654500, loss_tot: 215.53011243740355\n",
      "i: 654750, loss_tot: 190.6903829898394\n",
      "i: 655000, loss_tot: 147.3348448831332\n",
      "i: 655250, loss_tot: 189.29782110106905\n",
      "i: 655500, loss_tot: 243.0851490872167\n",
      "i: 655750, loss_tot: 251.0865529060737\n",
      "i: 656000, loss_tot: 224.48838682782835\n",
      "i: 656250, loss_tot: 202.49430397523014\n",
      "i: 656500, loss_tot: 263.7344025846439\n",
      "i: 656750, loss_tot: 190.84195731738583\n",
      "i: 657000, loss_tot: 207.81757970443397\n",
      "i: 657250, loss_tot: 257.8736627014104\n",
      "i: 657500, loss_tot: 265.5355279164994\n",
      "i: 657750, loss_tot: 212.51429111775187\n",
      "i: 658000, loss_tot: 208.72376037607995\n",
      "i: 658250, loss_tot: 214.79523681109782\n",
      "i: 658500, loss_tot: 263.4901913660474\n",
      "i: 658750, loss_tot: 272.0579218684137\n",
      "i: 659000, loss_tot: 223.81365896759556\n",
      "i: 659250, loss_tot: 194.83947399949656\n",
      "i: 659500, loss_tot: 249.31003069765313\n",
      "i: 659750, loss_tot: 192.00910491386895\n",
      "i: 660000, loss_tot: 228.8681530336896\n",
      "i: 660250, loss_tot: 211.0620447755682\n",
      "i: 660500, loss_tot: 219.28596623651683\n",
      "i: 660750, loss_tot: 196.9120780430641\n",
      "i: 661000, loss_tot: 211.11853309233646\n",
      "i: 661250, loss_tot: 231.17113288775087\n",
      "i: 661500, loss_tot: 192.0630380039511\n",
      "i: 661750, loss_tot: 187.86264247197659\n",
      "i: 662000, loss_tot: 225.2855061999987\n",
      "i: 662250, loss_tot: 214.71016218347205\n",
      "i: 662500, loss_tot: 257.6348046851295\n",
      "i: 662750, loss_tot: 222.30406003262993\n",
      "i: 663000, loss_tot: 216.58429682299496\n",
      "i: 663250, loss_tot: 237.7750867437292\n",
      "i: 663500, loss_tot: 196.48216701344703\n",
      "i: 663750, loss_tot: 257.64223737679924\n",
      "i: 664000, loss_tot: 215.3499335159408\n",
      "i: 664250, loss_tot: 182.72941079348325\n",
      "i: 664500, loss_tot: 204.18521830121998\n",
      "i: 664750, loss_tot: 183.62813140944877\n",
      "i: 665000, loss_tot: 197.7971310314536\n",
      "i: 665250, loss_tot: 242.03336111298762\n",
      "i: 665500, loss_tot: 269.327764339475\n",
      "i: 665750, loss_tot: 242.92102421885357\n",
      "i: 666000, loss_tot: 301.6484062653393\n",
      "i: 666250, loss_tot: 188.00742972154768\n",
      "i: 666500, loss_tot: 236.25368555904134\n",
      "i: 666750, loss_tot: 234.87514525114094\n",
      "i: 667000, loss_tot: 213.61729104085097\n",
      "i: 667250, loss_tot: 237.89796559639268\n",
      "i: 667500, loss_tot: 309.9164621133567\n",
      "i: 667750, loss_tot: 228.04273853210503\n",
      "i: 668000, loss_tot: 214.05603865598314\n",
      "i: 668250, loss_tot: 211.70445924222983\n",
      "i: 668500, loss_tot: 240.84698460387554\n",
      "i: 668750, loss_tot: 201.29377397569363\n",
      "i: 669000, loss_tot: 220.14661842680312\n",
      "i: 669250, loss_tot: 206.88258255328518\n",
      "i: 669500, loss_tot: 189.831328882206\n",
      "i: 669750, loss_tot: 232.45418489078665\n",
      "i: 670000, loss_tot: 172.11466665619753\n",
      "i: 670250, loss_tot: 195.96440152942466\n",
      "i: 670500, loss_tot: 196.3736180570334\n",
      "i: 670750, loss_tot: 245.79279678765226\n",
      "i: 671000, loss_tot: 191.7401859135733\n",
      "i: 671250, loss_tot: 212.59889469037415\n",
      "i: 671500, loss_tot: 210.22116524582728\n",
      "i: 671750, loss_tot: 193.50489885878022\n",
      "i: 672000, loss_tot: 235.43420240255764\n",
      "i: 672250, loss_tot: 219.84095533523708\n",
      "i: 672500, loss_tot: 188.43831041065977\n",
      "i: 672750, loss_tot: 240.73024982387375\n",
      "i: 673000, loss_tot: 178.8416531546414\n",
      "i: 673250, loss_tot: 211.14294586128554\n",
      "i: 673500, loss_tot: 191.94948220388198\n",
      "i: 673750, loss_tot: 286.0634531181771\n",
      "i: 674000, loss_tot: 236.24070787356308\n",
      "i: 674250, loss_tot: 282.11940416273075\n",
      "i: 674500, loss_tot: 199.71359350122512\n",
      "i: 674750, loss_tot: 237.01762629285477\n",
      "i: 675000, loss_tot: 276.97112850784504\n",
      "i: 675250, loss_tot: 205.8397967843128\n",
      "i: 675500, loss_tot: 220.63943407777523\n",
      "i: 675750, loss_tot: 218.86226577041438\n",
      "i: 676000, loss_tot: 229.84713301288195\n",
      "i: 676250, loss_tot: 212.25762108515949\n",
      "i: 676500, loss_tot: 220.87802570064088\n",
      "i: 676750, loss_tot: 213.3932039300073\n",
      "i: 677000, loss_tot: 238.73110426750006\n",
      "i: 677250, loss_tot: 228.5574258830701\n",
      "i: 677500, loss_tot: 209.6114718154166\n",
      "i: 677750, loss_tot: 281.33759761210445\n",
      "i: 678000, loss_tot: 230.6214018481295\n",
      "i: 678250, loss_tot: 217.90562152210157\n",
      "i: 678500, loss_tot: 240.9273012800794\n",
      "i: 678750, loss_tot: 244.57532029430476\n",
      "i: 679000, loss_tot: 248.5445055379218\n",
      "i: 679250, loss_tot: 208.5199030780863\n",
      "i: 679500, loss_tot: 228.25495160503218\n",
      "i: 679750, loss_tot: 201.68741614039598\n",
      "i: 680000, loss_tot: 241.9074285207293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 680250, loss_tot: 235.7081776235478\n",
      "i: 680500, loss_tot: 185.38965827423715\n",
      "i: 680750, loss_tot: 199.45094057596987\n",
      "i: 681000, loss_tot: 193.28871465354226\n",
      "i: 681250, loss_tot: 205.82278908068926\n",
      "i: 681500, loss_tot: 236.59931544080945\n",
      "i: 681750, loss_tot: 220.92916982158087\n",
      "i: 682000, loss_tot: 211.33308540992803\n",
      "i: 682250, loss_tot: 174.6438211685809\n",
      "i: 682500, loss_tot: 255.60148853124775\n",
      "i: 682750, loss_tot: 205.09937022564466\n",
      "i: 683000, loss_tot: 211.2707136230392\n",
      "i: 683250, loss_tot: 257.3594926194951\n",
      "i: 683500, loss_tot: 224.01556247266709\n",
      "i: 683750, loss_tot: 219.68179311581716\n",
      "i: 684000, loss_tot: 224.8729581945989\n",
      "i: 684250, loss_tot: 240.55369103688395\n",
      "i: 684500, loss_tot: 290.28361140673513\n",
      "i: 684750, loss_tot: 231.9563404605447\n",
      "i: 685000, loss_tot: 241.9770468857579\n",
      "i: 685250, loss_tot: 232.04038588774623\n",
      "i: 685500, loss_tot: 251.14558771303157\n",
      "i: 685750, loss_tot: 227.97496338438702\n",
      "i: 686000, loss_tot: 242.81701503974662\n",
      "i: 686250, loss_tot: 204.222683371288\n",
      "i: 686500, loss_tot: 205.78997046552075\n",
      "i: 686750, loss_tot: 238.8324744410676\n",
      "i: 687000, loss_tot: 290.71599010396284\n",
      "i: 687250, loss_tot: 191.90677263833814\n",
      "i: 687500, loss_tot: 189.85189637107453\n",
      "i: 687750, loss_tot: 219.9693695445543\n",
      "i: 688000, loss_tot: 201.38625834911247\n",
      "i: 688250, loss_tot: 212.77718414341587\n",
      "i: 688500, loss_tot: 228.12254390355025\n",
      "i: 688750, loss_tot: 201.61609368803045\n",
      "i: 689000, loss_tot: 244.76734874597983\n",
      "i: 689250, loss_tot: 244.46354710032887\n",
      "i: 689500, loss_tot: 275.0437696825221\n",
      "i: 689750, loss_tot: 222.0256737808617\n",
      "i: 690000, loss_tot: 239.21923146405317\n",
      "i: 690250, loss_tot: 221.83456004511746\n",
      "i: 690500, loss_tot: 259.6172678368891\n",
      "i: 690750, loss_tot: 262.37746971593066\n",
      "i: 691000, loss_tot: 202.9471786711039\n",
      "i: 691250, loss_tot: 241.21301490736758\n",
      "i: 691500, loss_tot: 257.68723151125954\n",
      "i: 691750, loss_tot: 217.21893257468707\n",
      "i: 692000, loss_tot: 204.92892750381023\n",
      "i: 692250, loss_tot: 225.36378230034373\n",
      "i: 692500, loss_tot: 204.0442547753386\n",
      "i: 692750, loss_tot: 185.13619577650033\n",
      "i: 693000, loss_tot: 225.79346929057968\n",
      "i: 693250, loss_tot: 261.9161845058389\n",
      "i: 693500, loss_tot: 215.46281587888487\n",
      "i: 693750, loss_tot: 187.59835796776838\n",
      "i: 694000, loss_tot: 202.52190615060522\n",
      "i: 694250, loss_tot: 218.98651043775956\n",
      "i: 694500, loss_tot: 162.01756058542057\n",
      "i: 694750, loss_tot: 223.28586245872896\n",
      "i: 695000, loss_tot: 207.68194642032321\n",
      "i: 695250, loss_tot: 190.1082882656448\n",
      "i: 695500, loss_tot: 225.59447801265867\n",
      "i: 695750, loss_tot: 201.823679410537\n",
      "i: 696000, loss_tot: 212.38410903436395\n",
      "i: 696250, loss_tot: 239.05185926837848\n",
      "i: 696500, loss_tot: 239.12008992755\n",
      "i: 696750, loss_tot: 204.74757647019345\n",
      "i: 697000, loss_tot: 245.6256891770102\n",
      "i: 697250, loss_tot: 237.07252763047813\n",
      "i: 697500, loss_tot: 229.73666176050676\n",
      "i: 697750, loss_tot: 297.9001008624418\n",
      "i: 698000, loss_tot: 197.71664119352653\n",
      "i: 698250, loss_tot: 225.6773850276461\n",
      "i: 698500, loss_tot: 232.36663964781786\n",
      "i: 698750, loss_tot: 258.4571081483632\n",
      "i: 699000, loss_tot: 298.2718048900552\n",
      "i: 699250, loss_tot: 274.4990889208956\n",
      "i: 699500, loss_tot: 209.52082131237162\n",
      "i: 699750, loss_tot: 206.70423535729566\n",
      "i: 700000, loss_tot: 222.14470248738778\n",
      "i: 700250, loss_tot: 230.98870696140918\n",
      "i: 700500, loss_tot: 236.84172986547463\n",
      "i: 700750, loss_tot: 240.57949953729786\n",
      "i: 701000, loss_tot: 214.39480610609056\n",
      "i: 701250, loss_tot: 196.700200138418\n",
      "i: 701500, loss_tot: 189.4175468472608\n",
      "i: 701750, loss_tot: 225.8233494088892\n",
      "i: 702000, loss_tot: 270.66450261697764\n",
      "i: 702250, loss_tot: 236.10240885612802\n",
      "i: 702500, loss_tot: 223.95234017266893\n",
      "i: 702750, loss_tot: 221.8675828291299\n",
      "i: 703000, loss_tot: 233.7585591051822\n",
      "i: 703250, loss_tot: 218.15838130480145\n",
      "i: 703500, loss_tot: 215.84953520684735\n",
      "i: 703750, loss_tot: 235.62625847305912\n",
      "i: 704000, loss_tot: 211.5482804448086\n",
      "i: 704250, loss_tot: 182.40154154030577\n",
      "i: 704500, loss_tot: 251.6344436106392\n",
      "i: 704750, loss_tot: 254.61540492421852\n",
      "i: 705000, loss_tot: 220.50598971460062\n",
      "i: 705250, loss_tot: 205.62053461191476\n",
      "i: 705500, loss_tot: 195.46982695527376\n",
      "i: 705750, loss_tot: 227.9926687722384\n",
      "i: 706000, loss_tot: 191.68475861521102\n",
      "i: 706250, loss_tot: 207.52024342261254\n",
      "i: 706500, loss_tot: 188.97361319409768\n",
      "i: 706750, loss_tot: 196.4562626944902\n",
      "i: 707000, loss_tot: 197.94232930236728\n",
      "i: 707250, loss_tot: 221.23998535838035\n",
      "i: 707500, loss_tot: 281.4703954634862\n",
      "i: 707750, loss_tot: 229.544169232344\n",
      "i: 708000, loss_tot: 233.9572784789656\n",
      "i: 708250, loss_tot: 215.57463751536997\n",
      "i: 708500, loss_tot: 288.96583894091714\n",
      "i: 708750, loss_tot: 297.51841624412805\n",
      "i: 709000, loss_tot: 257.59310616165413\n",
      "i: 709250, loss_tot: 262.7500679911673\n",
      "i: 709500, loss_tot: 213.52709771495313\n",
      "i: 709750, loss_tot: 260.5871583517564\n",
      "i: 710000, loss_tot: 250.23147821380292\n",
      "i: 710250, loss_tot: 200.44007401218528\n",
      "i: 710500, loss_tot: 204.7181399707025\n",
      "i: 710750, loss_tot: 201.0181322379601\n",
      "i: 711000, loss_tot: 199.4914254517376\n",
      "i: 711250, loss_tot: 216.63659084307693\n",
      "i: 711500, loss_tot: 205.6484913956282\n",
      "i: 711750, loss_tot: 279.55900186025593\n",
      "i: 712000, loss_tot: 191.0767226448562\n",
      "i: 712250, loss_tot: 230.28850647312123\n",
      "i: 712500, loss_tot: 178.61972956169396\n",
      "i: 712750, loss_tot: 286.5667257648241\n",
      "i: 713000, loss_tot: 273.3525249278749\n",
      "i: 713250, loss_tot: 234.4915529344028\n",
      "i: 713500, loss_tot: 191.8905358124338\n",
      "i: 713750, loss_tot: 193.44692629434633\n",
      "i: 714000, loss_tot: 255.60281308739914\n",
      "i: 714250, loss_tot: 180.93400940565974\n",
      "i: 714500, loss_tot: 211.60043671558756\n",
      "i: 714750, loss_tot: 235.55156618533655\n",
      "i: 715000, loss_tot: 187.23336809960165\n",
      "i: 715250, loss_tot: 246.7464460502755\n",
      "i: 715500, loss_tot: 220.62863017717376\n",
      "i: 715750, loss_tot: 220.94422608050982\n",
      "i: 716000, loss_tot: 260.1516890634503\n",
      "i: 716250, loss_tot: 214.84821491462128\n",
      "i: 716500, loss_tot: 209.98002346809955\n",
      "i: 716750, loss_tot: 256.7583070890797\n",
      "i: 717000, loss_tot: 201.60170542533604\n",
      "i: 717250, loss_tot: 232.11642891969532\n",
      "i: 717500, loss_tot: 178.7286271936819\n",
      "i: 717750, loss_tot: 219.5552225245675\n",
      "i: 718000, loss_tot: 210.48564765430055\n",
      "i: 718250, loss_tot: 228.2620362940349\n",
      "i: 718500, loss_tot: 243.67666512416224\n",
      "i: 718750, loss_tot: 205.78842852616827\n",
      "i: 719000, loss_tot: 242.29719019360024\n",
      "i: 719250, loss_tot: 172.56577266195515\n",
      "i: 719500, loss_tot: 214.28424553547063\n",
      "i: 719750, loss_tot: 206.7945337036997\n",
      "i: 720000, loss_tot: 186.1250403031241\n",
      "i: 720250, loss_tot: 260.6808039316145\n",
      "i: 720500, loss_tot: 216.24163454979657\n",
      "i: 720750, loss_tot: 211.67858240283095\n",
      "i: 721000, loss_tot: 230.89402360411364\n",
      "i: 721250, loss_tot: 187.06767316707163\n",
      "i: 721500, loss_tot: 181.29630257098276\n",
      "i: 721750, loss_tot: 263.4217212473847\n",
      "i: 722000, loss_tot: 225.5550123469904\n",
      "i: 722250, loss_tot: 219.5082582654219\n",
      "i: 722500, loss_tot: 229.41660592410162\n",
      "i: 722750, loss_tot: 200.68331686933024\n",
      "i: 723000, loss_tot: 215.00330525405704\n",
      "i: 723250, loss_tot: 218.76984469227492\n",
      "i: 723500, loss_tot: 216.00209645000766\n",
      "i: 723750, loss_tot: 257.3684379434842\n",
      "i: 724000, loss_tot: 228.62092434612566\n",
      "i: 724250, loss_tot: 172.33410726810806\n",
      "i: 724500, loss_tot: 188.36694213978626\n",
      "i: 724750, loss_tot: 205.2223187648319\n",
      "i: 725000, loss_tot: 195.93370187746027\n",
      "i: 725250, loss_tot: 186.5752227112312\n",
      "i: 725500, loss_tot: 235.85133661986328\n",
      "i: 725750, loss_tot: 245.64180140230573\n",
      "i: 726000, loss_tot: 203.55893542485762\n",
      "i: 726250, loss_tot: 225.70112952544355\n",
      "i: 726500, loss_tot: 214.4995741998301\n",
      "i: 726750, loss_tot: 247.21984060174472\n",
      "i: 727000, loss_tot: 188.35783548747656\n",
      "i: 727250, loss_tot: 224.57420958376753\n",
      "i: 727500, loss_tot: 205.244644816909\n",
      "i: 727750, loss_tot: 195.5587477517547\n",
      "i: 728000, loss_tot: 201.06545048270567\n",
      "i: 728250, loss_tot: 253.98151083312928\n",
      "i: 728500, loss_tot: 181.73755544175677\n",
      "i: 728750, loss_tot: 240.43552989049525\n",
      "i: 729000, loss_tot: 205.6081378443628\n",
      "i: 729250, loss_tot: 209.7982447295048\n",
      "i: 729500, loss_tot: 214.88636873061827\n",
      "i: 729750, loss_tot: 224.87963446484412\n",
      "i: 730000, loss_tot: 230.21489428444792\n",
      "i: 730250, loss_tot: 238.08172508117627\n",
      "i: 730500, loss_tot: 230.1823342713248\n",
      "i: 730750, loss_tot: 180.51737770465087\n",
      "i: 731000, loss_tot: 200.1534958830441\n",
      "i: 731250, loss_tot: 251.1171779726632\n",
      "i: 731500, loss_tot: 226.56717971194536\n",
      "i: 731750, loss_tot: 184.27630741229746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 732000, loss_tot: 242.1328905795864\n",
      "i: 732250, loss_tot: 261.1886766362407\n",
      "i: 732500, loss_tot: 200.52382099415422\n",
      "i: 732750, loss_tot: 231.05283008014877\n",
      "i: 733000, loss_tot: 235.14296671147866\n",
      "i: 733250, loss_tot: 215.01136665513738\n",
      "i: 733500, loss_tot: 254.73607313103042\n",
      "i: 733750, loss_tot: 200.0551202340611\n",
      "i: 734000, loss_tot: 181.37243620429973\n",
      "i: 734250, loss_tot: 208.24793758187886\n",
      "i: 734500, loss_tot: 200.17104453943233\n",
      "i: 734750, loss_tot: 224.4338899835949\n",
      "i: 735000, loss_tot: 186.53052984432202\n",
      "i: 735250, loss_tot: 262.675071992349\n",
      "i: 735500, loss_tot: 187.68043664181585\n",
      "i: 735750, loss_tot: 210.18815524434504\n",
      "i: 736000, loss_tot: 243.1117938328475\n",
      "i: 736250, loss_tot: 286.387861172393\n",
      "i: 736500, loss_tot: 196.5787823777643\n",
      "i: 736750, loss_tot: 199.6312133125128\n",
      "i: 737000, loss_tot: 185.5373161366023\n",
      "i: 737250, loss_tot: 196.85254964414634\n",
      "i: 737500, loss_tot: 233.19173012615997\n",
      "i: 737750, loss_tot: 217.26445704846643\n",
      "i: 738000, loss_tot: 211.74113845386398\n",
      "i: 738250, loss_tot: 185.87316975593566\n",
      "i: 738500, loss_tot: 218.11501531209797\n",
      "i: 738750, loss_tot: 229.81345633625983\n",
      "i: 739000, loss_tot: 172.76226883799666\n",
      "i: 739250, loss_tot: 206.26468104879896\n",
      "i: 739500, loss_tot: 164.8879684619361\n",
      "i: 739750, loss_tot: 184.4640665576933\n",
      "i: 740000, loss_tot: 231.7618535738581\n",
      "i: 740250, loss_tot: 205.80484275104783\n",
      "i: 740500, loss_tot: 258.92347115120924\n",
      "i: 740750, loss_tot: 195.6238647109914\n",
      "i: 741000, loss_tot: 210.70377515373286\n",
      "i: 741250, loss_tot: 215.69352845501663\n",
      "i: 741500, loss_tot: 206.16433910084422\n",
      "i: 741750, loss_tot: 250.51176022828267\n",
      "i: 742000, loss_tot: 202.86439830860937\n",
      "i: 742250, loss_tot: 215.54616172196347\n",
      "i: 742500, loss_tot: 205.90047848734073\n",
      "i: 742750, loss_tot: 221.45363216008468\n",
      "i: 743000, loss_tot: 174.6135838538578\n",
      "i: 743250, loss_tot: 242.33062824359223\n",
      "i: 743500, loss_tot: 221.51404475354585\n",
      "i: 743750, loss_tot: 217.52094936531302\n",
      "i: 744000, loss_tot: 252.71911703767807\n",
      "i: 744250, loss_tot: 177.95375548539522\n",
      "i: 744500, loss_tot: 246.72613956032276\n",
      "i: 744750, loss_tot: 207.281195191024\n",
      "i: 745000, loss_tot: 222.35365726563964\n",
      "i: 745250, loss_tot: 230.0561951087931\n",
      "i: 745500, loss_tot: 231.13577005978993\n",
      "i: 745750, loss_tot: 237.19279265613528\n",
      "i: 746000, loss_tot: 198.6871993914526\n",
      "i: 746250, loss_tot: 225.52724692985095\n",
      "i: 746500, loss_tot: 217.93158491822425\n",
      "i: 746750, loss_tot: 238.47935409171623\n",
      "i: 747000, loss_tot: 283.52033473839083\n",
      "i: 747250, loss_tot: 205.59218667854134\n",
      "i: 747500, loss_tot: 158.2488565284763\n",
      "i: 747750, loss_tot: 240.88241894151096\n",
      "i: 748000, loss_tot: 244.95285463145004\n",
      "i: 748250, loss_tot: 234.5725798388843\n",
      "i: 748500, loss_tot: 189.08107333575376\n",
      "i: 748750, loss_tot: 207.54859767710096\n",
      "i: 749000, loss_tot: 238.7621849167999\n",
      "i: 749250, loss_tot: 246.67844775148345\n",
      "i: 749500, loss_tot: 204.36185880565554\n",
      "i: 749750, loss_tot: 277.9826540902816\n",
      "i: 750000, loss_tot: 218.11314281960193\n",
      "i: 750250, loss_tot: 267.31465578419034\n",
      "i: 750500, loss_tot: 209.66449838643115\n",
      "i: 750750, loss_tot: 190.66505124823888\n",
      "i: 751000, loss_tot: 194.37763681978686\n",
      "i: 751250, loss_tot: 243.3662909771772\n",
      "i: 751500, loss_tot: 204.35088773590138\n",
      "i: 751750, loss_tot: 205.80534505458547\n",
      "i: 752000, loss_tot: 228.7065599703315\n",
      "i: 752250, loss_tot: 230.2134144209517\n",
      "i: 752500, loss_tot: 217.97111929091182\n",
      "i: 752750, loss_tot: 225.5816980208736\n",
      "i: 753000, loss_tot: 229.4671870044479\n",
      "i: 753250, loss_tot: 187.38439997085138\n",
      "i: 753500, loss_tot: 241.08090142672881\n",
      "i: 753750, loss_tot: 241.82510415837635\n",
      "i: 754000, loss_tot: 210.0335904650425\n",
      "i: 754250, loss_tot: 225.14845079681604\n",
      "i: 754500, loss_tot: 201.57634148248283\n",
      "i: 754750, loss_tot: 218.31319916281842\n",
      "i: 755000, loss_tot: 267.18139955163053\n",
      "i: 755250, loss_tot: 229.43501706602848\n",
      "i: 755500, loss_tot: 205.4544159737157\n",
      "i: 755750, loss_tot: 296.47801746768835\n",
      "i: 756000, loss_tot: 239.37243443915904\n",
      "i: 756250, loss_tot: 200.77732614809648\n",
      "i: 756500, loss_tot: 263.7032352747954\n",
      "i: 756750, loss_tot: 221.37089739261194\n",
      "i: 757000, loss_tot: 216.99239145783812\n",
      "i: 757250, loss_tot: 236.82981825145689\n",
      "i: 757500, loss_tot: 225.8213640686241\n",
      "i: 757750, loss_tot: 174.07150860142966\n",
      "i: 758000, loss_tot: 190.68733501589801\n",
      "i: 758250, loss_tot: 191.82279209472014\n",
      "i: 758500, loss_tot: 216.90578948757627\n",
      "i: 758750, loss_tot: 259.0390937983827\n",
      "i: 759000, loss_tot: 188.74979078587873\n",
      "i: 759250, loss_tot: 237.3966282081422\n",
      "i: 759500, loss_tot: 191.83916817218997\n",
      "i: 759750, loss_tot: 223.9762193385328\n",
      "i: 760000, loss_tot: 246.69895356748253\n",
      "i: 760250, loss_tot: 190.78183605932398\n",
      "i: 760500, loss_tot: 153.88941196935374\n",
      "i: 760750, loss_tot: 257.4143011140451\n",
      "i: 761000, loss_tot: 213.57505922909127\n",
      "i: 761250, loss_tot: 198.3679707312584\n",
      "i: 761500, loss_tot: 194.47189264521003\n",
      "i: 761750, loss_tot: 233.74907199624926\n",
      "i: 762000, loss_tot: 260.28237166842445\n",
      "i: 762250, loss_tot: 208.4832654406746\n",
      "i: 762500, loss_tot: 281.4925839010812\n",
      "i: 762750, loss_tot: 288.44302865731066\n",
      "i: 763000, loss_tot: 264.565229452271\n",
      "i: 763250, loss_tot: 194.71305124728025\n",
      "i: 763500, loss_tot: 221.71545963005727\n",
      "i: 763750, loss_tot: 196.4757599126734\n",
      "i: 764000, loss_tot: 219.9832819318169\n",
      "i: 764250, loss_tot: 215.66379800092503\n",
      "i: 764500, loss_tot: 256.31040045149\n",
      "i: 764750, loss_tot: 264.50511852594605\n",
      "i: 765000, loss_tot: 246.84129387815403\n",
      "i: 765250, loss_tot: 221.53118316626177\n",
      "i: 765500, loss_tot: 226.2617916756356\n",
      "i: 765750, loss_tot: 197.82452481614052\n",
      "i: 766000, loss_tot: 216.51779839484894\n",
      "i: 766250, loss_tot: 223.63105075577568\n",
      "i: 766500, loss_tot: 245.54180396381764\n",
      "i: 766750, loss_tot: 234.74070032272348\n",
      "i: 767000, loss_tot: 205.31651660189556\n",
      "i: 767250, loss_tot: 204.4592329934695\n",
      "i: 767500, loss_tot: 225.62065521062817\n",
      "i: 767750, loss_tot: 186.27629380726867\n",
      "i: 768000, loss_tot: 241.588021087979\n",
      "i: 768250, loss_tot: 261.3773558139243\n",
      "i: 768500, loss_tot: 239.1396144112789\n",
      "i: 768750, loss_tot: 220.67332607872902\n",
      "i: 769000, loss_tot: 229.96703766205349\n",
      "i: 769250, loss_tot: 176.41844318371656\n",
      "i: 769500, loss_tot: 233.88428528417134\n",
      "i: 769750, loss_tot: 206.85110427114415\n",
      "i: 770000, loss_tot: 241.29595351906028\n",
      "i: 770250, loss_tot: 230.25270468726697\n",
      "i: 770500, loss_tot: 224.9954449579842\n",
      "i: 770750, loss_tot: 220.09833013313124\n",
      "i: 771000, loss_tot: 215.06648225555662\n",
      "i: 771250, loss_tot: 272.1067333356764\n",
      "i: 771500, loss_tot: 204.53677298519307\n",
      "i: 771750, loss_tot: 215.23114404004534\n",
      "i: 772000, loss_tot: 219.9796005959205\n",
      "i: 772250, loss_tot: 238.66258680600558\n",
      "i: 772500, loss_tot: 232.25431627697776\n",
      "i: 772750, loss_tot: 221.15540975246114\n",
      "i: 773000, loss_tot: 216.0763193495013\n",
      "i: 773250, loss_tot: 189.99066406977536\n",
      "i: 773500, loss_tot: 229.06601197761665\n",
      "i: 773750, loss_tot: 317.8465781563311\n",
      "i: 774000, loss_tot: 242.65644769033509\n",
      "i: 774250, loss_tot: 186.11066041716606\n",
      "i: 774500, loss_tot: 254.51073993045836\n",
      "i: 774750, loss_tot: 174.45559776281243\n",
      "i: 775000, loss_tot: 203.54976116164414\n",
      "i: 775250, loss_tot: 204.5943491211989\n",
      "i: 775500, loss_tot: 162.92038362386793\n",
      "i: 775750, loss_tot: 270.76485274684205\n",
      "i: 776000, loss_tot: 194.74084741009133\n",
      "i: 776250, loss_tot: 206.58379218399526\n",
      "i: 776500, loss_tot: 235.89736863233207\n",
      "i: 776750, loss_tot: 229.3097887275275\n",
      "i: 777000, loss_tot: 243.2648861716638\n",
      "i: 777250, loss_tot: 242.5072659643628\n",
      "i: 777500, loss_tot: 203.90088930975006\n",
      "i: 777750, loss_tot: 219.98582380087234\n",
      "i: 778000, loss_tot: 208.18664750677183\n",
      "i: 778250, loss_tot: 198.46858787605436\n",
      "i: 778500, loss_tot: 176.11077920759743\n",
      "i: 778750, loss_tot: 270.53215823045645\n",
      "i: 779000, loss_tot: 223.03042050947582\n",
      "i: 779250, loss_tot: 235.21779494680646\n",
      "i: 779500, loss_tot: 212.12477938363793\n",
      "i: 779750, loss_tot: 179.05651300243102\n",
      "i: 780000, loss_tot: 227.13839649653252\n",
      "i: 780250, loss_tot: 232.75728475471394\n",
      "i: 780500, loss_tot: 227.82240877186072\n",
      "i: 780750, loss_tot: 246.31882227798923\n",
      "i: 781000, loss_tot: 194.23200339065517\n",
      "i: 781250, loss_tot: 254.8585269556499\n",
      "i: 781500, loss_tot: 230.8322229929577\n",
      "i: 781750, loss_tot: 224.32434320188332\n",
      "i: 782000, loss_tot: 219.90465851645916\n",
      "i: 782250, loss_tot: 189.51291809716554\n",
      "i: 782500, loss_tot: 213.45393542392648\n",
      "i: 782750, loss_tot: 242.48949849780664\n",
      "i: 783000, loss_tot: 189.25465109299577\n",
      "i: 783250, loss_tot: 237.68082864362702\n",
      "i: 783500, loss_tot: 207.96745910179604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 783750, loss_tot: 252.0923607951775\n",
      "i: 784000, loss_tot: 236.01040406699292\n",
      "i: 784250, loss_tot: 210.1004590171591\n",
      "i: 784500, loss_tot: 177.3131952783402\n",
      "i: 784750, loss_tot: 258.39702489283866\n",
      "i: 785000, loss_tot: 208.47682026490568\n",
      "i: 785250, loss_tot: 233.00928222691655\n",
      "i: 785500, loss_tot: 227.41214659516467\n",
      "i: 785750, loss_tot: 217.00513230351265\n",
      "i: 786000, loss_tot: 254.49746485879018\n",
      "i: 786250, loss_tot: 249.03764483374778\n",
      "i: 786500, loss_tot: 231.95978598975\n",
      "i: 786750, loss_tot: 222.3941777442385\n",
      "i: 787000, loss_tot: 218.68668966561555\n",
      "i: 787250, loss_tot: 266.04199720268\n",
      "i: 787500, loss_tot: 218.64470007103645\n",
      "i: 787750, loss_tot: 225.9509102216782\n",
      "i: 788000, loss_tot: 247.47913627818227\n",
      "i: 788250, loss_tot: 201.29257585125043\n",
      "i: 788500, loss_tot: 230.26306699693203\n",
      "i: 788750, loss_tot: 229.1577421088308\n",
      "i: 789000, loss_tot: 201.26149965959144\n",
      "i: 789250, loss_tot: 160.07087806764991\n",
      "i: 789500, loss_tot: 251.21789539947233\n",
      "i: 789750, loss_tot: 253.58057788004172\n",
      "i: 790000, loss_tot: 206.31834794630893\n",
      "i: 790250, loss_tot: 252.70367037105632\n",
      "i: 790500, loss_tot: 214.85217818715552\n",
      "i: 790750, loss_tot: 235.85318411853908\n",
      "i: 791000, loss_tot: 272.55136745858005\n",
      "i: 791250, loss_tot: 204.96380595883412\n",
      "i: 791500, loss_tot: 216.52791142532834\n",
      "i: 791750, loss_tot: 218.3543157958251\n",
      "i: 792000, loss_tot: 257.866337304886\n",
      "i: 792250, loss_tot: 198.58701322960468\n",
      "i: 792500, loss_tot: 204.01080987776194\n",
      "i: 792750, loss_tot: 170.51295701943934\n",
      "i: 793000, loss_tot: 229.53845652246687\n",
      "i: 793250, loss_tot: 201.61199159892305\n",
      "i: 793500, loss_tot: 217.753573578541\n",
      "i: 793750, loss_tot: 242.89907485886476\n",
      "i: 794000, loss_tot: 254.1606475844264\n",
      "i: 794250, loss_tot: 191.46062858842808\n",
      "i: 794500, loss_tot: 249.89418157757027\n",
      "i: 794750, loss_tot: 232.89972705525346\n",
      "i: 795000, loss_tot: 197.3174005754292\n",
      "i: 795250, loss_tot: 270.3067615051756\n",
      "i: 795500, loss_tot: 177.1830319508227\n",
      "i: 795750, loss_tot: 237.44245853370055\n",
      "i: 796000, loss_tot: 234.39502326900373\n",
      "i: 796250, loss_tot: 233.54616275935433\n",
      "i: 796500, loss_tot: 231.4211384459291\n",
      "i: 796750, loss_tot: 210.6032326467865\n",
      "i: 797000, loss_tot: 233.2680721066429\n",
      "i: 797250, loss_tot: 233.61918250918387\n",
      "i: 797500, loss_tot: 215.34428828462703\n",
      "i: 797750, loss_tot: 261.8102909434214\n",
      "i: 798000, loss_tot: 220.22735622732168\n",
      "i: 798250, loss_tot: 190.32851439061574\n",
      "i: 798500, loss_tot: 202.26476593970102\n",
      "i: 798750, loss_tot: 235.7530240015476\n",
      "i: 799000, loss_tot: 199.70960449082793\n",
      "i: 799250, loss_tot: 236.61196924394713\n",
      "i: 799500, loss_tot: 214.75243406676688\n",
      "i: 799750, loss_tot: 187.1921503689885\n",
      "i: 800000, loss_tot: 185.07968612569402\n",
      "i: 800250, loss_tot: 231.51249056201428\n",
      "i: 800500, loss_tot: 181.7649542553771\n",
      "i: 800750, loss_tot: 273.0371370467274\n",
      "i: 801000, loss_tot: 303.91294806730116\n",
      "i: 801250, loss_tot: 221.78084825739265\n"
     ]
    }
   ],
   "source": [
    "accum_vars = [tf.Variable(tf.zeros_like(tv.initialized_value()), trainable=False) for tv in model.trainable_variables]\n",
    "\n",
    "for i in range(10):\n",
    "    loss_tot = 0.0\n",
    "    losses = []\n",
    "    \n",
    "    ibatch = 0\n",
    "    \n",
    "    true_y = []\n",
    "    pred_y = []\n",
    "    \n",
    "    for ielem,train_data  in enumerate(train_ds):\n",
    "        \n",
    "        loss_value, grads = grad(model, train_data[:2],train_data[2], i)\n",
    "        \n",
    "        for igrad, gv in enumerate(grads):\n",
    "            accum_vars[igrad].assign_add(gv)\n",
    "        \n",
    "        loss_tot += loss_value.numpy()\n",
    "        if ibatch == 10:\n",
    "            opt.apply_gradients([(accum_vars[igrad] / 10, model.trainable_variables[igrad]) for igrad in range(len(accum_vars))])\n",
    "            ibatch = 0\n",
    "            for igrad in range(len(accum_vars)):\n",
    "                accum_vars[igrad].assign(tf.zeros_like(accum_vars[igrad]))\n",
    "                \n",
    "            losses.append(loss_tot)\n",
    "            loss_tot = 0\n",
    "        ibatch+=1\n",
    "\n",
    "        if ielem % 250 == 0: \n",
    "            print(f\"i: {ielem}, loss_tot: {np.mean(losses)}\")\n",
    "            losses.clear()\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f\"{models_path}/model_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    true_ids_testing = []\n",
    "    pred_ids_testing = []\n",
    "    loss_tot_testing = 0.0\n",
    "    for Xelem, ygen in zip(Xs_testing, ys_testing):\n",
    "        pred_id, pred_momentum, _ = model(Xelem)\n",
    "        true_ids_testing += [ygen[:, 0]]\n",
    "        pred_ids_testing += [tf.argmax(pred_id, axis=-1).numpy()]\n",
    "    true_ids_testing = np.concatenate(true_ids_testing)\n",
    "    pred_ids_testing = np.concatenate(pred_ids_testing)\n",
    "\n",
    "    acc = accuracy_score(true_ids, pred_ids)\n",
    "    acc_testing = accuracy_score(true_ids_testing, pred_ids_testing)\n",
    "    print(\"epoch={epoch} loss={loss:.2f} acc={acc:.4f}/{acc_testing:.4f}\".format(epoch=i, loss=loss_tot, acc=acc, acc_testing=acc_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#eval_ds = eval_ds.padded_batch(batch_size, padded_shapes=([None,n_features],[None,n_seed_features],[None,1]),\n",
    "#                                   padding_values=(0.,0.,0.),drop_remainder=True).repeat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
